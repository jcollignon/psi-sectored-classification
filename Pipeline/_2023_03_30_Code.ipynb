{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AnuYIc4-SNH"
      },
      "source": [
        "# Import and install all necessary packages in Python and Octave"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QWgcwHNG95zS"
      },
      "outputs": [],
      "source": [
        "# Import Colab specific packages and mount to Google Drive folder\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/', force_remount=True)\n",
        "\n",
        "!apt-get update\n",
        "!apt install msttcorefonts -qq\n",
        "\n",
        "# Import all necessary packages for code to run\n",
        "\n",
        "import os\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import math\n",
        "import pandas as pd\n",
        "import glob\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "from matplotlib.patches import Circle\n",
        "import seaborn as sns\n",
        "import copy\n",
        "from scipy import ndimage\n",
        "from scipy.spatial import procrustes\n",
        "import warnings\n",
        "import pickle\n",
        "import sklearn\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, UpSampling2D, Concatenate, GaussianNoise\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, LearningRateScheduler\n",
        "from tensorflow.python.client import device_lib\n",
        "from random import randint\n",
        "from tqdm import tqdm\n",
        "import cv2\n",
        "#from IPython.display import Image\n",
        "import PIL\n",
        "!pip3 install fpdf\n",
        "from fpdf import FPDF\n",
        "#import PyPDF2\n",
        "!pip3 install PyPDF2\n",
        "#from PyPDF2 import PdfFileMerger, PdfFileReader\n",
        "from PyPDF2 import PdfMerger, PdfReader\n",
        "import time # measure how long training takes\n",
        "import skimage\n",
        "from skimage.measure import label, find_contours\n",
        "from skimage.metrics import hausdorff_distance #, hausdorff_pair\n",
        "from skimage.morphology import skeletonize, convex_hull_image\n",
        "from skimage import draw\n",
        "import random\n",
        "\n",
        "!pip3 install num2words\n",
        "from num2words import num2words\n",
        "\n",
        "# Packages and programs required to run Octave code in this notebook (uses oct2py package)\n",
        "#print('ATTEMPTING TO INSTALL OCT2PY')\n",
        "!pip3 install oct2py #--no-deps\n",
        "#print('ATTEMPTING TO INSTALL OCTAVE')\n",
        "!apt install octave # makes it possible to run matlab scripts\n",
        "#print('ATTEMPTING TO INSTALL OCTAVE DEV TOOLS')\n",
        "!apt install liboctave-dev\n",
        "#!pip3 install --no-deps -e '/content/gdrive/My Drive/Colab Notebooks/Sector Project/oct2py-5.5.1'\n",
        "#print('BELOW IS AN ERROR IN SETUP!')\n",
        "\n",
        "import oct2py\n",
        "from oct2py import octave\n",
        "# The line below allows Octave to run alongside the notebook\n",
        "%load_ext oct2py.ipython \n",
        "\n",
        "\n",
        "# Check configurations\n",
        "# If you have a GPU connected, you should see specs pop up.\n",
        "tf.config.list_physical_devices('GPU')\n",
        "device_lib.list_local_devices()\n",
        "\n",
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "    print('Not connected to a GPU')\n",
        "else:\n",
        "    print(gpu_info)\n",
        "\n",
        "# Check if you are using a high-ram runtime (comes from one of Google's tutorials)\n",
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n",
        "\n",
        "if ram_gb < 20:\n",
        "    print('Not using a high-RAM runtime')\n",
        "else:\n",
        "    print('You are using a high-RAM runtime!')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HoDT8jsK3Jf1"
      },
      "source": [
        "# Start Octave and install its missing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7xWQY6Zpe7vy"
      },
      "outputs": [],
      "source": [
        "%%octave # Start Octave\n",
        "#pwd\n",
        "#dir(\"/content/gdrive/MyDrive\")\n",
        "#addpath(\"/content/gdrive/My Drive/Colab\\ Notebooks/sector-counting-pipeline/Pipeline\")\n",
        "#addpath(\"/content/gdrive/Colab Notebooks/sector-counting-pipeline/Pipeline\")\n",
        "#pkg install qt_toolkit\n",
        "#pkg install fltk\n",
        "\n",
        "#pkg install \"/content/gdrive/My Drive/Colab\\ Notebooks/psi-sectored-classification/image-2.12.0.tar.gz\"\n",
        "pkg install -forge image\n",
        "pkg load image\n",
        "\n",
        "#pkg install \"/content/gdrive/My Drive/Colab\\ Notebooks/psi-sectored-classification/dataframe-1.2.0.tar.gz\"\n",
        "pkg install -forge dataframe\n",
        "pkg load dataframe"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEt6DCxTSntw"
      },
      "source": [
        "# Set parameters for notebook flow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHNlZNfP4l5w"
      },
      "outputs": [],
      "source": [
        "#-----------------------\n",
        "# EXPECTED IMAGE INPUT\n",
        "#-----------------------\n",
        "\n",
        "# Input and output of U-Net\n",
        "# Image input and output\n",
        "H = 1024\n",
        "W = 1024\n",
        "shape = (H, W, 3) # The size of the input image (assumes 3 channels i.e. RGB)\n",
        "num_classes = 3 # How many classes of pixels should the segmentation have?\n",
        "# 2: Colony pixels versus background pixels\n",
        "# 3: Red colony pixels, white colony pixels and background pixels (this is what we will be using from now on)\n",
        "\n",
        "#---------------------\n",
        "# TRAINING PARAMETERS\n",
        "#---------------------\n",
        "\n",
        "# Training settings Enable training and/or classification\n",
        "train_model = False # set to True if you wish to train a new model\n",
        "use_test_network = True # set to True if you want to use a small model to test with instead of the implemented model\n",
        "\n",
        "# Model settings\n",
        "lr = 1e-4 # learning rate (initial)\n",
        "min_lr = 1e-6 # lowest learning rate if using a scheduler or a reduce on plateau (default is 1e-6)\n",
        "batch_size = 1 # how many images are fed in at one pass?\n",
        "epochs = 100 # the maximum number of passes through the images\n",
        "\n",
        "# Output segmentations of plates during training\n",
        "print_test_segs = False\n",
        "\n",
        "# Output segmentations of plates after training\n",
        "get_training_segs = True # save segmentations for the training images\n",
        "get_testing_segs = True # save segmentations for the testing images\n",
        "\n",
        "\n",
        "#---------------------\n",
        "# CLASSIFICATION PARAMETERS\n",
        "#---------------------\n",
        "\n",
        "# Should classification happen?\n",
        "classify_training_colonies = True\n",
        "classify_testing_colonies = True\n",
        "\n",
        "# Save all colony images and annotations of colonies from testing images\n",
        "save_all_annotations = True\n",
        "\n",
        "# Padding for images being saved (zooming out a bit, not adding blank pixels)\n",
        "image_padding = 5\n",
        "\n",
        "# Including OTHERS' annotations of the images\n",
        "use_expert_counts = False # quantifiable colonies from images (dots on the images)\n",
        "use_quantifiable_counts_from_table = False # quantifiable colonies tabulated (assumes you have the tabulated data)\n",
        "use_true_cured_colonies_from_table = False # cured colonies tabulated (assumes you have the tabulated data)\n",
        "use_true_sector_counts = False # sector frequencies tabulated (assumes you have the tabulated data)\n",
        "\n",
        "#---------------------\n",
        "# OTEHR THINGS TO LEAVE ALONE\n",
        "#---------------------\n",
        "\n",
        "# Set random number generator\n",
        "SEED = 42\n",
        "np.random.seed(SEED) # for numpy operations\n",
        "tf.random.set_seed(SEED) # for tensorflow operations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsYfQQtug_3p"
      },
      "source": [
        "# Get directories set up"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8WQQTOughJF-"
      },
      "outputs": [],
      "source": [
        "#---------------------------------------\n",
        "# THINGS TO CHANGE BEFORE RUNNING\n",
        "#---------------------------------------\n",
        "\n",
        "# 1. GET THE REPO DIRECTORY\n",
        "\n",
        "# Change the lines below to correspond to the loction of the repo in your Google Drive\n",
        "repo_parent_folder = '/content/gdrive/My Drive/Colab Notebooks' # The parent directory of the repo folder\n",
        "repo_body_folder = repo_parent_folder + '/psi-sectored-classification' # The repo folder itself, named \"Sector Project\"\n",
        "octave.addpath(repo_body_folder) # include this in Octave's path when reading functions.\n",
        "\n",
        "# This is the subfolder of the repo containing the segmnetation-classification pipeline.\n",
        "# This is also the directory of which this iPython script is found.\n",
        "main_folder = repo_body_folder + '/Pipeline' # The location of the code for running [PSI]-CIC\n",
        "\n",
        "\n",
        "# 2. GET THE FILE NAMES FOR THE WEIGHTS AND THE COLONY OUTPUT DOCUMENT\n",
        "\n",
        "# Name of the file containing the trainied weights\n",
        "# Such file should be stored in the \"Trained Models\" subfolder of \"Pipeline\"\n",
        "# Do not include the '.h5' file type at the end\n",
        "# File names:\n",
        "# 2021_07_01 (too big to add on Github)\n",
        "# test_model_3 (included in Github)\n",
        "weights_file = 'test_model_3'\n",
        "\n",
        "# NOTE: If you want to use the weights file used in the paper, please contact\n",
        "# me as Github's file size limits prevent me from including it in the repo.\n",
        "\n",
        "# Name of the output file containing all the colony crops from the classification step\n",
        "# This will be the name of the PDF file with colony crops in the \"_Pipeline_test\" folder.\n",
        "colony_chart_doc = '2023_03_15'\n",
        "\n",
        "\n",
        "# 3. GET DIRECTORIES OF TRAINING AND TESTING IMAGES\n",
        "\n",
        "# Training and validation image locations\n",
        "training_image_set = repo_body_folder + '/Image Generation/Synthetic_Images/train/images'\n",
        "validation_image_set = repo_body_folder + '/Image Generation/Synthetic_Images/val/images'\n",
        "\n",
        "# Directories of the testing images\n",
        "this_image_set = 'Test Plates/Set 1'\n",
        "# Note: The main folder where these images are found is \"Real Images\", which is the PARENT directory of this script\n",
        "# This will be the same structure used when looking at output for the specific image sets\n",
        "\n",
        "# If you would like to use one image to test how well a segmentation during\n",
        "# training is, write the name of the image you want to test in here.\n",
        "# This must be in the set of testing images.\n",
        "if print_test_segs == True:\n",
        "    image_to_test_with = 'Plate_2.jpg'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Initialize necessary folders for storing output (don't change this)"
      ],
      "metadata": {
        "id": "a663UgbaWj46"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Required folders\n",
        "Refer to this cell if a directory related error is thrown"
      ],
      "metadata": {
        "id": "6puKXvrPWxuu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check that the directories for syntheitc images and the weights exist.\n",
        "# AN ERROR IS THROWN IF ONE OF THEM CANNOT BE FOUND.\n",
        "\n",
        "# Directory where all TRAINING images and masks are found\n",
        "image_folder = repo_body_folder + '/Image Generation/Synthetic_Images'\n",
        "if os.path.exists(image_folder) == False:\n",
        "    raise NameError('Directory ' + image_folder + ' does not exist.')\n",
        "\n",
        "# Directory where model weights are stored or found\n",
        "weights_folder = main_folder + '/Trained Models'\n",
        "if os.path.exists(weights_folder) == False:\n",
        "    raise NameError('Directory ' + weights_folder + ' does not exist.')\n",
        "\n",
        "# Subdirectory containing all the test plates\n",
        "all_real_images_folder = repo_body_folder + '/' + 'Real_Images'\n",
        "if os.path.exists(all_real_images_folder) == False:\n",
        "    raise NameError('Directory ' + all_real_images_folder + ' does not exist.')\n",
        "\n",
        "# Subdirectory of the \"Real Images\" folder which contains the specific image set you are using\n",
        "real_image_folder = all_real_images_folder + '/' + this_image_set # leave this line alone\n",
        "if os.path.exists(real_image_folder) == False:\n",
        "    raise NameError('Directory ' + real_image_folder + ' does not exist.')\n",
        "\n",
        "# If you are using images containing the manual annotations, indicate where\n",
        "# this data is found\n",
        "if use_expert_counts == True:\n",
        "    additional_data_folder = main_folder + '/additional_data/' + this_image_set\n",
        "    if os.path.exists(additional_data_folder) == False:\n",
        "        raise NameError('Directory ' + additional_data_folder + ' does not exist.')\n",
        "\n",
        "# If you are using an image to intermediately test U-Net during training, \n",
        "# make sure the image you are using can be found\n",
        "if print_test_segs == True:\n",
        "    if os.path.exists(real_image_folder + '/' + image_to_test_with) == False:\n",
        "        raise NameError('The image you want to test with cannot be found in this folder.')"
      ],
      "metadata": {
        "id": "ezIfgS38WkT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Folders to add based on options"
      ],
      "metadata": {
        "id": "BhWRTbkkW6vf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#---------------------------------------------------\n",
        "# Training output directories\n",
        "\n",
        "# If folders do not exist, they will be created for you.\n",
        "\n",
        "# Primary directory where all output from TRAINING data will be stores\n",
        "train_output_folder = main_folder + '/output_train/' + str(weights_file)\n",
        "if os.path.exists(train_output_folder) == False:\n",
        "    os.makedirs(train_output_folder)\n",
        "\n",
        "# Subdirectory where TRAINING image segmentations will be stored\n",
        "train_seg_folder = train_output_folder + '/segs'\n",
        "if os.path.exists(train_seg_folder) == False:\n",
        "    os.mkdir(train_seg_folder)\n",
        "\n",
        "# Subdirectory where circle detections for the corresponding TRAINING image segmentation will be found\n",
        "train_circle_folder = train_output_folder + '/CHT Circles'\n",
        "if os.path.exists(train_circle_folder) == False:\n",
        "    os.makedirs(train_circle_folder)\n",
        "\n",
        "# Subdirectory where data for each circle detection in TRAINING images will be found (including position and radius)\n",
        "train_circle_data_folder = train_output_folder + '/CHT Data'\n",
        "if os.path.exists(train_circle_data_folder) == False:\n",
        "    os.makedirs(train_circle_data_folder)\n",
        "\n",
        "# Subdirectory where classification data for each detection in TRAINING images will be found (including position and radius)\n",
        "# These are .pkl files of tables, one per plate, containing data on each colony.\n",
        "train_output_table_folder = train_output_folder + '/Colony Tables'\n",
        "if os.path.exists(train_output_table_folder) == False:\n",
        "    os.makedirs(train_output_table_folder)\n",
        "\n",
        "\n",
        "#---------------------------------------------------\n",
        "# Testing output directories\n",
        "\n",
        "# If folders do not exist, they will be created for you.\n",
        "\n",
        "# If you would like to see output of the plate segmentation during the\n",
        "# training process, this is the subdirectory of the Pipeline folder where \n",
        "# such output will be stored\n",
        "if print_test_segs == True:\n",
        "    test_per_epoch_folder = main_folder + '/segs_per_epoch/' + str(weights_file) + '/' + this_image_set\n",
        "    if os.path.exists(test_per_epoch_folder) == False:\n",
        "        os.makedirs(test_per_epoch_folder)\n",
        "\n",
        "# Primary directory where all output from TESTING data will be stored\n",
        "# This is model specific, so the weights file name will be an additional subdirectory\n",
        "# for all image sets tested withn thouse weights.\n",
        "test_output_folder = main_folder + '/output_test/' + str(weights_file) + '/' + this_image_set\n",
        "if os.path.exists(test_output_folder) == False:\n",
        "    os.makedirs(test_output_folder)\n",
        "\n",
        "# Subdirectory where TESTING image segmentations will be stored\n",
        "test_seg_folder = test_output_folder + '/segs'\n",
        "if os.path.exists(test_seg_folder) == False:\n",
        "    os.makedirs(test_seg_folder)\n",
        "\n",
        "# Subdirectory where circle detections for the corresponding TESTING image segmentations will be found\n",
        "test_circle_folder = test_output_folder + '/CHT Circles'\n",
        "if os.path.exists(test_circle_folder) == False:\n",
        "    os.makedirs(test_circle_folder)\n",
        "\n",
        "# Subdirectory where data for each circle detection in TESTING images will be found (including position and radius)\n",
        "test_circle_data_folder = test_output_folder + '/CHT Data'\n",
        "if os.path.exists(test_circle_data_folder) == False:\n",
        "    os.makedirs(test_circle_data_folder)\n",
        "\n",
        "# Subdirectory where classification data for each detection in TESTING images will be found (including position and radius)\n",
        "# These are .pkl files of tables, one per plate, containing data on each colony.\n",
        "test_output_table_folder = test_output_folder + '/Colony Tables'\n",
        "if os.path.exists(test_output_table_folder) == False:\n",
        "    os.makedirs(test_output_table_folder)\n",
        "\n",
        "# Subdirectory showing the bounding boxes for each colony detected in the TESTING images will be found\n",
        "test_boxes_folder = test_output_folder + '/detections'\n",
        "if os.path.exists(test_boxes_folder) == False:\n",
        "    os.makedirs(test_boxes_folder)\n",
        "\n",
        "\n",
        "\n",
        "#------------------------------------------------------\n",
        "# FULL OUTPUT: ANNOTATION DETAILS AND PLOTS\n",
        "\n",
        "# Everything still stored in the subdiectory of output_test corresponding to \n",
        "# the segmentaion weights and image set used.\n",
        "\n",
        "# Subdirectory which stores PDF documents per plate showing the cropped colony, its\n",
        "# segmentation, and annotations.\n",
        "output_details_folder = test_output_folder + '/PDF Details'\n",
        "if os.path.exists(output_details_folder) == False:\n",
        "    os.makedirs(output_details_folder)\n",
        "\n",
        "# Subdirectory which stores plots visualizing data obgtained from each plate\n",
        "output_plots_folder = test_output_folder + '/Plots'\n",
        "if os.path.exists(output_plots_folder) == False:\n",
        "    os.makedirs(output_plots_folder)\n",
        "    \n",
        "#-------------------------------------------------------\n",
        "# FULL OUTPUT: CROPPING DIRECTORIES\n",
        "\n",
        "# This section is only active when save_all_annotations is True\n",
        "\n",
        "if save_all_annotations == True:\n",
        "\n",
        "    output_crops_folder = test_output_folder + '/crops'\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/raw') == False:\n",
        "        os.makedirs(output_crops_folder + '/raw') # where the original colonies are cropped and stored\n",
        "\n",
        "    # Below used only if data on quantifiable colonies are available\n",
        "\n",
        "    if use_expert_counts == True:\n",
        "        if os.path.exists(output_crops_folder + '/counted') == False:\n",
        "            os.makedirs(output_crops_folder + '/counted') # where the original quantifiable colonies are cropped and stored\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/circles') == False:\n",
        "        os.makedirs(output_crops_folder + '/circles') # same as before, but a circle is overlayed on the colony\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/segs') == False:\n",
        "        os.makedirs(output_crops_folder + '/segs') # the output from the U-Net segmentation such that only nonzero pixels in the circle are kept\n",
        "\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/init_regions') == False:\n",
        "        os.makedirs(output_crops_folder + '/init_regions') # A segmentation outlining the possible sector-like regions of the colony, both red and white\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/init_bounds') == False:\n",
        "        os.makedirs(output_crops_folder + '/init_bounds') # The raw segmentation containing only the boundary of the colony\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/init_partitions') == False:\n",
        "        os.makedirs(output_crops_folder + '/init_partitions') # same as the raw segmentation, but with lines annotated to represent locations of sector borders\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/init_bad') == False:\n",
        "        os.makedirs(output_crops_folder + '/init_bad') # A segmentation outlining the sector-like regions that failed the consistency check\n",
        "\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/cor_segs') == False:\n",
        "        os.makedirs(output_crops_folder + '/cor_segs') # the output from the U-Net segmentation such that only nonzero pixels in the circle are kept\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/cor_bounds') == False:\n",
        "        os.makedirs(output_crops_folder + '/cor_bounds') # The corrected segmentation containing only the boundary of the colony\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/cor_regions') == False:\n",
        "        os.makedirs(output_crops_folder + '/cor_regions') # the output from the U-Net segmentation such that only nonzero pixels in the circle are kept\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/cor_bounds') == False:\n",
        "        os.makedirs(output_crops_folder + '/cor_bounds') # same as the raw segmentation, but with lines annotated to represent locations of sector borders\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/cor_bad') == False:\n",
        "        os.makedirs(output_crops_folder + '/cor_bad') # A segmentation outlining the sector-like regions that failed the consistency check (should usually be blank after correction is performed)\n",
        "\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/sectors') == False:\n",
        "        os.makedirs(output_crops_folder + '/sectors') # the output containing the regions in the segmentation where a sector is predicted\n",
        "\n",
        "    if os.path.exists(output_crops_folder + '/sector_comps') == False:\n",
        "        os.makedirs(output_crops_folder + '/sector_comps') # same as before, but only red pixels in the segmentation are considered"
      ],
      "metadata": {
        "id": "sbcdCHFtW-r_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vv8knHnRStQk"
      },
      "source": [
        "# Functions to Load"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Functions for U-Net and classification"
      ],
      "metadata": {
        "id": "7s_oTZFsY7av"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5RmkuLhQ-XrF"
      },
      "source": [
        "### U-Net Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "it5W4ucb-Qp-"
      },
      "outputs": [],
      "source": [
        "# Functions for the U-Net Architecture\n",
        "\n",
        "# U-Net architecture, more deep\n",
        "\n",
        "def conv_block(inputs, channels, pool=True):\n",
        "    x = Conv2D(channels, 3, padding=\"same\")(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    x = Conv2D(channels, 3, padding=\"same\")(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Activation('relu')(x)\n",
        "\n",
        "    if pool == True: # Only to be used in the encoder path which has max pooling layers\n",
        "        p = MaxPool2D((2,2))(x)\n",
        "        return x, p\n",
        "    else:\n",
        "        return x\n",
        "\n",
        "if use_test_network == False:\n",
        "    print('Running U-Net.')\n",
        "\n",
        "    def build_unet(shape, num_classes):\n",
        "        inputs = Input(shape)\n",
        "\n",
        "        # Determine whether to add a layer indicating adding noise\n",
        "        # This should be done to the training images only.\n",
        "        #inputs = GaussianNoise(inputs, stddev=0.5) # use this\n",
        "        #inputs = GaussianNoise(inputs, stddev=0.5, training=True)\n",
        "\n",
        "        # Encoder region\n",
        "\n",
        "        x1, p1 = conv_block(inputs, 64, pool=True)\n",
        "        x2, p2 = conv_block(p1, 128, pool=True)\n",
        "        x3, p3 = conv_block(p2, 256, pool=True)\n",
        "        x4, p4 = conv_block(p3, 512, pool=True)\n",
        "\n",
        "        # Connecting the Encoder and Decoder regions (the deepest layer)\n",
        "\n",
        "        b1 = conv_block(p4, 1024, pool=False)\n",
        "\n",
        "        # Decoder Region\n",
        "\n",
        "        u1 = UpSampling2D((2,2), interpolation=\"bilinear\")(b1)\n",
        "        #print(u1.shape)\n",
        "        #print(x4.shape)\n",
        "        c1 = Concatenate()([u1, x4])\n",
        "        x5 = conv_block(c1, 512, pool=False)\n",
        "\n",
        "        u2 = UpSampling2D((2,2), interpolation=\"bilinear\")(x5)\n",
        "        c2 = Concatenate()([u2, x3])\n",
        "        x6 = conv_block(c2, 256, pool=False)\n",
        "\n",
        "        u3 = UpSampling2D((2,2), interpolation=\"bilinear\")(x6)\n",
        "        c3 = Concatenate()([u3, x2])\n",
        "        x7 = conv_block(c3, 128, pool=False)\n",
        "\n",
        "        u4 = UpSampling2D((2,2), interpolation=\"bilinear\")(x7)\n",
        "        c4 = Concatenate()([u4, x1])\n",
        "        x8 = conv_block(c4, 64, pool=False)\n",
        "\n",
        "        # Obtain output layer with number of desired classes\n",
        "\n",
        "        output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x8)\n",
        "\n",
        "        return Model(inputs, output)\n",
        "\n",
        "elif use_test_network == True:\n",
        "    print('Running the testing network.')\n",
        "\n",
        "    def build_unet(shape, num_classes):\n",
        "        inputs = Input(shape)\n",
        "\n",
        "        # Encoder region\n",
        "\n",
        "        x1, p1 = conv_block(inputs, 8, pool=True)\n",
        "\n",
        "        # Decoder Region\n",
        "\n",
        "        u1 = UpSampling2D((2,2), interpolation=\"bilinear\")(p1)\n",
        "        x2 = conv_block(u1, 16, pool=False)\n",
        "\n",
        "        # Obtain output layer with number of desired classes\n",
        "\n",
        "        output = Conv2D(num_classes, 1, padding=\"same\", activation=\"softmax\")(x2)\n",
        "\n",
        "        return Model(inputs, output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KBCMydc3-djw"
      },
      "source": [
        "### Pre-processing images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Q5RIlpt-gSX"
      },
      "outputs": [],
      "source": [
        "# function to crop image\n",
        "def crop(img):\n",
        "    i, j = img.nonzero()[:2]\n",
        "    x_min = i.min()\n",
        "    x_max = i.max() + 1\n",
        "    y_min = j.min()\n",
        "    y_max = j.max() + 1\n",
        "    return img[x_min:x_max, y_min:y_max], [x_min, x_max, y_min, y_max]\n",
        "\n",
        "def trim_border(x):\n",
        "    if x.shape[0] > x.shape[1]:\n",
        "        pixel_diff = x.shape[0] - x.shape[1]\n",
        "        if pixel_diff % 2 == 0:\n",
        "            x_cropped = x[(pixel_diff // 2):(x.shape[0]-(pixel_diff // 2)),:,:]\n",
        "        else:\n",
        "            x_cropped = x[math.ceil(pixel_diff / 2):x.shape[0]-(math.floor(pixel_diff / 2)),:,:]\n",
        "\n",
        "    elif x.shape[0] < x.shape[1]:\n",
        "        pixel_diff = x.shape[1] - x.shape[0]\n",
        "        if pixel_diff % 2 == 0:\n",
        "            x_cropped = x[:,(pixel_diff // 2):x.shape[1]-(pixel_diff // 2),:]\n",
        "        else:\n",
        "            x_cropped = x[:,math.ceil(pixel_diff / 2):x.shape[1]-(math.floor(pixel_diff / 2)),:]\n",
        "\n",
        "    else:\n",
        "        x_cropped = x\n",
        "    #print('After Resizing: ' + 'Width: ' + str((x_cropped.shape)[0]) + ', Height: ' + str((x_cropped.shape)[1]))\n",
        "    #raise NameError('Image is saved.')\n",
        "    return x_cropped\n",
        "\n",
        "def read_image(x):\n",
        "    x = cv2.imread(x,cv2.IMREAD_COLOR)\n",
        "    x = trim_border(x) # this should be called \n",
        "    x = cv2.resize(x,(W,H))\n",
        "    x = x / 255.0 # normalize image\n",
        "    x = x.astype(np.float32)\n",
        "    return x\n",
        "\n",
        "def read_mask(x):\n",
        "    x = cv2.imread(x,cv2.IMREAD_GRAYSCALE)\n",
        "    #print(x.shape)\n",
        "    x = cv2.resize(x,(W,H))\n",
        "    if num_classes == 2:\n",
        "        x = x / 255.0\n",
        "        # This is necessary because for some reason binary images automatically have 0 and 255 encoded.\n",
        "        #x = cv2.resize(x,(16,16))\n",
        "        #print(x.shape)\n",
        "    x = x.astype(np.int32)\n",
        "    return x\n",
        "\n",
        "def tf_dataset(x,y, batch=1):\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((x,y))\n",
        "    dataset = dataset.shuffle(buffer_size=500)\n",
        "    dataset = dataset.map(preprocess)\n",
        "    dataset = dataset.batch(batch)\n",
        "    dataset = dataset.repeat()\n",
        "    dataset = dataset.prefetch(2)\n",
        "    return dataset\n",
        "\n",
        "def preprocess(x,y):\n",
        "    def f(x,y):\n",
        "        x = x.decode()\n",
        "        y = y.decode()\n",
        "\n",
        "        image = read_image(x)\n",
        "        mask = read_mask(y)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "    image, mask = tf.numpy_function(f, [x, y], [tf.float32, tf.int32])\n",
        "    mask = tf.one_hot(mask, num_classes, dtype=tf.int32)\n",
        "    image.set_shape([H,W,3]) # does not change\n",
        "    mask.set_shape([H,W,num_classes]) # change last argument dependeing on how many classes you want to do for segmentation\n",
        "\n",
        "    return image, mask"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_bYZFAk-0ib"
      },
      "source": [
        "## Helper functions\n",
        "1. Cropping an image\n",
        "2. Finding unique elements in a lists\n",
        "3. Bresenham's Line Algorithm (draw line in pixel space)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgdCwJLV-1kL"
      },
      "outputs": [],
      "source": [
        "# Helper functions\n",
        "\n",
        "# function to get unique values\n",
        "# (https://www.geeksforgeeks.org/python-get-unique-values-list/)\n",
        "def unique(list1):\n",
        " \n",
        "  # intilize a null list\n",
        "    unique_list = []\n",
        "        \n",
        "    # traverse for all elements\n",
        "    for x in list1:\n",
        "        # check if exists in unique_list or not\n",
        "        if x not in unique_list:\n",
        "            unique_list.append(x)\n",
        "        # print list\n",
        "    return unique_list\n",
        "\n",
        "# Create triangle starting from center, connecting the two ends of a connected component\n",
        "# To get the boundaries of the triangle, use Bresenham's line algorithm\n",
        "\n",
        "# Definition taken from http://www.roguebasin.com/index.php?title=Bresenham%27s_Line_Algorithm#Python\n",
        "def get_line(start, end):\n",
        "    \"\"\"Bresenham's Line Algorithm\n",
        "    Produces a list of tuples from start and end\n",
        "\n",
        "    >>> points1 = get_line((0, 0), (3, 4))\n",
        "    >>> points2 = get_line((3, 4), (0, 0))\n",
        "    >>> assert(set(points1) == set(points2))\n",
        "    >>> print points1\n",
        "    [(0, 0), (1, 1), (1, 2), (2, 3), (3, 4)]\n",
        "    >>> print points2\n",
        "    [(3, 4), (2, 3), (1, 2), (1, 1), (0, 0)]\n",
        "    \"\"\"\n",
        "    # Setup initial conditions\n",
        "    x1, y1 = start\n",
        "    x2, y2 = end\n",
        "    dx = x2 - x1\n",
        "    dy = y2 - y1\n",
        "\n",
        "    # Determine how steep the line is\n",
        "    is_steep = abs(dy) > abs(dx)\n",
        "\n",
        "    # Rotate line\n",
        "    if is_steep:\n",
        "        x1, y1 = y1, x1\n",
        "        x2, y2 = y2, x2\n",
        "\n",
        "    # Swap start and end points if necessary and store swap state\n",
        "    swapped = False\n",
        "    if x1 > x2:\n",
        "        x1, x2 = x2, x1\n",
        "        y1, y2 = y2, y1\n",
        "        swapped = True\n",
        "\n",
        "    # Recalculate differentials\n",
        "    dx = x2 - x1\n",
        "    dy = y2 - y1\n",
        "\n",
        "    # Calculate error\n",
        "    error = int(dx / 2.0)\n",
        "    ystep = 1 if y1 < y2 else -1\n",
        "\n",
        "    # Iterate over bounding box generating points between start and end\n",
        "    y = y1\n",
        "    points = []\n",
        "    for x in range(x1, x2 + 1):\n",
        "        coord = (y, x) if is_steep else (x, y)\n",
        "        points.append(coord)\n",
        "        error -= abs(dy)\n",
        "        if error < 0:\n",
        "            y += ystep\n",
        "            error += dx\n",
        "\n",
        "    # Reverse the list if the coordinates were swapped\n",
        "    if swapped:\n",
        "        points.reverse()\n",
        "    return points\n",
        "\n",
        "# Function to sort bounary pixels by theta value relative to center of colony image\n",
        "    # 'seg' should be the mask of the colony boundary\n",
        "    # 'start' is the center of the image, and 'end' is the boundary pixel\n",
        "def sort_thetas(seg):\n",
        "    # get center of the segmentation\n",
        "    seg_shape = seg.shape\n",
        "    seg_center = (np.round(seg_shape[1]/2.0), np.round(seg_shape[0]/2.0))\n",
        "\n",
        "    # get the points on the boundary\n",
        "    points = np.transpose(np.nonzero(seg)).tolist()\n",
        "\n",
        "    # Get the angles from the center to the endpoints\n",
        "    these_thetas = []\n",
        "    for this_point in points:\n",
        "        diff_width = this_point[1] - seg_center[0]\n",
        "        diff_height = this_point[0] - seg_center[1]\n",
        "        these_thetas.append(math.atan2(-diff_height, diff_width))\n",
        "\n",
        "    these_thetas_sorted = np.sort(these_thetas)\n",
        "    these_thetas_sorted_args = np.argsort(these_thetas)\n",
        "    sorted_points = []\n",
        "    for this_arg in these_thetas_sorted_args:\n",
        "        sorted_points.append(points[this_arg])\n",
        "\n",
        "    # Add a copy of the first point to the end to make this periodic\n",
        "    these_thetas_sorted = np.append(these_thetas_sorted, these_thetas_sorted[0])\n",
        "    sorted_points.append(sorted_points[0])\n",
        "    \n",
        "    return these_thetas_sorted, sorted_points\n",
        "\n",
        "# Function to create data for plotting 'intensity' between endpoints of a line\n",
        "def get_intensity_map(seg, sorted_points):\n",
        "    intensity_sum = []\n",
        "    full_seg_sum = []\n",
        "    seg_shape = seg.shape\n",
        "    seg_center = (np.round(seg_shape[1]/2.0).astype(np.int32), np.round(seg_shape[0]/2.0).astype(np.int32))\n",
        "\n",
        "    # get a line between the center and each endpoint iteratively\n",
        "    for this_point in sorted_points:\n",
        "        line_points = get_line(seg_center, tuple(this_point))\n",
        "        line_points_sum = len(line_points)\n",
        "\n",
        "        # make mask containing points on the line\n",
        "        seg_line = np.zeros_like(seg)\n",
        "        full_seg = np.zeros_like(seg)\n",
        "        for this_line_point in line_points:\n",
        "\n",
        "            full_seg[this_line_point[0], this_line_point[1]] = True\n",
        "            # check if each pixel on the line is red.  Keep those that are red only\n",
        "            if seg[this_line_point[0], this_line_point[1]] == True:\n",
        "                seg_line[this_line_point[0], this_line_point[1]] = True\n",
        "\n",
        "        seg_line_sum = np.sum(seg_line)\n",
        "        intensity_sum.append(seg_line_sum)\n",
        "        full_seg_sum.append(np.sum(full_seg))\n",
        "\n",
        "    return intensity_sum, full_seg_sum\n",
        "\n",
        "def create_filled_ellipse_in_array(seg, padding = 0):\n",
        "    ellipse_array = np.zeros_like(seg).astype(bool)\n",
        "    ellipse_height = seg.shape[0]\n",
        "    ellipse_width = seg.shape[1]\n",
        "    rr, cc = draw.ellipse((ellipse_height -1) / 2.0, (ellipse_width-1) / 2.0, (ellipse_height) / 2.0 - padding, (ellipse_width) / 2.0 - padding)\n",
        "    ellipse_array[rr,cc] = 1\n",
        "    return ellipse_array\n",
        "\n",
        "def create_circle_boundary(seg, radius):\n",
        "    ellipse_array = np.zeros_like(seg).astype(bool)\n",
        "    ellipse_height = seg.shape[0]\n",
        "    ellipse_width = seg.shape[1]\n",
        "    rr, cc = draw.ellipse((ellipse_height -1) / 2.0, (ellipse_width-1) / 2.0, radius, radius)\n",
        "    ellipse_array[rr,cc] = 1\n",
        "    ellipse_boundary = get_colony_boundary_binary(ellipse_array)\n",
        "    return ellipse_boundary\n",
        "\n",
        "def get_endpoint_locations(endpoints_list, seg, radius):\n",
        "    # Function finds the angle between the center and endpoints of the component,\n",
        "    # and extends the endpoint to the radius of the circle predicted\n",
        "    ellipse_array = np.zeros_like(seg).astype(bool)\n",
        "    ellipse_height = seg.shape[0]\n",
        "    ellipse_width = seg.shape[1]\n",
        "    mid_height = (ellipse_height -1) / 2.0\n",
        "    mid_width = (ellipse_width -1) / 2.0\n",
        "    endpoints_x = []\n",
        "    endpoints_y = []\n",
        "    endpoints_x.append(mid_width)\n",
        "    endpoints_y.append(mid_height)\n",
        "    center_seg = list([mid_height, mid_width])\n",
        "    angle_list = []\n",
        "    for this_endpoint in endpoints_list:\n",
        "        angle = math.atan2((this_endpoint[0] - endpoints_y[0]), (this_endpoint[1] - endpoints_x[0]))\n",
        "        angle_list.append(angle)\n",
        "    endpoint_locations = []\n",
        "    for this_angle in angle_list:\n",
        "        endpoint_x = center_seg[1] + radius*math.cos(this_angle)\n",
        "        endpoint_y = center_seg[0] + radius*math.sin(this_angle)\n",
        "        endpoint_locations.append(list([endpoint_x, endpoint_y]))\n",
        "        endpoints_x.append(endpoint_x)\n",
        "        endpoints_y.append(endpoint_y)\n",
        "    return angle_list, endpoint_locations, endpoints_x, endpoints_y\n",
        "\n",
        "def switch_red_white(seg):\n",
        "    temp_seg = copy.deepcopy(seg)\n",
        "    temp_seg = np.where(temp_seg == 255, 111, temp_seg) # find pixels given 255, place a temporary number (these should be red pixels)\n",
        "    temp_seg = np.where(temp_seg == 127, 255, temp_seg) # find pixels given 255, and assign them 255 (these are the white pixels you want to label properly)\n",
        "    temp_seg = np.where(temp_seg == 111, 127, temp_seg) # find pixels given the temporary label, and assign them 127 (these are the red pixels you want to label properly)\n",
        "    return temp_seg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gVsFlEMA-3V1"
      },
      "source": [
        "## Classification Code\n",
        "Functions related to the colony boundary\n",
        "\n",
        "1. Find the colony boundary and skeletonize it.\n",
        "2. Same as 1, but with binaray images.\n",
        "3. Get the red and white components.\n",
        "4. Find the connected components of the red boundary.\n",
        "5. For each component, find the endpoints.\n",
        "6. Draw the sector from the endpoints to the colony center.\n",
        "7. Get the boundary and interior of the sector.\n",
        "8. Check if the interior and boundary partitions of the sector are consistent\n",
        "9. Decide if the boundary has been misclassified.  If yes, change the class of the colony boundary.  Rerun steps 4-9.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-YyUzDm2-5xO"
      },
      "outputs": [],
      "source": [
        "# Function to find colony boundary\n",
        "\n",
        "def get_colony_boundary(colony_mask):\n",
        "    padded_colony = np.pad(colony_mask[:,:,0] != 0, 1, 'constant', constant_values=0)\n",
        "    check_boundary_array = np.zeros_like(padded_colony) + 4\n",
        "    image_shape = check_boundary_array.shape\n",
        "\n",
        "    for i in range(1,image_shape[0]-1):\n",
        "        for j in range(1,image_shape[1]-1):\n",
        "            check_boundary_array[i,j] = check_boundary_array[i,j] - padded_colony[i-1,j] # pixel above is 1\n",
        "            check_boundary_array[i,j] = check_boundary_array[i,j] - padded_colony[i+1,j] # pixel below is 1\n",
        "            check_boundary_array[i,j] = check_boundary_array[i,j] - padded_colony[i,j-1] # pixel to the left is 1\n",
        "            check_boundary_array[i,j] = check_boundary_array[i,j] - padded_colony[i,j+1] # pixel to the right is 1\n",
        "\n",
        "    background_mask = check_boundary_array > 0\n",
        "    edge_mask = np.multiply(background_mask, padded_colony) # sanity check so that boundary is in the padded colony\n",
        "    edge_mask_unpadded = edge_mask[1:-1, 1:-1] # remove the padding\n",
        "\n",
        "    # Skeletonize red boundary pixels (https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html)\n",
        "    # This will turn any represenation of a cohesive red colony region on the boundary as a set of lines in pixels space, meant to correct for areas that have weird boundaries.\n",
        "    edge_mask_unpadded = skeletonize(edge_mask_unpadded)\n",
        "    return edge_mask_unpadded\n",
        "\n",
        "# binary version of above code\n",
        "def get_colony_boundary_binary(colony_mask):\n",
        "    padded_colony = np.pad(colony_mask != 0, 1, 'constant', constant_values=0)\n",
        "    check_boundary_array = np.zeros_like(padded_colony) + 4\n",
        "    image_shape = check_boundary_array.shape\n",
        "\n",
        "    for i in range(1,image_shape[0]-1):\n",
        "        for j in range(1,image_shape[1]-1):\n",
        "            check_boundary_array[i,j] = check_boundary_array[i,j] - padded_colony[i-1,j] # pixel above is 1\n",
        "            check_boundary_array[i,j] = check_boundary_array[i,j] - padded_colony[i+1,j] # pixel below is 1\n",
        "            check_boundary_array[i,j] = check_boundary_array[i,j] - padded_colony[i,j-1] # pixel to the left is 1\n",
        "            check_boundary_array[i,j] = check_boundary_array[i,j] - padded_colony[i,j+1] # pixel to the right is 1\n",
        "\n",
        "    background_mask = check_boundary_array > 0\n",
        "    edge_mask = np.multiply(background_mask, padded_colony) # sanity check so that boundary is in the padded colony\n",
        "    edge_mask_unpadded = edge_mask[1:-1, 1:-1] # remove the padding\n",
        "\n",
        "    # Skeletonize red boundary pixels (https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html)\n",
        "    # This will turn any represenation of a cohesive red colony region on the boundary as a set of lines in pixels space, meant to correct for areas that have weird boundaries.\n",
        "    edge_mask_unpadded = skeletonize(edge_mask_unpadded)\n",
        "    return edge_mask_unpadded\n",
        "\n",
        "\n",
        "# Function to find both the red and white partitions of colony boundary\n",
        "\n",
        "def get_boundary_partitions(red_colony_mask, white_colony_mask, boundary):\n",
        "    red_boundary_mask = np.multiply(red_colony_mask, boundary)\n",
        "    white_boundary_mask = np.multiply(white_colony_mask, boundary)\n",
        "    boundary_mask_h, boundary_mask_w =  boundary.shape\n",
        "\n",
        "    \n",
        "    #red_boundary_skeleton = skeletonize(red_boundary_mask)\n",
        "    #white_boundary_skeleton = skeletonize(white_boundary_mask)\n",
        "    return red_boundary_mask, white_boundary_mask, boundary_mask_h, boundary_mask_w\n",
        "\n",
        "\n",
        "# Function to find endpoints of red connected component\n",
        "\n",
        "def get_boundary_component_endpoints(colony_image, red_component):\n",
        "    red_component_padded = np.pad(red_component, 1, 'constant', constant_values=0).astype(np.int32)\n",
        "\n",
        "    # This function uses the results of 2 methods to find endpoints of a curve in order to deal with each other's deficiencies.\n",
        "\n",
        "    # Method 1:\n",
        "    # Hit-miss algortihm using cv2 function goodFeaturesToTrack (https://docs.opencv.org/3.4/dd/d1a/group__imgproc__feature.html#ga1d6bb77486c8f92d79c8793ad995d541)\n",
        "    red_endpoints = cv2.goodFeaturesToTrack(red_component.astype(np.uint8), maxCorners=2, qualityLevel=0.01, minDistance=0.1)\n",
        "    if type(red_endpoints == None):\n",
        "        red_endpoints_list = []\n",
        "        #print(red_endpoints_list)\n",
        "    else:\n",
        "        red_endpoints = red_endpoints.astype(np.int32)\n",
        "        red_endpoints_list = (red_endpoints[0].astype(np.int32)).tolist()\n",
        "\n",
        "    # Method 2:\n",
        "    # Look for the obvious endpoints that 'corner'\n",
        "    endpoints_check = np.zeros_like(colony_image) + 8\n",
        "    endpoints_check_padded = np.pad(endpoints_check, 1, 'constant', constant_values=0)\n",
        "    endpoint_padded_shape = endpoints_check_padded.shape\n",
        "\n",
        "    for i in range(1,endpoint_padded_shape[0]-1):\n",
        "        for j in range(1,endpoint_padded_shape[1]-1):\n",
        "            endpoints_check_padded[i,j] = endpoints_check_padded[i,j] - red_component_padded[i-1,j] # pixel above is 1\n",
        "            endpoints_check_padded[i,j] = endpoints_check_padded[i,j] - red_component_padded[i+1,j] # pixel below is 1\n",
        "            endpoints_check_padded[i,j] = endpoints_check_padded[i,j] - red_component_padded[i,j-1] # pixel to the left is 1\n",
        "            endpoints_check_padded[i,j] = endpoints_check_padded[i,j] - red_component_padded[i,j+1] # pixel to the right is 1\n",
        "            endpoints_check_padded[i,j] = endpoints_check_padded[i,j] - red_component_padded[i-1,j-1] # pixel on top-left is 1\n",
        "            endpoints_check_padded[i,j] = endpoints_check_padded[i,j] - red_component_padded[i-1,j+1] # pixel on top-right is 1\n",
        "            endpoints_check_padded[i,j] = endpoints_check_padded[i,j] - red_component_padded[i+1,j-1] # pixel on bottom-left is 1\n",
        "            endpoints_check_padded[i,j] = endpoints_check_padded[i,j] - red_component_padded[i+1,j+1] # pixel on bottom-right is 1\n",
        "\n",
        "    # Look for any 'cornering' pixels.  There should be at most 2 if skeletonize works properly.\n",
        "    endpoint_mask = endpoints_check_padded > 6\n",
        "    component_endpoint_mask = np.multiply(endpoint_mask, red_component_padded) # sanity check to see if endpoints are part of boundary mask\n",
        "    component_endpoint_mask_unpadded = component_endpoint_mask[1:-1, 1:-1]\n",
        "    endpoint_locations = np.nonzero(component_endpoint_mask_unpadded)\n",
        "\n",
        "    # ensure dimensions are consistent\n",
        "    endpoint_locations = np.transpose(np.flip(np.flip(np.array(endpoint_locations), axis=0),axis=1))\n",
        "    endpoint_locations = endpoint_locations.tolist()\n",
        "\n",
        "    # combine lists and keep the unique elements\n",
        "\n",
        "    full_endpoints_list = endpoint_locations + red_endpoints_list\n",
        "    full_endpoints_list = unique(full_endpoints_list)\n",
        "\n",
        "    if len(full_endpoints_list) == 1:\n",
        "        warnings.warn('Algorithm found only 1 endpoint.  It\\'s possible that you have a very small region, but double check the code again anyway.')\n",
        "    elif len(full_endpoints_list) > 2:\n",
        "        warnings.warn('Algorithm found more than 2 endpoints.  Possible bad boundary detected.  Will proceed in using the first two elements in the list.')\n",
        "    elif len(full_endpoints_list) == 0:\n",
        "        warnings.warn('Algorithm found no endpoints.  It\\'s possible that you have a full cycle, but double check the code again anyway.')\n",
        "\n",
        "    return full_endpoints_list # This does NOT include the center of the colony\n",
        "\n",
        "\n",
        "# Function that returns the boundary and filled sector\n",
        "\n",
        "def get_sector_masks(red_component, full_endpoints_list):\n",
        "    sector_bounds = np.zeros_like(red_component)\n",
        "    red_h, red_w = sector_bounds.shape\n",
        "\n",
        "    # if there exists an endpoint\n",
        "    if len(full_endpoints_list) > 0:\n",
        "        bound_1 = get_line((np.round(red_h/2.0).astype(np.int32), np.round(red_w/2.0).astype(np.int32)), (full_endpoints_list[0][1],full_endpoints_list[0][0]))\n",
        "        boundary_line_1 = [list(this_pix) for this_pix in bound_1]\n",
        "        for this_point in boundary_line_1:\n",
        "            sector_bounds[this_point[0],this_point[1]] = 1\n",
        "\n",
        "    # if there exists at least two endpoints (and hopefully there are EXACTLY two...)\n",
        "    if len(full_endpoints_list) > 1:\n",
        "        bound_2 = get_line((np.round(red_h/2.0).astype(np.int32), np.round(red_w/2.0).astype(np.int32)), (full_endpoints_list[1][1],full_endpoints_list[1][0]))\n",
        "        boundary_line_2 = [list(this_pix) for this_pix in bound_2]\n",
        "        for this_point in boundary_line_2:\n",
        "            sector_bounds[this_point[0],this_point[1]] = 1\n",
        "\n",
        "    sector_boundary = np.logical_or(sector_bounds, red_component)\n",
        "\n",
        "    # Flood fill region inside sector boundary\n",
        "    sector_filled = copy.deepcopy(sector_boundary)\n",
        "    sector_filled[ndimage.binary_fill_holes(sector_filled)] = 1 # flood fill region using 'binary_fill_holes'\n",
        "    sector_filled = sector_filled.astype(np.int32)\n",
        "\n",
        "    sector_interior = np.logical_xor(sector_filled, sector_boundary)\n",
        "    return sector_boundary, sector_interior, sector_filled\n",
        "\n",
        "\n",
        "# Function to check for interior-exterior consistency\n",
        "\n",
        "def check_for_consistency(sector_interior, sector_boundary, red_colony_mask):\n",
        "  # Check that the interior of the sector is represented in the colony\n",
        "    check_interior = np.logical_and(sector_interior, red_colony_mask)\n",
        "    interior_sum = np.sum(sector_interior)\n",
        "    check_interior_sum = np.sum(check_interior)\n",
        "    # If there is no interior or there are two few pixels, use both the interior and the boundary.\n",
        "    if interior_sum >= 3:\n",
        "        # If first condition is met, check to see how close the sector is actually captured by U-Net\n",
        "        # Compute the number of pixels in the sector detected by U-Net, divided by the number of pixels in tbe simplified sector.\n",
        "        prop_interior = check_interior_sum.astype(np.float64) / interior_sum.astype(np.float64)\n",
        "        if prop_interior < 0.5:\n",
        "            #print('There is one sector that may be misclassified.  Moving on to next sector.')\n",
        "            confirm_check = False\n",
        "            # U-Net did not detect an adequate number of pixels inside the simplified sector\n",
        "            # This could be a misclassified sector\n",
        "            # In this case, change the bad boundary pixels to the opposite color\n",
        "            # Since we are working only with the red boundary pixel, change the bad red pixels to white pixels.\n",
        "        else:\n",
        "            #print('This is a sector')\n",
        "            confirm_check = True\n",
        "            # If the second condition is also not met, then you have a sector\n",
        "            # add the sector to the list\n",
        "    else:\n",
        "        #print('There is one sector that is too small to analyze.  Using both interior and boundary instead')\n",
        "        full_sector = np.logical_or(sector_interior, sector_boundary)\n",
        "        check_interior_and_boundary = np.logical_and(full_sector, red_colony_mask)\n",
        "        sector_sum = np.sum(full_sector)\n",
        "        check_full_sum = np.sum(check_interior_and_boundary)\n",
        "        prop_interior = check_full_sum.astype(np.float64) / sector_sum.astype(np.float64)\n",
        "        if sector_sum >= 5:\n",
        "            # There are enough pixels overall to perform a measurement.\n",
        "            \n",
        "            if prop_interior < 0.5:\n",
        "                #print('There is one sector that may be misclassified.  Moving on to next sector.')\n",
        "                confirm_check = False\n",
        "            else:\n",
        "                #print('This is a sector')\n",
        "                confirm_check = True\n",
        "\n",
        "        else:\n",
        "            #print('There is one sector that is too small for the method being used.  Skipping this one.')\n",
        "            confirm_check = False\n",
        "    \n",
        "    return confirm_check, prop_interior\n",
        "\n",
        "# A redo of the above function, but considers the full region regardless of how many pixels there are (must be greater than 0)\n",
        "def check_for_consistency_2(sector_filled, colony_mask):\n",
        "  # Check that the interior of the sector is represented in the colony\n",
        "    check_interior = np.logical_and(sector_filled, colony_mask)\n",
        "    sector_sum = np.sum(sector_filled)\n",
        "    check_sector_sum = np.sum(check_interior)\n",
        "    prop_interior = check_sector_sum.astype(np.float64) / sector_sum.astype(np.float64)\n",
        "\n",
        "    if prop_interior < 0.5:\n",
        "        confirm_check = False\n",
        "    else:\n",
        "        confirm_check = True\n",
        "    \n",
        "    return confirm_check, prop_interior\n",
        "\n",
        "\n",
        "# Function to change pixels from red to white\n",
        "\n",
        "def change_pixel_labels(red_boundary_skeleton, red_component, white_boundary_skeleton):\n",
        "  # If a potential sector is lacking interior red pixels, and intead has sifficinet percentage of white pixels,\n",
        "  # this function will change the exterior pixels of the sector from red to white.\n",
        "    temp_red_boundary_skeleton = np.logical_xor(red_boundary_skeleton, red_component) # one is a subset of the other\n",
        "    temp_white_boundary_skeleton = np.logical_or(white_boundary_skeleton, red_component) # both are disjoint\n",
        "    return temp_red_boundary_skeleton, temp_white_boundary_skeleton\n",
        "\n",
        "# Function doesn't work yet.  Use the two below this.\n",
        "def pixel_class_swap_on_boundary(boundary_skeleton_to_change, red_boundary_skeleton_bad_components, white_boundary_skeleton_bad_components):\n",
        "\n",
        "    bad_red_boundary_pixels = np.logical_and(boundary_skeleton_to_change > 0, red_boundary_skeleton_bad_components)\n",
        "    bad_white_boundary_pixels = np.logical_and(boundary_skeleton_to_change > 0, white_boundary_skeleton_bad_components)\n",
        "\n",
        "    # Change bad red boundaries to white\n",
        "    boundary_skeleton_to_change[bad_red_boundary_pixels] = 1\n",
        "\n",
        "    # Change bad white boundaries to red\n",
        "    boundary_skeleton_to_change[bad_white_boundary_pixels] = 2\n",
        "\n",
        "    return boundary_skeleton_to_change\n",
        "\n",
        "# Functions for swapping boundary labels for components that fail consistency check\n",
        "# Consider writing a function that does both operatons for both classes.\n",
        "def grow_boundary(boundary_skeleton_to_grow, bad_components_to_take):\n",
        "    # using logical or allows to add to the existing structure\n",
        "    grown_boundary = np.logical_or(boundary_skeleton_to_grow, bad_components_to_take)  # For example, add the bad white boundaries to the red boundaries\n",
        "    return grown_boundary\n",
        "\n",
        "def shrink_boundary(boundary_skeleton_to_shrink, bad_components_to_remove):\n",
        "    # Since red and white boundaries are both disjoint subsets of the full boundary, using xor will subtract the subset from the whole without adding new information.\n",
        "    shrunk_boundary = np.logical_xor(boundary_skeleton_to_shrink, bad_components_to_remove) # For example, remove the bad white boundaries, and give them to the red boundaries\n",
        "    return shrunk_boundary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U12rQGjZiPaZ"
      },
      "source": [
        "## Functions for shape properties"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PpaLqNJTiXVo"
      },
      "outputs": [],
      "source": [
        "# Condition 1: Check that the colony segmentation is one connected component\n",
        "def check_components_of_colony(seg):\n",
        "    # First, check if the colony is one connected component\n",
        "    binary_seg = seg > 0\n",
        "    seg_labels = label(binary_seg)\n",
        "    num_labels = np.unique(seg_labels)[1:]\n",
        "    #print('Number of labels: ' + str(num_labels))\n",
        "\n",
        "    if len(num_labels) == 1:\n",
        "        # The colony is one connected component\n",
        "        # This satisfies the condition\n",
        "        condition_1_strong = True\n",
        "        condition_1_weak = True\n",
        "    else:\n",
        "        binary_seg_count = np.count_nonzero(binary_seg)\n",
        "        # This colony has two or more connectged components\n",
        "        # Find the biggest one, and set a threshold\n",
        "        # Loop through each non-zero number\n",
        "        max_comp_size = 0\n",
        "        for this_label in num_labels:\n",
        "            this_comp = seg_labels[seg_labels == this_label]\n",
        "            this_comp_size = sum(this_comp)\n",
        "            if this_comp_size > max_comp_size:\n",
        "                max_comp_size = copy.deepcopy(this_comp_size)\n",
        "        big_ratio = max_comp_size / float(binary_seg_count)\n",
        "        if big_ratio > 0.9:\n",
        "            condition_1_strong = False\n",
        "            condition_1_weak = True\n",
        "        else:\n",
        "            condition_1_strong = False\n",
        "            condition_1_weak = False\n",
        "\n",
        "    return condition_1_strong, condition_1_weak\n",
        "\n",
        "\n",
        "# Condition 2: Check that the boundary of the colony sgentmation is one connected cpmponent\n",
        "# The one should be more strict because all parts of the boundary are used explicitly in the classification step.\n",
        "def check_components_of_boundary(seg_boundary):\n",
        "    # First, check if the colony is one connected component\n",
        "    binary_seg = seg_boundary > 0\n",
        "    seg_labels = label(binary_seg)\n",
        "    num_labels = np.unique(seg_labels)[1:]\n",
        "\n",
        "    if len(num_labels) == 1:\n",
        "        # The boundary meets condition 2\n",
        "        condition_2 = True\n",
        "    else:\n",
        "        # The boundary has two or more connected compoents\n",
        "        # This fails condition 2\n",
        "        condition_2 = False\n",
        "    \n",
        "    return condition_2\n",
        "\n",
        "\n",
        "# Condition 3: Check for holes in the colony segmentation.\n",
        "# Ideas: Get the colony boundary.  Fill it.  If the fill matches the colony segmentation,\n",
        "# then this is easly verified.  If there is more than one connected component, \n",
        "# then this condition will automatically fail.\n",
        "def check_for_holes(seg, seg_boundary):\n",
        "    binary_seg = seg > 0\n",
        "    binary_boundary = seg_boundary > 0\n",
        "\n",
        "    #print(binary_seg.shape)\n",
        "    #print(binary_boundary.shape)\n",
        "\n",
        "    # Take the boundary and fill the space in between\n",
        "    filled_boundary = copy.deepcopy(binary_boundary)\n",
        "    filled_boundary[ndimage.binary_fill_holes(filled_boundary)] = True\n",
        "    #print(filled_boundary.shape)\n",
        "    # print('Filled boundary')\n",
        "    # plt.imshow(filled_boundary)\n",
        "    # plt.show()\n",
        "    filled_boundary_count = np.count_nonzero(filled_boundary) # number of pixels inside the boundary, including the boundary itself.\n",
        "    binary_seg_agreement = np.logical_and(binary_seg, filled_boundary) # all pixels in the filled boundary that are also in the segmentation\n",
        "    binary_seg_agreement_count = np.count_nonzero(binary_seg_agreement) # how many of those pixels exist?\n",
        "    binary_seg_count = np.count_nonzero(binary_seg)\n",
        "    #print(binary_seg_agreement_count)\n",
        "    #print(binary_seg_count)\n",
        "    if (float(binary_seg_agreement_count) / float(filled_boundary_count)) > 0.999:\n",
        "        # The boundary and the space within matches that of the space occupies by the colony segmenatation\n",
        "        condition_3 = True\n",
        "    else:\n",
        "        condition_3 = False\n",
        "    \n",
        "    return condition_3\n",
        "\n",
        "\n",
        "# Condition 4: Check that the colony boundary has only one cycle, and that the cycle uses every pixel of the boundary.\n",
        "# This is equivalent to saying that the colony boundary has exactly one Hamiltonian cycle.\n",
        "# Showing that there exists one is far easier than showing there is only one though.\n",
        "def find_hamilton_cycle(seg_boundary):\n",
        "    binary_boundary = seg_boundary > 0\n",
        "    # Check that a cycle exists\n",
        "    # If it exists, check that the cycle traverses the same number of pixels as the number in the segmentation\n",
        "    # Idea: Find all cycles of an image.  Aim for the ones whose length is the same as the number of pixels of the boundary.  This will ensure that all teh pixels are being used.\n",
        "    \n",
        "    # get contours\n",
        "    contours = cv2.findContours(binary_boundary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    hierarchy = contours[1] if len(contours) == 2 else contours[2]\n",
        "    contours = contours[0] if len(contours) == 2 else contours[1]\n",
        "\n",
        "    # count inner contours\n",
        "    count = 0\n",
        "    for component in zip(contours, hierarchy):\n",
        "        cntr = component[0]\n",
        "        hier = component[1]\n",
        "        # discard outermost no parent contours and keep innermost no child contours\n",
        "        # hier = indices for next, previous, child, parent\n",
        "        # no parent or no child indicated by negative values\n",
        "        if (hier[3] > -1) & (hier[2] < 0):\n",
        "            count = count + 1\n",
        "\n",
        "    # get the actual inner list of hierarchy descriptions\n",
        "    hierarchy = hierarchy[0]\n",
        "\n",
        "    has_cycle = False\n",
        "    return has_cycle\n",
        "\n",
        "    \n",
        "    \n",
        "\n",
        "# Condition 5: Check that the convex hull of the segmentation is close to a circle.\n",
        "def compare_convex_hull(seg, seg_boundary):\n",
        "    binary_seg = seg > 0\n",
        "    binary_boundary = seg_boundary > 0\n",
        "    #binary_seg_count = np.count_nonzero(binary_seg)\n",
        "\n",
        "    # Compare the convex hull of the segmentation with the segmentation itself\n",
        "    chull_seg = convex_hull_image(binary_boundary)\n",
        "    chull_seg_count = np.count_nonzero(chull_seg)\n",
        "    # print('Convex Hull')\n",
        "    # plt.imshow(chull_seg)\n",
        "    # plt.show()\n",
        "    #chull_seg_count = np.count_nonzero(chull_seg)\n",
        "    comparison_with_seg = np.logical_and(binary_seg, chull_seg) # compare the convex hull to the segmentation\n",
        "    comparison_with_seg_count = np.count_nonzero(comparison_with_seg) # count the number of pixels appearing in both\n",
        "    #print(float(comparison_with_seg_count))\n",
        "    #print(float(chull_seg_count))\n",
        "    if (float(comparison_with_seg_count) / float(chull_seg_count)) > 0.95:\n",
        "        # The colony segmentation appears to be approximately convex\n",
        "        #print('Convex segmentation')\n",
        "        is_approximately_convex = True\n",
        "    else:\n",
        "        #print('Not convex')\n",
        "        is_approximately_convex = False\n",
        "\n",
        "    # Compare the colony semgation to a circle.\n",
        "    filled_circle = create_filled_ellipse_in_array(seg, padding = 0)\n",
        "    filled_circle_count = np.count_nonzero(filled_circle)\n",
        "    comparison_with_circle = np.logical_and(binary_seg, filled_circle)\n",
        "    comparison_with_circle_count = np.count_nonzero(comparison_with_circle)\n",
        "    if (float(comparison_with_circle_count) / float(filled_circle_count)) > 0.95:\n",
        "        # The colony segmentation appears to be approximately convex\n",
        "        #print('Circular')\n",
        "        is_approximately_circular = True\n",
        "    else:\n",
        "        #print('Not circular')\n",
        "        is_approximately_circular = False\n",
        "\n",
        "    return is_approximately_convex, is_approximately_circular\n",
        "\n",
        "# Condition 6: Compute the Hausdorff distance between the boundary segmentation and the enclosing circle.\n",
        "# Ideally, we want the shape of the colony segmengtation to be very similar to a circle, because real coloies appear round.\n",
        "def get_hausdorff_distance(seg, seg_boundary):\n",
        "    binary_seg = seg > 0\n",
        "    binary_boundary = seg_boundary > 0\n",
        "    chull_seg = convex_hull_image(binary_boundary) # get convex hull of the boundary, and fill it.\n",
        "    chull_boundary = get_colony_boundary_binary(chull_seg)\n",
        "    filled_circle = create_filled_ellipse_in_array(seg, padding = 0)\n",
        "    circle_boundary = get_colony_boundary_binary(filled_circle)\n",
        "\n",
        "    # Compute Hausdorff distance between colony boundary and circle\n",
        "    dist_to_circle = hausdorff_distance(binary_boundary, circle_boundary)\n",
        "\n",
        "    # Compute Hausdorff distance between colony boundary and the boundary of the segmentation's convex hull\n",
        "    dist_to_chull = hausdorff_distance(binary_boundary, chull_boundary)\n",
        "\n",
        "    return dist_to_chull, dist_to_circle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssk6NEIKlRb3"
      },
      "source": [
        "## Functions for Plotting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bK2aZ3glTXr"
      },
      "outputs": [],
      "source": [
        "def find_mode(my_array):\n",
        "    vals, counts = np.unique(my_array, return_counts = True)\n",
        "    index = np.argmax(counts)\n",
        "    return vals[index], counts[index]\n",
        "\n",
        "def get_count_breakdown(my_array):\n",
        "    if len(my_array) > 0:\n",
        "        vals, counts = np.unique(my_array, return_counts = True)\n",
        "        max_val = np.max(vals)\n",
        "        vals_list = list(vals)\n",
        "        sorted_counts = []\n",
        "        for i in range(0, max_val+1):\n",
        "            this_val = vals_list.index(i)\n",
        "            sorted_counts.append(counts[this_val])\n",
        "        return np.array(sorted_counts)\n",
        "    else:\n",
        "        return np.array([])\n",
        "\n",
        "def extend_array(my_array, length):\n",
        "    if my_array.size < length:\n",
        "        some_zeros = length - my_array.size\n",
        "        my_ext_array = np.append(my_array, np.zeros((1, some_zeros), dtype=int))\n",
        "        return my_ext_array\n",
        "    else:\n",
        "        return my_array\n",
        "\n",
        "def get_sector_count_breakdown(my_array):\n",
        "    if len(my_array) > 0:\n",
        "        vals, counts = np.unique(my_array, return_counts = True)\n",
        "        max_val = np.max(vals)\n",
        "        min_val = np.min(vals)\n",
        "        if min_val != 0:\n",
        "            no_counts = np.array([0 for i in range(0, min_val)])\n",
        "            counts = np.append(no_counts, counts)\n",
        "            no_vals = np.array([i for i in range(0, min_val)])\n",
        "            vals = np.append(no_vals, vals)\n",
        "        vals_list = list(vals)\n",
        "        sorted_counts = []\n",
        "        print(counts)\n",
        "        print(vals)\n",
        "        print(vals_list)\n",
        "        for i in range(0, max_val+1):\n",
        "            this_val = vals_list.index(i)\n",
        "            sorted_counts.append(counts[this_val])\n",
        "        return np.array(sorted_counts)\n",
        "    else:\n",
        "        return np.array([])\n",
        "\n",
        "def addlabels_initial(x,y,fs):\n",
        "    for i in range(len(x)):\n",
        "        ax.text(i-(0.25), y[i]+5, y[i], ha = 'center', fontfamily=\"serif\", fontsize=fs)\n",
        "\n",
        "def addlabels_prediction(x,y,fs):\n",
        "    for i in range(len(x)):\n",
        "        ax.text(i, y[i]+5, y[i], ha = 'center', fontfamily=\"serif\", fontsize=fs)\n",
        "\n",
        "def addlabels_truemarks(x,y,fs):\n",
        "    for i in range(len(x)):\n",
        "        ax.text(i+(0.25), y[i]+5, y[i], ha = 'center', fontfamily=\"serif\", fontsize=fs)\n",
        "\n",
        "def addlabels_centered(x,y,fs):\n",
        "    for i in range(len(x)):\n",
        "        ax.text(x[i], y[i]+5, y[i], ha = 'center', fontfamily=\"serif\", fontsize=fs)\n",
        "\n",
        "\n",
        "def addlabels_initial_ax(x,y,fs, this_axis):\n",
        "    for i in range(len(x)):\n",
        "        ax[this_axis].text(i-(0.25), y[i]+5, y[i], ha = 'center', fontfamily=\"serif\", fontsize=fs)\n",
        "\n",
        "def addlabels_prediction_ax(x,y,fs, this_axis):\n",
        "    for i in range(len(x)):\n",
        "        ax[this_axis].text(i, y[i]+5, y[i], ha = 'center', fontfamily=\"serif\", fontsize=fs)\n",
        "\n",
        "def addlabels_truemarks_ax(x,y,fs, this_axis):\n",
        "    for i in range(len(x)):\n",
        "        ax[this_axis].text(i+(0.25), y[i]+5, y[i], ha = 'center', fontfamily=\"serif\", fontsize=fs)\n",
        "\n",
        "def addlabels_centered_ax(x,y,fs, this_axis):\n",
        "    for i in range(len(x)):\n",
        "        ax[this_axis].text(x[i], y[i]+5, y[i], ha = 'center', fontfamily=\"serif\", fontsize=fs)\n",
        "\n",
        "def addlabels_prediction_ax_bytick(x,y,fs, this_axis):\n",
        "    for i in range(len(x)):\n",
        "        ax[this_axis].text(x[i], y[i]+5, y[i], ha = 'center', fontfamily=\"serif\", fontsize=fs)\n",
        "\n",
        "def addlabels_truemarks_ax_bytick(x,y,fs, this_axis):\n",
        "    for i in range(len(x)):\n",
        "        ax[this_axis].text(x[i]+(0.25), y[i]+5, y[i], ha = 'center', fontfamily=\"serif\", fontsize=fs)\n",
        "\n",
        "def addlabels_centered_ax_bytick(x,y,fs, this_axis):\n",
        "    for i in range(len(x)):\n",
        "        ax[this_axis].text(x[i], y[i]+5, y[i], ha = 'center', fontfamily=\"serif\", fontsize=fs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOxLMcYr-_la"
      },
      "source": [
        "# Load training and validation images, and save paths to those images\n",
        "Only use this if you have the masks showing sector counts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0CoBKV7l_EBn"
      },
      "outputs": [],
      "source": [
        "# Images for Training and validation\n",
        "\n",
        "# Get paths of training and validation sets\n",
        "\n",
        "train_path = image_folder + '/train'\n",
        "val_path = image_folder + '/val'\n",
        "\n",
        "image_path = train_path + '/images/'\n",
        "mask_path = train_path + '/masks/'\n",
        "sector_count_path = train_path + '/masks_sector_counts/'\n",
        "#mask_boundary_path = train_path + '/masks_bw_boundary/'\n",
        "val_image_path = val_path + '/images/'\n",
        "val_mask_path = val_path + '/masks/'\n",
        "val_sector_count_path = val_path + '/masks_sector_counts/'\n",
        "#val_mask_boundary_path = val_path + '/masks_bw_boundary/'\n",
        "\n",
        "# Get names of training images and masks\n",
        "\n",
        "my_images = glob.glob(image_path + '*.png')\n",
        "my_masks = glob.glob(mask_path + '*.png')\n",
        "my_sector_counts = glob.glob(sector_count_path + '*.png')\n",
        "my_val_images = glob.glob(val_image_path + '*.png')\n",
        "my_val_masks = glob.glob(val_mask_path + '*.png')\n",
        "my_val_sector_counts = glob.glob(val_sector_count_path + '*.png')\n",
        "\n",
        "# Check that list length is the same\n",
        "if (len(my_images) != len(my_masks)) | (len(my_images) != len(my_sector_counts)):\n",
        "    raise ValueError('The number of images in the train subdirectories are inconsistent.  Check that the numbe of images is the same in all train subdirectories.')\n",
        "\n",
        "if (len(my_val_images) != len(my_val_masks)) | (len(my_val_images) != len(my_val_sector_counts)):\n",
        "    raise ValueError('The number of images in the val subdirectories are inconsistent.  Check that the number of images is the same in all val subdirectories.')\n",
        "\n",
        "\n",
        "# Check that all images used have the (image, mask, sector_count) tuple.\n",
        "\n",
        "for file in my_images:\n",
        "    x = os.path.basename(file)\n",
        "    #print(mask_path + x)\n",
        "    if os.path.exists(mask_path + x) == False:\n",
        "        raise NameError('Training mask not found for image ' + image_path + x)\n",
        "    if os.path.exists(sector_count_path + x) == False:\n",
        "        raise NameError('Training sector count mask not found for image ' + image_path + x)\n",
        "\n",
        "for file in my_masks:\n",
        "    x = os.path.basename(file)\n",
        "    #print(mask_path + x)\n",
        "    if os.path.exists(image_path + x) == False:\n",
        "        raise NameError('Training image not found for mask ' + mask_path + x)\n",
        "    if os.path.exists(sector_count_path + x) == False:\n",
        "        raise NameError('Training sector count mask not found for mask ' + mask_path + x)\n",
        "\n",
        "for file in my_sector_counts:\n",
        "    x = os.path.basename(file)\n",
        "    #print(mask_path + x)\n",
        "    if os.path.exists(image_path + x) == False:\n",
        "        raise NameError('Training image not found for sector count mask ' + sector_count_path + x)\n",
        "    if os.path.exists(mask_path + x) == False:\n",
        "        raise NameError('Training mask not found for sector count mask ' + sector_count_path + x)\n",
        "\n",
        "# Get names of validation images and masks\n",
        "\n",
        "for file in my_val_images:\n",
        "    x = os.path.basename(file)\n",
        "    #print(mask_path + x)\n",
        "    if os.path.exists(val_mask_path + x) == False:\n",
        "        raise NameError('Validation mask not found for image ' + val_image_path + x)\n",
        "    if os.path.exists(val_sector_count_path + x) == False:\n",
        "        raise NameError('Validation sector count mask not found for image ' + val_image_path + x)\n",
        "\n",
        "for file in my_val_masks:\n",
        "    x = os.path.basename(file)\n",
        "    #print(mask_path + x)\n",
        "    if os.path.exists(val_image_path + x) == False:\n",
        "        raise NameError('Validation image not found for mask ' + val_mask_path + x)\n",
        "    if os.path.exists(val_sector_count_path + x) == False:\n",
        "        raise NameError('Validation sector count mask not found for mask ' + val_mask_path + x)\n",
        "\n",
        "for file in my_val_sector_counts:\n",
        "    x = os.path.basename(file)\n",
        "    #print(mask_path + x)\n",
        "    if os.path.exists(val_image_path + x) == False:\n",
        "        raise NameError('Validation image not found for sector count mask ' + val_sector_count_path + x)\n",
        "    if os.path.exists(val_mask_path + x) == False:\n",
        "        raise NameError('Validation mask not found for sector count mask ' + val_sector_count_path + x)\n",
        "\n",
        "#file_list = os.listdir(root + '/images/*.png')\n",
        "print('Image locations checked and grouped.')\n",
        "\n",
        "  # What the above does is this:\n",
        "  # my_images and my_masks are the training images and correspodning training masks respectively.\n",
        "  # my_val_images and my_val_masks are the validation images and validation masks respectively.\n",
        "  # This checks to see if all the images and masks have corresponding pairs.\n",
        "  # If this part results in an error, do not continue until the error is resolved.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C0ym5zrdgmKK"
      },
      "source": [
        "# Same as above, but no sector count masks are provided\n",
        "Use this if you do not have sector counts masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3KmRbcdgnlL"
      },
      "outputs": [],
      "source": [
        "# Images for Training and validation\n",
        "\n",
        "# Get paths of training and validation sets\n",
        "\n",
        "train_path = image_folder + '/train'\n",
        "val_path = image_folder + '/val'\n",
        "\n",
        "image_path = train_path + '/images/'\n",
        "mask_path = train_path + '/masks/'\n",
        "#sector_count_path = train_path + '/masks_sector_counts/'\n",
        "#mask_boundary_path = train_path + '/masks_bw_boundary/'\n",
        "val_image_path = val_path + '/images/'\n",
        "val_mask_path = val_path + '/masks/'\n",
        "#val_sector_count_path = val_path + '/masks_sector_counts/'\n",
        "#val_mask_boundary_path = val_path + '/masks_bw_boundary/'\n",
        "\n",
        "print(image_path)\n",
        "\n",
        "# Get names of training images and masks\n",
        "\n",
        "# images and masks are png files with the same names\n",
        "\n",
        "my_images = glob.glob(image_path + '*.png')\n",
        "my_masks = glob.glob(mask_path + '*.png')\n",
        "#my_sector_counts = glob.glob(sector_count_path + '*.png')\n",
        "my_val_images = glob.glob(val_image_path + '*.png')\n",
        "my_val_masks = glob.glob(val_mask_path + '*.png')\n",
        "#my_val_sector_counts = glob.glob(val_sector_count_path + '*.png')\n",
        "\n",
        "#print(len(my_images))\n",
        "#print(len(my_masks))\n",
        "\n",
        "# Check that list length is the same\n",
        "if len(my_images) != len(my_masks):\n",
        "    raise ValueError('The number of images in the train subdirectories are inconsistent.  Check that the numbe of images is the same in all train subdirectories.')\n",
        "\n",
        "if len(my_val_images) != len(my_val_masks):\n",
        "    raise ValueError('The number of images in the val subdirectories are inconsistent.  Check that the number of images is the same in all val subdirectories.')\n",
        "\n",
        "\n",
        "# Check that all images used have the (image, mask, sector_count) tuple.\n",
        "\n",
        "for file in my_images:\n",
        "    x = os.path.splitext(os.path.basename(file))[0]\n",
        "    #print(x)\n",
        "    #print(mask_path + x)\n",
        "    #print(mask_path + x)\n",
        "    if os.path.exists(mask_path + x + '.png') == False:\n",
        "        raise NameError('Training mask not found for image ' + image_path + x)\n",
        "    # if os.path.exists(sector_count_path + x) == False:\n",
        "    #     raise NameError('Training sector count mask not found for image ' + image_path + x)\n",
        "\n",
        "for file in my_masks:\n",
        "    x = os.path.splitext(os.path.basename(file))[0]\n",
        "    #print(mask_path + x)\n",
        "    if os.path.exists(image_path + x + '.png') == False:\n",
        "        raise NameError('Training image not found for mask ' + mask_path + x)\n",
        "    # if os.path.exists(sector_count_path + x) == False:\n",
        "    #     raise NameError('Training sector count mask not found for mask ' + mask_path + x)\n",
        "\n",
        "# for file in my_sector_counts:\n",
        "#     x = os.path.basename(file)\n",
        "#     #print(mask_path + x)\n",
        "#     if os.path.exists(image_path + x) == False:\n",
        "#         raise NameError('Training image not found for sector count mask ' + sector_count_path + x)\n",
        "#     if os.path.exists(mask_path + x) == False:\n",
        "#         raise NameError('Training mask not found for sector count mask ' + sector_count_path + x)\n",
        "\n",
        "# Get names of validation images and masks\n",
        "\n",
        "for file in my_val_images:\n",
        "    x = os.path.splitext(os.path.basename(file))[0]\n",
        "    #print(mask_path + x)\n",
        "    if os.path.exists(val_mask_path + x + '.png') == False:\n",
        "        raise NameError('Validation mask not found for image ' + val_image_path + x)\n",
        "    # if os.path.exists(val_sector_count_path + x) == False:\n",
        "    #     raise NameError('Validation sector count mask not found for image ' + val_image_path + x)\n",
        "\n",
        "for file in my_val_masks:\n",
        "    x = os.path.splitext(os.path.basename(file))[0]\n",
        "    #print(mask_path + x)\n",
        "    if os.path.exists(val_image_path + x + '.png') == False:\n",
        "        raise NameError('Validation image not found for mask ' + val_mask_path + x)\n",
        "    # if os.path.exists(val_sector_count_path + x) == False:\n",
        "    #     raise NameError('Validation sector count mask not found for mask ' + val_mask_path + x)\n",
        "\n",
        "# for file in my_val_sector_counts:\n",
        "#     x = os.path.basename(file)\n",
        "#     #print(mask_path + x)\n",
        "#     if os.path.exists(val_image_path + x) == False:\n",
        "#         raise NameError('Validation image not found for sector count mask ' + val_sector_count_path + x)\n",
        "#     if os.path.exists(val_mask_path + x) == False:\n",
        "#         raise NameError('Validation mask not found for sector count mask ' + val_sector_count_path + x)\n",
        "\n",
        "#file_list = os.listdir(root + '/images/*.png')\n",
        "print('Image locations checked and grouped.')\n",
        "\n",
        "  # What the above does is this:\n",
        "  # my_images and my_masks are the training images and correspodning training masks respectively.\n",
        "  # my_val_images and my_val_masks are the validation images and validation masks respectively.\n",
        "  # This checks to see if all the images and masks have corresponding pairs.\n",
        "  # If this part results in an error, do not continue until the error is resolved.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROCdty_DS9jl"
      },
      "source": [
        "# Build U-Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlHqp2qG_ObI"
      },
      "source": [
        "## Look at summary of U-Net leyers and define callback functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QNKyy65N_bUL"
      },
      "outputs": [],
      "source": [
        "# See summary for a 1024x1024x3 image\n",
        "model = build_unet((1024,1024,3),3)\n",
        "model.summary()\n",
        "\n",
        "# This function is not used in the paper\n",
        "def my_schedule(epoch, lr):\n",
        "    if ((epoch % 10) == 0) and (epoch != 0):\n",
        "        print('Reducing learning rate by factor of 10.  New learning rate is', lr*0.1)\n",
        "        return lr * 0.1\n",
        "    else:\n",
        "        return lr\n",
        "\n",
        "class MyCallback(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        print('Getting test segmentations.')\n",
        "        # Load test images and predict with model\n",
        "\n",
        "        # Image a (mostly cured + sectored example)\n",
        "        x = read_image(real_image_folder + '/' + image_to_test_with)\n",
        "        p = model.predict(np.expand_dims(x,axis=0))[0]\n",
        "        p = np.argmax(p,axis=-1)\n",
        "        p = np.expand_dims(p,axis=-1)\n",
        "        p = p * (255/(num_classes-1))\n",
        "        p = p.astype(np.uint8)\n",
        "        my_image = PIL.Image.fromarray(np.squeeze(p, axis=-1), \"L\")\n",
        "        my_image.save(test_per_epoch_folder + '/a_' + str(epoch) + '.png')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lis9Al-N_xbz"
      },
      "source": [
        "## Build U-Net, set parameters for training and set which callbacks to use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TLVycbtIAEkt"
      },
      "outputs": [],
      "source": [
        "# Compile model\n",
        "model = build_unet(shape, num_classes)\n",
        "\n",
        "# used in paper\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr), metrics=['accuracy']) \n",
        "\n",
        "# Not used in paper\n",
        "#model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(lr), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n",
        "\n",
        "# Set up function that gathers the images\n",
        "train_dataset = tf_dataset(my_images, my_masks, batch = batch_size)\n",
        "val_dataset = tf_dataset(my_val_images, my_val_masks, batch = batch_size)\n",
        "\n",
        "# Estimate how many batches of data are need to complete 1 epoch\n",
        "train_steps = len(my_images)//batch_size\n",
        "val_steps = len(my_val_images)//batch_size\n",
        "\n",
        "# Set callbacks during the training process\n",
        "if print_test_segs == True:\n",
        "\n",
        "    # Includes the functions defined in the previous cell for printing a segmentation of specific test image at each epoch\n",
        "    # Save model weights at each epoch, only keeping the best weights\n",
        "    # Learning rate decreases upon reaching a local minimum in validation loss\n",
        "    # Training stops automatically when validation loss does not decrease any more than 0.001 after 5 epochs\n",
        "    # Training will stop automatically after reaching the maximum number of epochs \n",
        "    callbacks = [\n",
        "                ModelCheckpoint(weights_folder + '/' + weights_file + '.h5', verbose=1, save_best_model=True, save_weights_only=False),\n",
        "                MyCallback(),\n",
        "                LearningRateScheduler(my_schedule),\n",
        "                ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=min_lr),\n",
        "                EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=5, verbose=1)\n",
        "    ]\n",
        "else:\n",
        "    # Save model weights at each epoch, only keeping the best weights\n",
        "    # Learning rate decreases upon reaching a local minimum in validation loss\n",
        "    # Training stops automatically when validation loss does not decrease any more than 0.001 after 5 epochs\n",
        "    # Training will stop automatically after reaching the maximum number of epochs \n",
        "    callbacks = [\n",
        "                ModelCheckpoint(weights_folder + '/' + weights_file + '.h5', verbose=1, save_best_model=True, save_weights_only=False),\n",
        "                ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=min_lr),\n",
        "                EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=5, verbose=1)\n",
        "    ]\n",
        "\n",
        "\n",
        "# For training up until the maxmum number of epochs specified\n",
        "# callbacks = [\n",
        "#              ModelCheckpoint(weights_folder + '/' + weights_file + '.h5', verbose=1, save_best_model=True, save_weights_only=False),\n",
        "#              ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-8)\n",
        "# ]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Msa8JJN6sp0b"
      },
      "source": [
        "# Training a new U-Net only!\n",
        "Only run this block if you are trying to obtain a new set of weights for U-Net.  Otherwise previous training results may be lost in the output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qzEic0OSsvG2"
      },
      "outputs": [],
      "source": [
        "# If you have a trained model, load it first to continue training at this checkpoint\n",
        "# Haven't set up to resume training yet.\n",
        "#model = tf.keras.models.load_model(\"/content/gdrive/My Drive/Colab Notebooks/U-Net/data_30/model_classes_3_mixed.h5\")\n",
        "\n",
        "\n",
        "# IF YOU ENABLED TRAINING, THEN RUN THE CODE SNIPPET BELOW.  IF NOT, THIS BLOCK WILL BE SKIPPED.\n",
        "\n",
        "if train_model == True:\n",
        "    # train the model\n",
        "    history = model.fit(train_dataset,\n",
        "            steps_per_epoch=train_steps,\n",
        "            validation_data=val_dataset,\n",
        "            validation_steps=val_steps,\n",
        "            epochs=epochs,\n",
        "            callbacks=callbacks)\n",
        "    print(history.history.keys())\n",
        "\n",
        "    \n",
        "\n",
        "    # Plot the results of training\n",
        "    # This code was taken from https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n",
        "\n",
        "    # summarize history for accuracy\n",
        "    plt.plot(history.history['categorical_accuracy'])\n",
        "    plt.plot(history.history['val_categorical_accuracy'])\n",
        "    plt.title('Model Accuracy on Synthetic Images')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training', 'Validation'], loc='center right')\n",
        "    plt.show()\n",
        "\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss on Synthetic Images')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training', 'Validation'], loc='center right')\n",
        "    plt.show()\n",
        "\n",
        "    file_handle = open(weights_folder + '/accuracy_loss_' + str(num_classes) + '.pkl','wb')\n",
        "    pickle.dump([history.history['categorical_accuracy'], history.history['val_categorical_accuracy'], history.history['loss'], history.history['val_loss']], file_handle)\n",
        "    file_handle.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vjc6RlTA-crB"
      },
      "outputs": [],
      "source": [
        "if train_model == True:\n",
        "\n",
        "    # summarize history for accuracy\n",
        "    plt.plot(history.history['categorical_accuracy'])\n",
        "    plt.plot(history.history['val_categorical_accuracy'])\n",
        "    plt.title('Model Accuracy on Synthetic Images')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training', 'Validation'], loc='best')\n",
        "    plt.show()\n",
        "\n",
        "    # summarize history for loss\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('Model Loss on Synthetic Images')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Training', 'Validation'], loc='best')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ai1eixofc6IZ"
      },
      "source": [
        "# Load a trained U-Net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVQHmb6wTvxe"
      },
      "outputs": [],
      "source": [
        "# This uses the value of \"weights_file\" specified near the beginning of the script\n",
        "model = tf.keras.models.load_model(weights_folder + '/' + weights_file + '.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UjkI5i8MsEGS"
      },
      "source": [
        "# TRAINING Image Segmentation and Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get locations of training and validation images\n",
        "Always run this"
      ],
      "metadata": {
        "id": "mVrxpuFvfDYd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_images_train = sorted(glob.glob(training_image_set + '/' + '*'))\n",
        "training_images_val = sorted(glob.glob(validation_image_set + '/' + '*'))\n",
        "training_images = sorted(training_images_train + training_images_val)\n",
        "print('Number of images found: ' + str(len(training_images)))"
      ],
      "metadata": {
        "id": "T69LqSIdfB2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GjGz7R9qsEGV"
      },
      "source": [
        "## Segment training images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0sH97-wrsEGX"
      },
      "outputs": [],
      "source": [
        "# Code for image segmentation (involves Python and Octave code (requires oct2py module))\n",
        "# 1. Python - Ready U-Net for input.\n",
        "# 2. Python - Feed image to U-Net.\n",
        "# 3. Python - Get output segmentation of image.\n",
        "\n",
        "# 4. Octave - Use isolated colonies to estimate a range of radii to search for circular colonies.\n",
        "# 5. Octave - Obtain centers and radii in image with circle Hough transform (imfindcircles).\n",
        "# 6. Octave (and then Python) - Save csv files of circle locations and sizes in each image respectively.\n",
        "\n",
        "# 7. Python (matplotlib) - Make mask of image showing where the circles are found.\n",
        "# 8. Repeat steps 2-7 for each image\n",
        "\n",
        "if get_training_segs == True:\n",
        "\n",
        "    %matplotlib inline\n",
        "\n",
        "     # For eahc training image\n",
        "    for this_image in training_images:\n",
        "\n",
        "        # Steps 1-3: get output segmentation and save it\n",
        "\n",
        "        this_plate = pathlib.PurePath(this_image)\n",
        "        plate_name = this_plate.name\n",
        "\n",
        "        print('Reading plate: ' + str(plate_name))\n",
        "\n",
        "        x = read_image(this_image)\n",
        "        \n",
        "        # Predict the class of each pixel, and partition output the same way\n",
        "        p = model.predict(np.expand_dims(x,axis=0))[0]\n",
        "        p = np.argmax(p,axis=-1)\n",
        "        p = np.expand_dims(p,axis=-1)\n",
        "        p = p * (255/(num_classes-1))\n",
        "        p = p.astype(np.int32)\n",
        "\n",
        "\n",
        "        p_full = tf.identity(p).numpy()\n",
        "        in_class = tf.math.greater(tf.constant(p_full), tf.constant([0])).numpy()\n",
        "\n",
        "        p = p.astype(np.uint8)\n",
        "        # white pixels (should be 255)\n",
        "        p_1 = tf.math.equal(tf.constant(p_full), tf.constant([255])).numpy().astype(np.uint8) * 255\n",
        "        # red pixels (should be 127)\n",
        "        p_2 = tf.math.equal(tf.constant(p_full), tf.constant([127])).numpy().astype(np.uint8) * 255\n",
        "        p_full = 255 * in_class.astype(np.uint8)\n",
        "        #print(p.shape)\n",
        "\n",
        "        #cv2_imshow(p)\n",
        "        \n",
        "        # Show and/or save image\n",
        "        #plt.imshow(p * 255/(num_classes-1))\n",
        "        #cv2.cvtColor(p * 255/(num_classes-1), cv2.COLOR_BGR2RGB)\n",
        "        #plt.imshow(cv2.cvtColor(p * 255/(num_classes-1), cv2.COLOR_BGR2GRAY))\n",
        "        #plt.imshow(p, cmap='binary')\n",
        "        #plt.show()\n",
        "        #print(np.unique(p[20:40, 900:920]))\n",
        "        my_image = PIL.Image.fromarray(np.squeeze(p, axis=-1), \"L\")\n",
        "        #display(my_image.resize((256,256)))\n",
        "        my_image.save(train_seg_folder + '/' + this_plate.stem + '.png')\n",
        "\n",
        "\n",
        "        # Steps 4-6: Run Matlab code in Octave to use CHT, and store colony location data\n",
        "\n",
        "        octave.feval('get_circular_data.m', this_image, train_seg_folder + '/' + this_plate.stem + '.png', train_circle_data_folder)\n",
        "        try:\n",
        "            radii_table = pd.read_csv(train_circle_data_folder + '/' + this_plate.stem + '.csv', header=None)\n",
        "            radii_table.columns = ['Colony', 'Center (x)', 'Center (y)', 'Radius', 'Top Left (x)', 'Top Left (y)', 'Width', 'Height', 'Estimated Center (x)', 'Estimated Center (y)']\n",
        "            radii_table.to_csv(train_circle_data_folder + '/' + this_plate.stem + '.csv')\n",
        "\n",
        "            # Step 7: Plot the image with the circles overlayed, and save it\n",
        "            #radii_table = pd.read_csv(test_circle_data_folder + '/' + this_plate.stem + '.csv')\n",
        "\n",
        "            fig, ax = plt.subplots()\n",
        "            ax.imshow(cv2.cvtColor(x, cv2.COLOR_BGR2RGB))\n",
        "            fig.set_size_inches(1024/96, 1024/96)\n",
        "            for index, row in radii_table.iterrows():\n",
        "                full_circle = Circle((row['Estimated Center (x)'], row['Estimated Center (y)']), radius=row['Radius'], color='blue', fill=False, linewidth=1, alpha=0.9)\n",
        "                ax.add_patch(full_circle)\n",
        "            plt.axis('off')\n",
        "            fig.savefig(train_circle_folder + '/' + pathlib.Path(this_image).stem + '.jpg', bbox_inches='tight', pad_inches=0)\n",
        "            plt.close()\n",
        "\n",
        "\n",
        "        except pd.errors.EmptyDataError:\n",
        "            # If an error is about to be thrown due to an empty csv file, run these lines instead\n",
        "            # An empty file means no colonies were detected\n",
        "            # We still would like to ensure a file with this name exists for later.\n",
        "            print('No colonies were detected.  Skipping this image.')\n",
        "            my_table_columns = ['Colony', 'Center (x)', 'Center (y)', 'Radius', 'Top Left (x)', 'Top Left (y)', 'Width', 'Height', 'Estimated Center (x)', 'Estimated Center (y)']\n",
        "            radii_table = pd.DataFrame(columns=my_table_columns)\n",
        "            radii_table.to_csv(train_circle_data_folder + '/' + this_plate.stem + '.csv')\n",
        "\n",
        "            # Step 7: Plot the image with the circles overlayed, and save it\n",
        "            #radii_table = pd.read_csv(test_circle_data_folder + '/' + this_plate.stem + '.csv')\n",
        "\n",
        "            #pylab.ioff()\n",
        "            fig, ax = plt.subplots()\n",
        "            ax.imshow(cv2.cvtColor(x, cv2.COLOR_BGR2RGB))\n",
        "            fig.set_size_inches(1024/96, 1024/96) # set because the small screen pixel size is 96 dpi\n",
        "            plt.axis('off')\n",
        "            fig.savefig(train_circle_folder + '/' + pathlib.Path(this_image).stem + '.jpg', bbox_inches='tight', pad_inches=0)\n",
        "            plt.close()\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get the names of the images segmented and their circle detections"
      ],
      "metadata": {
        "id": "-WWazVlOh54B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_CHT_images = sorted(glob.glob(train_circle_folder + '/' + '*'))\n",
        "\n",
        "print('Number of images found: ' + str(len(train_CHT_images)))\n",
        "\n",
        "train_image_pairs = tuple(zip(training_images, train_CHT_images))\n",
        "print(train_image_pairs)\n",
        "\n",
        "# Create reference table for plate names, and store it as a csv file in the main annotation directory\n",
        "file_dict = {}\n",
        "for this_plate_number in range(1, len(training_images)+1):\n",
        "    this_plate = pathlib.PurePath(training_images[this_plate_number - 1])\n",
        "    plate_name = this_plate.name\n",
        "    plate_stem = os.path.splitext(plate_name)[0]\n",
        "    file_dict[plate_name] = 'Plate ' + str(this_plate_number)\n",
        "print(file_dict)\n",
        "file_items = file_dict.items()\n",
        "file_list = list(file_items)\n",
        "file_df = pd.DataFrame(file_items, columns = ['Plate Name', 'Folder Name'])\n",
        "print(file_df)"
      ],
      "metadata": {
        "id": "CrC9Ma2eiGto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Classify colonies in training images"
      ],
      "metadata": {
        "id": "8Wuh9xAOkK3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code for colony classification (this should be all python code)\n",
        "# 1. Read in image and corresponding segmentation.\n",
        "# 2. Read in csv files containg circle locations.\n",
        "# 3. For each row in the csv file, crop out the circular region, estimate size.\n",
        "# 4. Restrict data collection to pixels within the circle detected, exclusing all other pixels.\n",
        "# 5. Split the components of the image into red, white and background.\n",
        "# 6. Get boundary components of the colony, check for consistency.\n",
        "# 7. Output predicted number of sectors and their sizes after the consistency check.\n",
        "# 8. Save the cropping of the colony in a few ways:\n",
        "#   - the raw colony\n",
        "#   - the raw colony with circle overlayed\n",
        "#   - the segmentation of the colony within the circular region\n",
        "#   - the segmentation of the colony with lines drawn on the image to repreent sector borders\n",
        "#   - the predicted sector like regions, where each sector is a different shade of gray.\n",
        "#   - similar to the previous, but keeping pixels classified only as red pixels.\n",
        "#   - the segmentation that is corrected following the consistency check (possibly doing an additional check on the white pixels)\n",
        "# 9. Save data on the colony itself, including the sector information, to a row in a table.\n",
        "# 10. Save the table to a csv file.\n",
        "# 11. Repeat all steps above for each image.\n",
        "\n",
        "# Issues to work on:\n",
        "# Verify that the purity metric is properly being utilized\n",
        "# Figure out what to do with the holes inside colony segmentations.\n",
        "#   -- A hole has its own boundary, so could look for the boundary of the hole.\n",
        "#   -- The boundary of the hole MUST be smaller than the boundary of the entire colony\n",
        "#   -- Find all connected compoents of the boundary, then exclude the LARGEST one.\n",
        "#   -- For all other boundary components, these are expected to be the holes.  You need a procedure to fill them.\n",
        "#   -- The procedure could be as simple as filling the hole with the class pertaining to the most common pixel on the boundary.\n",
        "\n",
        "# Implementation already existing:\n",
        "\n",
        "\n",
        "\n",
        "if classify_training_colonies == True:\n",
        "\n",
        "    %matplotlib inline\n",
        "\n",
        "    starting_image = True\n",
        "\n",
        "    # if use_expert_counts == True:\n",
        "    #     dot_quant_images = sorted(glob.glob(additional_data_folder + '/Quant/' + '*'))\n",
        "    #     dot_state_images = sorted(glob.glob(additional_data_folder + '/State/' + '*'))\n",
        "\n",
        "\n",
        "    # Run each plate through the classification pipeline\n",
        "\n",
        "    for (train_image, CHT_image) in train_image_pairs:\n",
        "\n",
        "        # Get plate name \n",
        "        this_plate = pathlib.PurePath(train_image)\n",
        "        plate_name = this_plate.name\n",
        "        plate_stem = os.path.splitext(plate_name)[0]\n",
        "\n",
        "        print('Plate: ' + str(plate_name) + ':')\n",
        "        # if save_all_annotations == True:\n",
        "        #     print('Annotations will be saved within subfolders named ' + \"\\'\" + file_dict[plate_name] + \"\\'\")\n",
        "\n",
        "        # Read images of the plate\n",
        "        x = read_image(train_image)\n",
        "        x_CHT = read_image(CHT_image)\n",
        "\n",
        "        # initialize lists for storing values\n",
        "        all_cropped_colonies = []\n",
        "\n",
        "        # Sizes of regions in pixels\n",
        "        white_region_sum = []\n",
        "        red_region_sum = []\n",
        "        colony_region_sum = []\n",
        "        sector_region_sum = []\n",
        "\n",
        "        corrected_white_region_sum = []\n",
        "        corrected_red_region_sum = []\n",
        "        corrected_sector_region_sum = []\n",
        "\n",
        "        true_white_region_sum = []\n",
        "        true_red_region_sum = []\n",
        "        true_colony_region_sum = []\n",
        "        true_sector_region_sum = []\n",
        "\n",
        "        # Counting sectors\n",
        "        initial_region_counts = []\n",
        "        all_sector_counts = []\n",
        "        true_sector_counts = []\n",
        "\n",
        "        \n",
        "\n",
        "        boundary_region_sum = []\n",
        "        colony_prop_sum = []\n",
        "\n",
        "        # Purity scores for regions and colonies\n",
        "        average_sector_score = []\n",
        "        average_sector_iou = []\n",
        "\n",
        "        weighted_sector_score_before = []\n",
        "        weighted_red_sector_score_before = []\n",
        "        weighted_white_sector_score_before = []\n",
        "\n",
        "        weighted_sector_score_after = []\n",
        "        weighted_red_sector_score_after = []\n",
        "        weighted_white_sector_score_after = []\n",
        "\n",
        "        # Bounding box info for colonies in images\n",
        "        sides_vert_top = [];\n",
        "        sides_vert_bottom = [];\n",
        "        sides_horz_left = [];\n",
        "        sides_horz_right = [];\n",
        "\n",
        "        # Test lists\n",
        "        colony_is_connected = []\n",
        "        colony_is_approx_connected = []\n",
        "        boundary_is_connected = []\n",
        "        colony_is_whole = []\n",
        "        boundary_is_hamilton = []\n",
        "        colony_is_approx_convex = []\n",
        "        colony_is_approx_circular = []\n",
        "        hausdorff_dist_convex = []\n",
        "        hausdorff_dist_circle = []\n",
        "\n",
        "        # Lists to store purity scores of each region and the color of the region\n",
        "        region_purity_before = []\n",
        "        region_color_before = []\n",
        "        region_sizes_before = []\n",
        "\n",
        "        weighted_purity_before = []\n",
        "        weighted_purity_red_before = []\n",
        "        weighted_purity_white_before = []\n",
        "\n",
        "        region_purity_after = []\n",
        "        region_color_after = []\n",
        "        region_sizes_after = []\n",
        "\n",
        "        weighted_purity_after = []\n",
        "        weighted_purity_red_after = []\n",
        "        weighted_purity_white_after = []\n",
        "\n",
        "        cured_colony_before = []\n",
        "        cured_colony_after = []\n",
        "\n",
        "        stable_colony_before = []\n",
        "        stable_colony_after = []\n",
        "\n",
        "        # Load images here if using quantifable colony data/annotations\n",
        "        # if use_expert_counts == True:\n",
        "        #     x_quant = read_image(additional_data_folder + '/Quant/' + plate_stem + '.tif')\n",
        "        #     x_state = read_image(additional_data_folder + '/State/' + plate_stem + '.tif')\n",
        "        #     quantifiable_colony = []\n",
        "        #     quantifiable_cured = []\n",
        "        #     quantifiable_stable = []\n",
        "        #     quantifiable_sectored = []\n",
        "\n",
        "        #------------------------------\n",
        "        # Read in plate and locate colonies\n",
        "        #------------------------------\n",
        "        \n",
        "        # Read the segmentation of the plate, and keep track of which class each pixel belongs to\n",
        "        p = read_mask(train_seg_folder + '/' + this_plate.stem + '.png')\n",
        "        #p = read_mask(main_folder + '/Test Segs/' + specific_test_folder + '/Class_3/' + this_plate.stem + '.png')\n",
        "\n",
        "        p_full = tf.identity(p).numpy()\n",
        "        in_class = tf.math.greater(tf.constant(p_full), tf.constant([0])).numpy()\n",
        "\n",
        "        p = p.astype(np.uint8)\n",
        "        # white pixels\n",
        "        p_1 = tf.math.equal(tf.constant(p_full), tf.constant([255])).numpy().astype(np.uint8) * 255\n",
        "        # red pixels\n",
        "        p_2 = tf.math.equal(tf.constant(p_full), tf.constant([127])).numpy().astype(np.uint8) * 255\n",
        "        p_full = 255 * in_class.astype(np.uint8)\n",
        "\n",
        "        # Gather the location and radii data from the colonies\n",
        "        # If there are no colonies detected, or there is no table, skip this section at once\n",
        "\n",
        "        colony_locations = pd.read_csv(train_circle_data_folder + '/' + pathlib.Path(train_image).stem + '.csv')\n",
        "        #colony_locations = pd.read_csv(main_folder + '/Test Segs CHT Data/' + specific_test_folder + '/Class_3/' + pathlib.Path(test_image).stem + '.csv')\n",
        "\n",
        "        # Output information from the imported csv\n",
        "        print(str(len(colony_locations[\"Radius\"])) + ' colonies found using circle Hough transform')\n",
        "        plate_names = np.repeat(plate_name, len(colony_locations[\"Radius\"]))\n",
        "        colony_numbers = np.array(range(len(colony_locations[\"Radius\"])))\n",
        "\n",
        "        #---------------------------------------------------------------------\n",
        "\n",
        "        # CLASSIFICATION PIPELINE START\n",
        "        # Pre-processing step\n",
        "\n",
        "        # Images to save:\n",
        "        # - Cropping of the colony\n",
        "        # - Cropping of the colony with the overalyed circle\n",
        "        # - Original colony segmentation, such that only the pixels inside the overlayed circle are considered.\n",
        "\n",
        "        for this_index in range(0,len(colony_numbers)):\n",
        "\n",
        "            print('')\n",
        "            print('Colony ' + str(this_index))\n",
        "            # get example image using bounding indices\n",
        "            #this_index = 2\n",
        "\n",
        "            # Copy location data from colony image\n",
        "            top_left_x = colony_locations[\"Top Left (x)\"][this_index]\n",
        "            top_left_y = colony_locations[\"Top Left (y)\"][this_index]\n",
        "            box_width = colony_locations[\"Width\"][this_index]\n",
        "            box_height = colony_locations[\"Height\"][this_index]\n",
        "\n",
        "            # Store the locations in another set of lists\n",
        "            sides_vert_top.append(top_left_y)\n",
        "            sides_vert_bottom.append(top_left_y + box_height - 1)\n",
        "            sides_horz_left.append(top_left_x)\n",
        "            sides_horz_right.append(top_left_x + box_width - 1)\n",
        "\n",
        "            # Grab segmentation of colony using coordinates copied above\n",
        "            # The colony image is NOT a boolean array\n",
        "            colony_image = p[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1)]\n",
        "            ellipse_array = create_filled_ellipse_in_array(colony_image)\n",
        "            colony_image = np.multiply(colony_image, ellipse_array) # unpadded segmentation with the pixels inside the overlayed circle\n",
        "\n",
        "            # if use_expert_counts == True:\n",
        "            #     quant_image = x_quant[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1), :]\n",
        "            #     state_image = x_state[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1), :]\n",
        "\n",
        "            # The colony mask IS a boolean array.  Keep all the pixels of each class.\n",
        "            white_colony_mask = p_1[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1)] > 0\n",
        "            red_colony_mask = p_2[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1)] > 0 \n",
        "            colony_mask = np.logical_or(white_colony_mask, red_colony_mask) # sanity check to see of this is the same as colony image\n",
        "\n",
        "            # Add segmentation of the pixels inside the circular region of detection, and apply the mask.  This ensures we only use the pixels inside the circle for analysis.\n",
        "            # Booleans are inputs, and booleans are outputs\n",
        "            # Force a circle in colonies detected in the circle detection step\n",
        "            white_colony_mask = np.multiply(white_colony_mask, ellipse_array)\n",
        "            red_colony_mask = np.multiply(red_colony_mask, ellipse_array)\n",
        "            colony_mask = np.logical_or(white_colony_mask, red_colony_mask)\n",
        "\n",
        "            # Get initial measure of the sizes of the red and white regions of the colony\n",
        "            white_region_sum.append(np.sum(white_colony_mask))\n",
        "            red_region_sum.append(np.sum(red_colony_mask))\n",
        "            colony_region_sum.append(np.sum(colony_mask))\n",
        "            sector_region_sum.append(np.sum(red_colony_mask) / np.sum(colony_mask))\n",
        "\n",
        "            # Find colony boundaries, ensuring that the boundaries are ON the colony, not ADJACENT to it.\n",
        "            edge_mask_unpadded = get_colony_boundary_binary(colony_image) # The function is above\n",
        "            interior_mask_unpadded = np.logical_xor(colony_image > 0, edge_mask_unpadded) # Second mask containing only the interior pixels of the segmentation\n",
        "            interior_colony = np.multiply(colony_image, interior_mask_unpadded) # This is NOT a boolean\n",
        "\n",
        "            # #---------------------------------------------------------------\n",
        "            # # Get quantifiable colony labels (if applicable)\n",
        "            # #---------------------------------------------------------------\n",
        "\n",
        "            # # If we have locations of quantifiable colonies, use this to gather the colonies.\n",
        "            # if use_expert_counts == True:\n",
        "            #     #----------------------------------\n",
        "            #     # Determine where the quantifiable colonies are (they have black dots on them)\n",
        "            #     # Set color boundaries for the markers in the counted images\n",
        "            #     black_dot_boundaries = [([0, 0, 0], [5, 5, 5])]\n",
        "\n",
        "            #     for (lower, upper) in black_dot_boundaries:\n",
        "            #     # create NumPy arrays from the boundaries\n",
        "            #         lower = np.array(lower, dtype = \"uint8\")\n",
        "            #         upper = np.array(upper, dtype = \"uint8\")\n",
        "            #         # find the colors within the specified boundaries and apply\n",
        "            #         # the mask\n",
        "            #         dot_mask = cv2.inRange((quant_image*255).astype(np.uint8), lower, upper)\n",
        "            #         #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n",
        "            #         # Get connected components of the detected pixels\n",
        "            #         black_labels = label(dot_mask)\n",
        "            #         num_black_labels = len(np.unique(black_labels))\n",
        "            #         if num_black_labels <= 1:\n",
        "            #             # No dot was detected.  Thus the colony was considered non-quantifiable.\n",
        "            #             colony_is_quantifiable = False\n",
        "            #         else:\n",
        "            #             # Loop through each component.  Find one component that is not too small and is directly on the colony\n",
        "            #             colony_center_y = (quant_image.shape[0] - 1) / 2.0\n",
        "            #             colony_center_x = (quant_image.shape[1] - 1) / 2.0\n",
        "            #             for this_comp in range(1, num_black_labels):\n",
        "            #                 this_dot_comp = black_labels == this_comp\n",
        "            #                 # Get centroid of component\n",
        "            #                 (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(this_dot_comp)\n",
        "            #                 dot_dist = math.sqrt(((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n",
        "            #                 if dot_dist < colony_locations[\"Radius\"][this_index]:\n",
        "            #                     colony_is_quantifiable = True\n",
        "            #                     break\n",
        "            #                     # end the loop, as we found a dot on the colony\n",
        "                            \n",
        "            #                 if this_comp == (num_black_labels - 1):\n",
        "            #                     # We looped through all the dots, but none of them were on the colony.  Don't analyze this colony.\n",
        "            #                     colony_is_quantifiable = False\n",
        "\n",
        "            #     quantifiable_colony.append(colony_is_quantifiable)\n",
        "\n",
        "            #     #print('Colony', this_index, ': Quantifiable:', colony_is_quantifiable)\n",
        "\n",
        "            #     #----------------------------------------\n",
        "            #     # Determine if colony is cured, stable, or sectored\n",
        "\n",
        "            #     # RGB version\n",
        "            #     # cured_dot_boundaries = [([34-5, 177-5, 76-5], [34+5, 177+5, 76+5])]\n",
        "            #     # stable_dot_boundaries = [([237-5, 28-5, 36-5], [237+5, 28+5, 36+5])]\n",
        "            #     # sectored_dot_boundaries = [([63-5, 72-5, 204-5], [63+5, 72+5, 204+5])]\n",
        "\n",
        "            #     # BGR version (cv2 needs this)\n",
        "            #     # Marker colors were manaully chosen, so info below is based on that.\n",
        "            #     # Wes annotations\n",
        "            #     cured_dot_boundaries = [([76-5, 177-5, 34-5], [76+5, 177+5, 34+5])]\n",
        "            #     stable_dot_boundaries = [([36-5, 28-5, 237-5], [36+5, 28+5, 237+5])]\n",
        "            #     sectored_dot_boundaries = [([204-5, 72-5, 63-5], [204+5, 72+5, 63+5])]\n",
        "\n",
        "            #     # Nicole annotations\n",
        "            #     # cured_dot_boundaries = [([0, 250, 0], [0, 255, 0])]\n",
        "            #     # stable_dot_boundaries = [([0, 0, 250], [0, 0, 255])]\n",
        "            #     # sectored_dot_boundaries = [([250, 250, 0], [255, 255, 0])]\n",
        "\n",
        "            #     # cured_dot_boundaries = [([0, 250, 0], [0, 255, 0])]\n",
        "            #     # stable_dot_boundaries = [([0, 0, 250], [0, 0, 255])]\n",
        "            #     # sectored_dot_boundaries = [([250, 0, 0], [255, 0, 0])]\n",
        "\n",
        "            #     for (lower, upper) in cured_dot_boundaries:\n",
        "            #     # create NumPy arrays from the boundaries\n",
        "            #         lower = np.array(lower, dtype = \"uint8\")\n",
        "            #         upper = np.array(upper, dtype = \"uint8\")\n",
        "            #         # find the colors within the specified boundaries and apply\n",
        "            #         # the mask\n",
        "            #         #print(np.unique((colony_image*255).astype(np.uint8)))\n",
        "            #         dot_mask = cv2.inRange((state_image*255).astype(np.uint8), lower, upper)\n",
        "            #         #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n",
        "            #         # Get connected components of the detected dot pixels\n",
        "            #         #print(np.unique(dot_mask))\n",
        "            #         cured_labels = label(dot_mask)\n",
        "            #         num_cured_labels = len(np.unique(cured_labels))\n",
        "            #         if num_cured_labels <= 1:\n",
        "            #             # No dot was detected.  Thus the colony was considered non-quantifiable.\n",
        "            #             colony_is_cured = False\n",
        "            #         else:\n",
        "            #             # Loop through each component.  Find one component that is not too small and is directly on the colony\n",
        "            #             colony_center_y = (state_image.shape[0] - 1) / 2.0\n",
        "            #             colony_center_x = (state_image.shape[1] - 1) / 2.0\n",
        "            #             for this_comp in range(1, num_cured_labels):\n",
        "            #                 this_dot_comp = cured_labels == this_comp\n",
        "            #                 # Get centroid of component\n",
        "            #                 (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(this_dot_comp)\n",
        "            #                 dot_dist = math.sqrt(((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n",
        "            #                 if dot_dist < colony_locations[\"Radius\"][this_index]:\n",
        "            #                     colony_is_cured = True\n",
        "            #                     break\n",
        "            #                     # end the loop, as we found a dot on the colony\n",
        "                            \n",
        "            #                 if this_comp == (num_cured_labels - 1):\n",
        "            #                     # We looped through all the dots, but none of them were on the colony.  Don't analyze this colony.\n",
        "            #                     colony_is_cured = False\n",
        "\n",
        "            #     quantifiable_cured.append(colony_is_cured)\n",
        "\n",
        "            #     #print('Colony', this_index, ': Cured:', colony_is_cured)\n",
        "\n",
        "\n",
        "            #     for (lower, upper) in stable_dot_boundaries:\n",
        "            #     # create NumPy arrays from the boundaries\n",
        "            #         lower = np.array(lower, dtype = \"uint8\")\n",
        "            #         upper = np.array(upper, dtype = \"uint8\")\n",
        "            #         # find the colors within the specified boundaries and apply\n",
        "            #         # the mask\n",
        "            #         #print(np.unique((colony_image*255).astype(np.uint8)))\n",
        "            #         dot_mask = cv2.inRange((state_image*255).astype(np.uint8), lower, upper)\n",
        "            #         #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n",
        "            #         # Get connected components of the detected pixels\n",
        "            #         #print(np.unique(dot_mask))\n",
        "            #         stable_labels = label(dot_mask)\n",
        "            #         num_stable_labels = len(np.unique(stable_labels))\n",
        "            #         if num_stable_labels <= 1:\n",
        "            #             # No dot was detected.  Thus the colony was considered non-quantifiable.\n",
        "            #             colony_is_stable = False\n",
        "            #         else:\n",
        "            #             # Loop through each component.  Find one component that is not too small and is directly on the colony\n",
        "            #             colony_center_y = (state_image.shape[0] - 1) / 2.0\n",
        "            #             colony_center_x = (state_image.shape[1] - 1) / 2.0\n",
        "            #             for this_comp in range(1, num_stable_labels):\n",
        "            #                 this_dot_comp = stable_labels == this_comp\n",
        "            #                 # Get centroid of component\n",
        "            #                 (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(this_dot_comp)\n",
        "            #                 dot_dist = math.sqrt(((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n",
        "            #                 if dot_dist < colony_locations[\"Radius\"][this_index]:\n",
        "            #                     colony_is_stable = True\n",
        "            #                     break\n",
        "            #                     # end the loop, as we found a dot on the colony\n",
        "                            \n",
        "            #                 if this_comp == (num_stable_labels - 1):\n",
        "            #                     # We looped through all the dots, but none of them were on the colony.  Don't analyze this colony.\n",
        "            #                     colony_is_stable = False\n",
        "\n",
        "            #     quantifiable_stable.append(colony_is_stable)\n",
        "\n",
        "            #     #print('Colony', this_index, ': Stable:', colony_is_stable)\n",
        "\n",
        "\n",
        "            #     for (lower, upper) in sectored_dot_boundaries:\n",
        "            #     # create NumPy arrays from the boundaries\n",
        "            #         lower = np.array(lower, dtype = \"uint8\")\n",
        "            #         upper = np.array(upper, dtype = \"uint8\")\n",
        "            #         # find the colors within the specified boundaries and apply\n",
        "            #         # the mask\n",
        "            #         #print(np.unique((colony_image*255).astype(np.uint8)))\n",
        "            #         dot_mask = cv2.inRange((state_image*255).astype(np.uint8), lower, upper)\n",
        "            #         #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n",
        "            #         # Get connected components of the detected pixels\n",
        "            #         #print(np.unique(dot_mask))\n",
        "            #         sectored_labels = label(dot_mask)\n",
        "            #         num_sectored_labels = len(np.unique(sectored_labels))\n",
        "            #         if num_sectored_labels <= 1:\n",
        "            #             # No dot was detected.  Thus the colony was considered non-quantifiable.\n",
        "            #             colony_is_sectored = False\n",
        "            #         else:\n",
        "            #             # Loop through each component.  Find one component that is not too small and is directly on the colony\n",
        "            #             colony_center_y = (state_image.shape[0] - 1) / 2.0\n",
        "            #             colony_center_x = (state_image.shape[1] - 1) / 2.0\n",
        "            #             for this_comp in range(1, num_sectored_labels):\n",
        "            #                 this_dot_comp = sectored_labels == this_comp\n",
        "            #                 # Get centroid of component\n",
        "            #                 (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(this_dot_comp)\n",
        "            #                 dot_dist = math.sqrt(((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n",
        "            #                 if dot_dist < colony_locations[\"Radius\"][this_index]:\n",
        "            #                     colony_is_sectored = True\n",
        "            #                     break\n",
        "            #                     # end the loop, as we found a dot on the colony\n",
        "                            \n",
        "            #                 if this_comp == (num_sectored_labels - 1):\n",
        "            #                     # We looped through all the dots, but none of them were on the colony.  Don't analyze this colony.\n",
        "            #                     colony_is_sectored = False\n",
        "\n",
        "            #     quantifiable_sectored.append(colony_is_sectored)\n",
        "\n",
        "            #     #print('Colony', this_index, ': Sectored:', colony_is_sectored)\n",
        "\n",
        "\n",
        "            #     #----------------------------------\n",
        "\n",
        "            #-----------------------------------------------------\n",
        "            # Get connectedness properties of the segmentation\n",
        "            #-----------------------------------------------------\n",
        "\n",
        "            # Use this information to test whether the segmentation meets the conditions\n",
        "\n",
        "            # Condition 1 test: is the segmentation one connected component?\n",
        "            condition_1_test_strong, condition_1_test_weak = check_components_of_colony(colony_mask)\n",
        "            colony_is_connected.append(condition_1_test_strong)\n",
        "            colony_is_approx_connected.append(condition_1_test_weak)\n",
        "            #print('Condition 1: Seg is one component: ' + str(condition_1_test_strong))\n",
        "            #print(\"Condition 1: Seg is \\'approximately\\' one component: \" + str(condition_1_test_weak))\n",
        "\n",
        "            # Condition 2 test: Is the boundary one connected component?\n",
        "            condition_2_test = check_components_of_boundary(edge_mask_unpadded)\n",
        "            boundary_is_connected.append(condition_2_test)\n",
        "            #print('Condition 2: Boundary is one component: ' + str(condition_2_test))\n",
        "\n",
        "            # Condition 3 test: Are there holes in the segmentation?\n",
        "            condition_3_test = check_for_holes(colony_mask, edge_mask_unpadded)\n",
        "            colony_is_whole.append(condition_3_test)\n",
        "            #print('Condition 3: Segmentation has no holes: ' + str(condition_3_test))\n",
        "\n",
        "            # Condition 4 test: Is the boundary a Hamiltonian cycle? (no ready yet)\n",
        "            #condition_4_test = get_hamilton_cycle(colony_mask, edge_mask_unpadded)\n",
        "            #print('Has Hamiltonian cycle: ' + str(condition_4_test))\n",
        "\n",
        "            # Condition 5: Check circularity and convexity\n",
        "            condition_5_convex, condition_5_circular = compare_convex_hull(colony_mask, edge_mask_unpadded)\n",
        "            colony_is_approx_convex.append(condition_5_convex)\n",
        "            colony_is_approx_circular.append(condition_5_circular)\n",
        "            #print('Condition 5: Segmentation is approximately convex: ' + str(condition_5_convex))\n",
        "            #print('Condition 5: Segmentation is approximately circular: ' + str(condition_5_circular))\n",
        "\n",
        "            # Condition 6: Check hausdorff distance\n",
        "            hausdorff_chull, hausdorff_circle = get_hausdorff_distance(colony_mask, edge_mask_unpadded)\n",
        "            hausdorff_dist_convex.append(hausdorff_chull)\n",
        "            hausdorff_dist_circle.append(hausdorff_circle)\n",
        "            #print('Condition 6: Hausdorff distance between boundary and convex hull: ' + str(hausdorff_chull))\n",
        "            #print('Condition 6: Hausdorff distance between boundary and circle: ' + str(hausdorff_circle))\n",
        "\n",
        "            #----------------------------------------\n",
        "            # Partition the boundaries into red and white components\n",
        "\n",
        "            # Get 'ideal' boundary of the colony\n",
        "            ideal_circle = create_circle_boundary(edge_mask_unpadded, colony_locations[\"Radius\"][this_index])\n",
        "\n",
        "            # Find connected components of the red and white pixels found on the boundary\n",
        "            red_boundary_skeleton, white_boundary_skeleton, boundary_mask_h, boundary_mask_w = get_boundary_partitions(red_colony_mask, white_colony_mask, edge_mask_unpadded)\n",
        "\n",
        "            #plt.imshow(red_boundary_skeleton)\n",
        "            #plt.title('Red Boundary Skeleton')\n",
        "\n",
        "            # Save the three images using this data\n",
        "            #   - Oringinal image padded\n",
        "            #   - CHT image padded\n",
        "            #   - Segmentation padded\n",
        "            # Force a circle like previously\n",
        "            padded_x = 255 * x[max((top_left_y-1)-image_padding, 0):min((top_left_y + box_height - 1)+image_padding, H-1), max((top_left_x-1) - image_padding, 0):min((top_left_x + box_width - 1)+image_padding, W-1), :]\n",
        "            padded_x_CHT = 255 * x_CHT[max((top_left_y-1)-image_padding, 0):min((top_left_y + box_height - 1)+image_padding, H-1), max((top_left_x-1) - image_padding, 0):min((top_left_x + box_width - 1)+image_padding, W-1), :]\n",
        "            padded_mask = p[max((top_left_y-1)-image_padding, 0):min((top_left_y + box_height - 1)+image_padding, H-1), max((top_left_x-1) - image_padding, 0):min((top_left_x + box_width - 1)+image_padding, W-1)]\n",
        "            ellipse_array_2 = create_filled_ellipse_in_array(padded_mask, padding = image_padding)\n",
        "            padded_mask = np.multiply(padded_mask, ellipse_array_2)\n",
        "\n",
        "            # Save the colony images as previously\n",
        "            # if save_all_annotations == True:\n",
        "            #     if not cv2.imwrite(output_crops_folder + '/raw/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.jpg', padded_x):\n",
        "            #         raise Exception('Could not write image.')\n",
        "            #     if not cv2.imwrite(output_crops_folder + '/circles/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.jpg', padded_x_CHT):\n",
        "            #         raise Exception('Could not write image.')\n",
        "            #     if not cv2.imwrite(output_crops_folder + '/segs/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', padded_mask):\n",
        "            #         raise Exception('Could not write image.')\n",
        "\n",
        "            # # Save the croppings for individual colonies which were annotated\n",
        "            #     if use_expert_counts == True:\n",
        "            #         padded_x_count = 255 * x_quant[max((top_left_y-1)-image_padding, 0):min((top_left_y + box_height - 1)+image_padding, H-1), max((top_left_x-1) - image_padding, 0):min((top_left_x + box_width - 1)+image_padding, W-1), :]\n",
        "            #         if not cv2.imwrite(output_crops_folder + '/counted/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', padded_x_count):\n",
        "            #             raise Exception('Could not write image.')\n",
        "            #-------------------------------------------------------------\n",
        "\n",
        "            # CLASSIFICATION STEP BEGINS\n",
        "            # GET INITIAL REGIONAL BREAKDOWN AND RED REGION ANNOTATIONS OF THE COLONY\n",
        "\n",
        "            # Should store information about the following:\n",
        "            #   - Idealized red and white regions\n",
        "            #   - The boundaries of each red and white region\n",
        "            #   - The sizes of each region\n",
        "            #   - The purity scores of each region\n",
        "            #   - the states of each colony (cured, stable)\n",
        "\n",
        "            # Images to save in this section\n",
        "            # - Regional segmentation\n",
        "            # - Boundary of the colony\n",
        "            # - Red region boundary annotation\n",
        "            # - Regions that fail consistency check\n",
        "\n",
        "            # Plot padded version of the initial segmentation.  Annotations will be saved onto the image.\n",
        "            colony_image_padded = np.pad(colony_image, 5)\n",
        "            fig1, ax1 = plt.subplots()\n",
        "            ax1.imshow(colony_image_padded, cmap='gray')\n",
        "\n",
        "\n",
        "            recheck_boundaries = True # initialized to true so that we can look at show each step of the pipeline is performing\n",
        "\n",
        "            # Using boundary information, find and extract potential red and white regions of the colony\n",
        "\n",
        "            red_labels = label(red_boundary_skeleton)\n",
        "            white_labels = label(white_boundary_skeleton)\n",
        "\n",
        "            # Initialize masks separating potential red and white regions\n",
        "            initial_red_region_mask = np.zeros_like(red_boundary_skeleton)\n",
        "            initial_white_region_mask = np.zeros_like(white_boundary_skeleton)\n",
        "            initial_red_boundary_mask = np.zeros_like(red_boundary_skeleton)\n",
        "            initial_white_boundary_mask = np.zeros_like(white_boundary_skeleton)\n",
        "\n",
        "            # keep track of regions which fail the consistency check\n",
        "            initial_bad_red_score_mask = np.zeros_like(red_boundary_skeleton)\n",
        "            initial_bad_white_score_mask = np.zeros_like(white_boundary_skeleton)\n",
        "\n",
        "            # Keep track of boundaries whihc fail the consistency check\n",
        "            boundary_correction = np.zeros_like(red_boundary_skeleton)\n",
        "\n",
        "            # Initialize lists to store characteristics about each region\n",
        "            # This includes endpoints on the sector, the purity of the sector, and an indicator for the purity being above the 50 percent threshold\n",
        "            red_component_endpoints = []\n",
        "            red_component_scores = []\n",
        "            red_component_checks = []\n",
        "            red_component_sizes = []\n",
        "\n",
        "            white_component_endpoints = []\n",
        "            white_component_scores = []\n",
        "            white_component_checks = []\n",
        "            white_component_sizes = []\n",
        "\n",
        "            # How many boundaries of each color are there?\n",
        "            num_red_boundaries = len(np.unique(red_labels)[1:]) # number of red boundaries present\n",
        "            num_white_boundaries = len(np.unique(white_labels)[1:]) # number of white boundaries present\n",
        "\n",
        "            # Initial count of the number of sectors is the number of red boundaries\n",
        "            initial_region_counts.append(num_red_boundaries)\n",
        "\n",
        "            # States can be initialy predicted using the number of red and white boundaries\n",
        "            #if ((num_red_boundaries == 1) & (num_white_boundaries == 0)):\n",
        "            if (num_white_boundaries == 0):\n",
        "                cured_colony_before.append(True)\n",
        "            else:\n",
        "                cured_colony_before.append(False)\n",
        "\n",
        "            #if ((num_red_boundaries == 0) & (num_white_boundaries == 1)):\n",
        "            if (num_red_boundaries == 0):\n",
        "                stable_colony_before.append(True)\n",
        "            else:\n",
        "                stable_colony_before.append(False)\n",
        "\n",
        "            # Now, to analyze each of the regions to determine if they are sectored\n",
        "\n",
        "            # Analyze the initial red regions of the colony\n",
        "            for this_label in np.unique(red_labels)[1:]:\n",
        "                red_component = copy.deepcopy(red_labels)\n",
        "                red_component = red_component == this_label\n",
        "                red_component = red_component.astype(np.int32)\n",
        "\n",
        "                # Append the red boundary pixels on this component to the red boundary mask\n",
        "                initial_red_boundary_mask = np.logical_or(initial_red_boundary_mask, red_component > 0)\n",
        "\n",
        "                # Function to get endpoints of connected component\n",
        "                full_endpoints_list = get_boundary_component_endpoints(colony_image[:,:], red_component)\n",
        "\n",
        "                # If exactly two points are found, then everything's good.\n",
        "\n",
        "                # Get the angle of the endpoints relative to the colony center\n",
        "                [endpoint_angles, endpoint_locations, endpoints_x, endpoints_y] = get_endpoint_locations(full_endpoints_list, colony_mask, colony_locations[\"Radius\"][this_index])\n",
        "\n",
        "                # Function to get mask representing sector boundary\n",
        "                sector_boundary, sector_interior, sector_filled = get_sector_masks(red_component, full_endpoints_list)\n",
        "\n",
        "                # Append the predicted filled region to the red region mask\n",
        "                initial_red_region_mask = np.logical_or(initial_red_region_mask, sector_filled)\n",
        "\n",
        "                # Apply consistency check to score the region\n",
        "                confirm_check, prop_interior = check_for_consistency_2(sector_filled, red_colony_mask)\n",
        "\n",
        "                # Update score mask to denote where the consistency check failed\n",
        "                if confirm_check == False:\n",
        "                    recheck_boundaries = True\n",
        "                    initial_bad_red_score_mask = np.logical_or(initial_bad_red_score_mask, sector_filled)\n",
        "\n",
        "                # Append scores and info to lists\n",
        "                red_component_endpoints.append(full_endpoints_list) # endpoints of the connected compponent on the boundary\n",
        "                red_component_scores.append(prop_interior) # purity score of the region\n",
        "                red_component_checks.append(confirm_check) # whether the purity score was at least 0.5\n",
        "                red_component_sizes.append(np.sum(initial_red_region_mask)) # the number of pixels in the region\n",
        "                \n",
        "                # # ---ANNOTATION PROCEDURE---\n",
        "\n",
        "                # # Plot the lines of the sector (and the boundary line) onto the colony segmentation\n",
        "                # length_points = len(endpoints_x)\n",
        "                # #print(length_points)\n",
        "                # #print(endpoints_x)\n",
        "                # if len(np.unique(red_labels)[1:]) > 0: # only plots lines if there are divided regions\n",
        "                #     plot_bounds_x = []\n",
        "                #     plot_bounds_y = []\n",
        "                #     plot_bounds_x.append(endpoints_x[0] + image_padding)\n",
        "                #     plot_bounds_y.append(endpoints_y[0] + image_padding)\n",
        "                #     # Get list of center and endpoints on the boundary\n",
        "                #     for this_bound in range(0, length_points-1):\n",
        "                #         plot_bounds_x.append(endpoints_x[this_bound+1] + image_padding)\n",
        "                #         plot_bounds_y.append(endpoints_y[this_bound+1] + image_padding)\n",
        "                #         #plt.plot(plot_points_y, plot_points_x, color='blue')\n",
        "                #         #print(endpoints_x[0:2])\n",
        "                #         #print(endpoints_y[0:2])\n",
        "                #     plot_bounds_x = np.roll(np.array(plot_bounds_x), 1)\n",
        "                #     plot_bounds_y = np.roll(np.array(plot_bounds_y), 1)\n",
        "                #     #print(plot_bounds_x)\n",
        "                #     #print(plot_bounds_y)\n",
        "                #     line_style = ':' if (len(plot_bounds_x) == 2) else '-'\n",
        "                #     ax1.plot(plot_bounds_y, plot_bounds_x, linewidth=5, linestyle=line_style, alpha=0.85)\n",
        "                #     if len(plot_bounds_x) == 1:\n",
        "                #         full_circle = Circle((plot_bounds_y, plot_bounds_x), radius=colony_locations[\"Radius\"][this_index], color='blue', fill=False, linewidth=5, alpha=0.85)\n",
        "                #         ax1.add_patch(full_circle)\n",
        "\n",
        "\n",
        "            # Do the same for the white regions\n",
        "            for this_label in np.unique(white_labels)[1:]:\n",
        "                white_component = copy.deepcopy(white_labels)\n",
        "                white_component = white_component == this_label\n",
        "                white_component = white_component.astype(np.int32)\n",
        "\n",
        "                initial_white_boundary_mask = np.logical_or(initial_white_boundary_mask, white_component > 0)\n",
        "\n",
        "                # Function to get endpoints of connected component\n",
        "                full_endpoints_list = get_boundary_component_endpoints(colony_image[:,:], white_component)\n",
        "\n",
        "                # If exactly two points are found, then everything's good.\n",
        "\n",
        "                # Function to get mask representing sector boundary\n",
        "                sector_boundary, sector_interior, sector_filled = get_sector_masks(white_component, full_endpoints_list)\n",
        "\n",
        "                # Fill initial region mask with the filled sector\n",
        "                initial_white_region_mask = np.logical_or(initial_white_region_mask, sector_filled)\n",
        "\n",
        "                # Apply consistency check to score region\n",
        "                confirm_check, prop_interior = check_for_consistency_2(sector_filled, white_colony_mask)\n",
        "\n",
        "                # Update score mask to denote where the consistency check failed\n",
        "                if confirm_check == False:\n",
        "                    recheck_boundaries = True\n",
        "                    initial_bad_white_score_mask = np.logical_or(initial_bad_white_score_mask, sector_filled)\n",
        "\n",
        "                # Append scores and info to lists\n",
        "                white_component_endpoints.append(full_endpoints_list)\n",
        "                white_component_scores.append(prop_interior)\n",
        "                white_component_checks.append(confirm_check)\n",
        "                white_component_sizes.append(np.sum(initial_white_region_mask))\n",
        "\n",
        "            # At this point, you should have two masks, one for the red and white regions respectivey.\n",
        "            # You should also have the endponts of each component, stored as a collection of lists, one list per component\n",
        "            # Finally, you should have a score for those components\n",
        "\n",
        "            # -------------------------------------\n",
        "            # Store the purity scores in a sublist, along with a second sublist indicating the color of each region\n",
        "            # -------------------------------------\n",
        "\n",
        "            all_component_scores = []\n",
        "            all_region_colors = []\n",
        "            all_region_sizes = []\n",
        "\n",
        "            if not red_component_scores:\n",
        "                all_region_colors = all_region_colors + ['red']\n",
        "                all_component_scores = all_component_scores + [np.nan]\n",
        "                all_region_sizes = all_region_sizes + [np.nan]\n",
        "            else:\n",
        "                all_region_colors = all_region_colors + (['red'] * len(red_component_scores))\n",
        "                all_component_scores = all_component_scores + red_component_scores\n",
        "                all_region_sizes = all_region_sizes + red_component_sizes\n",
        "\n",
        "            if not white_component_scores:\n",
        "                all_region_colors = all_region_colors + ['white']\n",
        "                all_component_scores = all_component_scores + [np.nan]\n",
        "                all_region_sizes = all_region_sizes + [np.nan]\n",
        "            else:\n",
        "                all_region_colors = all_region_colors + (['white'] * len(white_component_scores))\n",
        "                all_component_scores = all_component_scores + white_component_scores\n",
        "                all_region_sizes = all_region_sizes + white_component_sizes\n",
        "\n",
        "            region_purity_before.append(all_component_scores)\n",
        "            region_color_before.append(all_region_colors)\n",
        "            region_sizes_before.append(all_region_sizes)\n",
        "\n",
        "            # -------------------------------------\n",
        "            # Do the same for the weighted purity scores across the entire colony\n",
        "            # -------------------------------------\n",
        "\n",
        "            # Compute weighted purity scores over all regions, for white only, and for red only\n",
        "\n",
        "            total_red_sum = np.nansum(red_component_sizes)\n",
        "            total_white_sum = np.nansum(white_component_sizes)\n",
        "\n",
        "            if not red_component_scores:\n",
        "                red_region_weights = np.array([0])\n",
        "                weighted_red_scores = np.array([0])\n",
        "            else:\n",
        "                red_region_weights = np.divide(np.array(red_component_sizes), total_red_sum) # this vector should add to 1, as this is a normalization of the weights\n",
        "                weighted_red_scores = np.multiply(np.array(red_component_scores), red_region_weights)\n",
        "\n",
        "            if not white_component_scores:\n",
        "                white_region_weights = np.array([0])\n",
        "                weighted_white_scores = np.array([0])\n",
        "            else:\n",
        "                white_region_weights = np.divide(np.array(white_component_sizes), total_white_sum) # this vector should add to 1, as this is a normalization of the weights\n",
        "                weighted_white_scores = np.multiply(np.array(white_component_scores), white_region_weights)\n",
        "\n",
        "            # Get weighted average over both regions together\n",
        "            all_region_sum = np.nansum(all_region_sizes)\n",
        "            all_region_weights = np.divide(np.array(red_component_sizes + white_component_sizes), all_region_sum)\n",
        "            all_region_weighted_scores = np.multiply(np.array(red_component_scores + white_component_scores), all_region_weights)\n",
        "\n",
        "            weighted_purity_red_before.append(list(weighted_red_scores))\n",
        "            weighted_purity_white_before.append(list(weighted_white_scores))\n",
        "            weighted_purity_before.append(list(all_region_weighted_scores))\n",
        "            weighted_red_sector_score_before.append(np.nansum(weighted_red_scores))\n",
        "            weighted_white_sector_score_before.append(np.nansum(weighted_white_scores))\n",
        "            weighted_sector_score_before.append(np.nansum(all_region_weighted_scores))\n",
        "\n",
        "            # Now, create the masks containing the initial_regions\n",
        "            initial_region_mask = np.maximum(initial_red_region_mask.astype(np.uint8), 2*initial_white_region_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            initial_boundary_mask = np.maximum(initial_red_boundary_mask.astype(np.uint8), 2*initial_white_boundary_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            initial_score_mask = np.maximum(initial_bad_red_score_mask.astype(np.uint8), 2*initial_bad_white_score_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "\n",
        "            # Make sure to pad them in the same way as the output segmentation\n",
        "            initial_region_mask = np.pad(initial_region_mask, image_padding)\n",
        "            initial_boundary_mask = np.pad(initial_boundary_mask, image_padding)\n",
        "            initial_score_mask = np.pad(initial_score_mask, image_padding)\n",
        "\n",
        "            # # Save the initial region and boundary mask.  Also save image indicating regions which should be investigted further.\n",
        "            # if save_all_annotations == True:\n",
        "            #     if not cv2.imwrite(output_crops_folder + '/init_regions/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', initial_region_mask):\n",
        "            #         raise Exception('Could not write image.')\n",
        "            #     if not cv2.imwrite(output_crops_folder + '/init_bounds/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', initial_boundary_mask):\n",
        "            #         raise Exception('Could not write image.')\n",
        "            #     if not cv2.imwrite(output_crops_folder + '/init_bad/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', initial_score_mask):\n",
        "            #         raise Exception('Could not write image.')\n",
        "            plt.axis('off')\n",
        "            # if save_all_annotations == True:\n",
        "            #     fig1.savefig(output_crops_folder + '/init_partitions/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', bbox_inches='tight', pad_inches=0)\n",
        "            plt.close(fig1);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            #------------------------------------------------------------------\n",
        "\n",
        "            # CLASS SWITCH/MERGING STEP\n",
        "\n",
        "            # This is only applied to regions where the consistency check fails.\n",
        "            # i.e. less than 50% of pixels in the predicted region are of the same class\n",
        "            # as the outer boundary pixels\n",
        "\n",
        "            # The process will repeat until all regions pass the consisency check\n",
        "\n",
        "            # NOTE: This section is only executed if one of either the red or\n",
        "            # white regions estimated above, fails the constency check.\n",
        "            # If all regions predicted are consistent in class, the below will\n",
        "            # not execute, as it will do exactly the same stuff as just done above.\n",
        "\n",
        "            # Therefore, this section is purposely redundant and helps us keep\n",
        "            # track of which regions are being updated.\n",
        "\n",
        "\n",
        "\n",
        "            repetition_counter = 0\n",
        "            performing_correction = False # initialize at the beginning\n",
        "\n",
        "            while recheck_boundaries == True:\n",
        "\n",
        "                recheck_boundaries = False # reset.\n",
        "                repetition_counter = repetition_counter + 1\n",
        "\n",
        "                # The above should be switched back to True if there is a potentially misclassified boundary\n",
        "\n",
        "\n",
        "                # Find the connected components of the skeleton.\n",
        "                # The number of red connected components gives the initial number of sectors.\n",
        "                # The number of white connected components are the regions separating the red sectors.\n",
        "                # A score for sectoriness will be applied to both sets of regions.\n",
        "                red_labels = label(red_boundary_skeleton)\n",
        "                white_labels = label(white_boundary_skeleton)\n",
        "\n",
        "                # Initialize masks separating potential red and white regions\n",
        "                red_region_mask = np.zeros_like(red_boundary_skeleton)\n",
        "                white_region_mask = np.zeros_like(white_boundary_skeleton)\n",
        "                red_boundary_mask = np.zeros_like(red_boundary_skeleton)\n",
        "                white_boundary_mask = np.zeros_like(white_boundary_skeleton)\n",
        "                red_score_mask = np.zeros_like(red_boundary_skeleton)\n",
        "                white_score_mask = np.zeros_like(white_boundary_skeleton)\n",
        "\n",
        "                # Intialize array to change boundary.\n",
        "                # This is only updated when there is a potentially misclassified boundary.\n",
        "                boundary_correction_red = np.zeros_like(red_boundary_skeleton)\n",
        "                boundary_correction_white = np.zeros_like(white_boundary_skeleton)\n",
        "\n",
        "                # Generate regions directly from segmentation\n",
        "                # Iterate through each component and collect some information\n",
        "                # Collect info about component endpoints and purity scores\n",
        "                red_component_endpoints = []\n",
        "                red_component_scores = []\n",
        "                red_component_checks = []\n",
        "\n",
        "                white_component_endpoints = []\n",
        "                white_component_scores = []\n",
        "                white_component_checks = []\n",
        "\n",
        "               # print('Number of red components: ' + str(max(np.unique(red_labels)[1:])))\n",
        "\n",
        "                # Iterate through the red components\n",
        "                for this_label in np.unique(red_labels)[1:]:\n",
        "                    #print('Running the red check.')\n",
        "                    red_component = copy.deepcopy(red_labels)\n",
        "                    red_component = red_component == this_label\n",
        "                    red_component = red_component.astype(np.int32)\n",
        "\n",
        "                    red_boundary_mask = np.logical_or(red_boundary_mask, red_component > 0)\n",
        "\n",
        "                    # Function to get endpoints of connected component\n",
        "                    full_endpoints_list = get_boundary_component_endpoints(colony_image[:,:], red_component)\n",
        "\n",
        "                    # If exactly two points are found, then everything's good.\n",
        "\n",
        "                    # Function to get mask representing sector boundary\n",
        "                    sector_boundary, sector_interior, sector_filled = get_sector_masks(red_component, full_endpoints_list)\n",
        "\n",
        "                    # Fill initial region mask with the filled sector\n",
        "                    red_region_mask = np.logical_or(red_region_mask, sector_filled)\n",
        "\n",
        "                    # Apply consistency check to score region\n",
        "                    confirm_check, prop_interior = check_for_consistency_2(sector_filled, red_colony_mask)\n",
        "\n",
        "                    # Update score mask to denote where the consistency check failed\n",
        "                    if confirm_check == False:\n",
        "                        #performing_correction = True # This signifies that boundary information will be different from the initial breakdown\n",
        "                        recheck_boundaries = True\n",
        "                        boundary_correction_red = np.logical_or(boundary_correction_red, red_component)\n",
        "\n",
        "\n",
        "                    # Append scores and info to lists\n",
        "                    red_component_endpoints.append(full_endpoints_list)\n",
        "                    red_component_scores.append(prop_interior)\n",
        "                    red_component_checks.append(confirm_check)\n",
        "\n",
        "                \n",
        "                # Do the same for the white components\n",
        "                for this_label in np.unique(white_labels)[1:]:\n",
        "\n",
        "                    white_component = copy.deepcopy(white_labels)\n",
        "                    white_component = white_component == this_label\n",
        "                    white_component = white_component.astype(np.int32)\n",
        "\n",
        "                    white_boundary_mask = np.logical_or(white_boundary_mask, white_component > 0)\n",
        "\n",
        "                    # Function to get endpoints of connected component\n",
        "                    full_endpoints_list = get_boundary_component_endpoints(colony_image[:,:], white_component)\n",
        "\n",
        "                    # If exactly two points are found, then everything's good.\n",
        "\n",
        "                    # Function to get mask representing sector boundary\n",
        "                    sector_boundary, sector_interior, sector_filled = get_sector_masks(white_component, full_endpoints_list)\n",
        "\n",
        "                    # Fill initial region mask with the filled sector\n",
        "                    white_region_mask = np.logical_or(white_region_mask, sector_filled)\n",
        "\n",
        "                    # Apply consistency check to score region\n",
        "                    confirm_check, prop_interior = check_for_consistency_2(sector_filled, white_colony_mask)\n",
        "\n",
        "                    # Update score mask to denote where the consistency check failed\n",
        "                    if confirm_check == False:\n",
        "                        #performing_correction = True # This signifies that boundary information will be different from the initial breakdown\n",
        "                        recheck_boundaries = True\n",
        "                        boundary_correction_white = np.logical_or(boundary_correction_white, white_component)\n",
        "\n",
        "                    # Append scores and info to lists\n",
        "                    white_component_endpoints.append(full_endpoints_list)\n",
        "                    white_component_scores.append(prop_interior)\n",
        "                    white_component_checks.append(confirm_check)\n",
        "\n",
        "                # If there were regions that failed the consistency check, swap the classes on the boundary\n",
        "                if recheck_boundaries == True:\n",
        "\n",
        "                    performing_correction = True # This signifies that boundary information will be different from the initial breakdown\n",
        "\n",
        "                    # Run the swap functions\n",
        "                    red_boundary_skeleton = grow_boundary(red_boundary_skeleton, boundary_correction_white) # takes the bad white boundaries and switches them to the red class\n",
        "                    red_boundary_skeleton = shrink_boundary(red_boundary_skeleton, boundary_correction_red) # removes the bad red boundaries\n",
        "\n",
        "                    white_boundary_skeleton = grow_boundary(white_boundary_skeleton, boundary_correction_red) # takes the bad red boundaries and switches them to the white class\n",
        "                    white_boundary_skeleton = shrink_boundary(white_boundary_skeleton, boundary_correction_white) # removes the bad white boundaries\n",
        "\n",
        "                # Only run the block below if this colony cannot be analyzed appropriatly with this pipeline (may be an awful segmentation)\n",
        "                if repetition_counter > 20:\n",
        "                    warnings.warn('Corrections have been applied too many times.  The colony segmentation used here is likely unsuitable for this pipeline.')\n",
        "                    break\n",
        "\n",
        "                    # Once the swap is done, you will head back to the top of this while loop.\n",
        "\n",
        "            # At this point, you should have two masks, one for the red and white regions respectivey.\n",
        "            # You should also have the endponts of each components, stored as a collection of lists, one list per component\n",
        "            # Finally, you should have a score for those components\n",
        "\n",
        "            # Now, create the masks containing the regions that pass the consistency check\n",
        "            corrected_region_mask = np.maximum(red_region_mask.astype(np.uint8), 2*white_region_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            corrected_boundary_mask = np.maximum(red_boundary_mask.astype(np.uint8), 2*white_boundary_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "\n",
        "            red_labels = label(red_boundary_skeleton)\n",
        "            white_labels = label(white_boundary_skeleton)\n",
        "\n",
        "            #corrected_boundary_mask = np.maximum((white_labels > 0).astype(np.uint8), 2*((red_labels > 0).astype(np.uint8)))*(255/(num_classes-1))\n",
        "\n",
        "            # Use the corrected boundary_mask to piece together the corrected colony segmentation\n",
        "            corrected_colony_image = np.add(interior_colony, corrected_boundary_mask).astype(np.uint8)\n",
        "            corrected_colony_image_padded = np.pad(corrected_colony_image, image_padding)\n",
        "\n",
        "            # Re-partition the image following correction\n",
        "            corrected_full = tf.identity(corrected_colony_image).numpy().astype(np.int32)\n",
        "            corrected_white_colony_mask = tf.math.equal(tf.constant(corrected_full), tf.constant([255])).numpy().astype(np.uint8)\n",
        "            corrected_red_colony_mask = tf.math.equal(tf.constant(corrected_full), tf.constant([127])).numpy().astype(np.uint8)\n",
        "            corrected_colony_mask = np.logical_or(corrected_white_colony_mask, corrected_red_colony_mask) # sanity check to see of this is the same as colony image\n",
        "\n",
        "\n",
        "            # if performing_correction == True:\n",
        "            #     corrected_region_mask = np.maximum(white_region_mask.astype(np.uint8), 2*red_region_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            #     corrected_boundary_mask = np.maximum(white_boundary_mask.astype(np.uint8), 2*red_boundary_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            #     #score_mask = np.maximum(initial_bad_white_score_mask.astype(np.uint8), 2*initial_bad_red_score_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            # else:\n",
        "            #     corrected_region_mask = np.maximum(initial_white_region_mask.astype(np.uint8), 2*initial_red_region_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            #     corrected_boundary_mask = np.maximum(initial_white_boundary_mask.astype(np.uint8), 2*initial_red_boundary_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "\n",
        "            \n",
        "            #score_mask = np.pad(score_mask, 5)\n",
        "\n",
        "            #--------------------------------------------------\n",
        "            # Get the corrected skeletons, regions, and annotations\n",
        "\n",
        "            # Get boundary information from the boundary corrected/merged segmentation\n",
        "            corrected_red_boundary_skeleton, corrected_white_boundary_skeleton, corrected_boundary_mask_h, corrected_boundary_mask_w = get_boundary_partitions(corrected_red_colony_mask, corrected_white_colony_mask, edge_mask_unpadded)\n",
        "\n",
        "            red_labels = label(corrected_red_boundary_skeleton)\n",
        "            white_labels = label(corrected_white_boundary_skeleton)\n",
        "\n",
        "            corrected_boundary_mask = np.maximum((red_labels > 0).astype(np.uint8), 2*((white_labels > 0).astype(np.uint8)))*(255/(num_classes-1))\n",
        "\n",
        "            # Use the corrected boundary_mask to piece together the corrected colony segmentation\n",
        "            corrected_colony_image = np.add(interior_colony, corrected_boundary_mask).astype(np.uint8)\n",
        "            corrected_colony_image_padded = np.pad(corrected_colony_image, image_padding)\n",
        "\n",
        "            corrected_region_mask = np.maximum(red_region_mask.astype(np.uint8), 2*white_region_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            corrected_boundary_mask = np.maximum(red_boundary_mask.astype(np.uint8), 2*white_boundary_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            #score_mask = np.maximum(initial_bad_white_score_mask.astype(np.uint8), 2*initial_bad_red_score_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "\n",
        "            # Re-partition the image following correction\n",
        "            corrected_full = tf.identity(corrected_colony_image).numpy().astype(np.int32)\n",
        "            corrected_white_colony_mask = tf.math.equal(tf.constant(corrected_full), tf.constant([255])).numpy().astype(np.uint8)\n",
        "            corrected_red_colony_mask = tf.math.equal(tf.constant(corrected_full), tf.constant([127])).numpy().astype(np.uint8)\n",
        "            corrected_colony_mask = np.logical_or(corrected_white_colony_mask, corrected_red_colony_mask) # sanity check to see of this is the same as colony image\n",
        "\n",
        "            \n",
        "\n",
        "            #-------------------------------------------------------------------\n",
        "\n",
        "            # PROCESSING THE CORRECTED REGIONS\n",
        "            # If you got to this point, then the boundaries should be consistent with the interior of the colony.\n",
        "\n",
        "            # Images to save in this section\n",
        "            # - Regional segmentation with the corrected boundary\n",
        "            # - Red region boundary annotation with the corrected boundary\n",
        "            # - Red regions remaining after correction applied\n",
        "\n",
        "            \n",
        "\n",
        "            # initialize masks containing the sector locations\n",
        "            all_sector_bounds = np.zeros_like(colony_mask).astype(np.int32)\n",
        "            all_sector_filled = np.zeros_like(colony_mask).astype(np.int32)\n",
        "            all_sector_filled_labels = np.zeros_like(colony_mask).astype(np.int32)\n",
        "\n",
        "            # Use the corrected boundary_mask to piece together the corrected colony segmentation\n",
        "            # corrected_colony_image = np.add(interior_colony, corrected_boundary_mask).astype(np.uint8)\n",
        "            # corrected_colony_image_padded = np.pad(corrected_colony_image, image_padding)\n",
        "\n",
        "            # # Re-partition the image followng correction\n",
        "            # corrected_full = tf.identity(corrected_colony_image).numpy().astype(np.int32)\n",
        "            # corrected_white_colony_mask = tf.math.equal(tf.constant(corrected_full), tf.constant([127])).numpy().astype(np.uint8)\n",
        "            # corrected_red_colony_mask = tf.math.equal(tf.constant(corrected_full), tf.constant([255])).numpy().astype(np.uint8)\n",
        "            # corrected_colony_mask = np.logical_or(corrected_white_colony_mask, corrected_red_colony_mask) # sanity check to see of this is the same as colony image\n",
        "            #print(np.unique(corrected_colony_image))\n",
        "            #plt.imshow(corrected_colony_mask, cmap='gray')\n",
        "            #raise NameError('Corrected colony mask')\n",
        "\n",
        "            # Save the corrected segmenation\n",
        "            # if save_all_annotations == True:\n",
        "            #     if not cv2.imwrite(output_crops_folder + '/cor_segs/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', corrected_colony_image_padded):\n",
        "            #         raise Exception('Could not write image.')\n",
        "\n",
        "            # # Get boundary information from the corrected segmentation\n",
        "            # corrected_red_boundary_skeleton, corrected_white_boundary_skeleton, corrected_boundary_mask_h, corrected_boundary_mask_w = get_boundary_partitions(corrected_red_colony_mask, corrected_white_colony_mask, edge_mask_unpadded)\n",
        "\n",
        "            # Initialize masks separating potential red and white regions\n",
        "            post_red_region_mask = np.zeros_like(corrected_red_boundary_skeleton)\n",
        "            post_white_region_mask = np.zeros_like(corrected_white_boundary_skeleton)\n",
        "            post_red_boundary_mask = np.zeros_like(corrected_red_boundary_skeleton)\n",
        "            post_white_boundary_mask = np.zeros_like(corrected_white_boundary_skeleton)\n",
        "            post_red_score_mask = np.zeros_like(corrected_red_boundary_skeleton)\n",
        "            post_white_score_mask = np.zeros_like(corrected_white_boundary_skeleton)\n",
        "\n",
        "            # red_labels = label(corrected_red_boundary_skeleton)\n",
        "            # white_labels = label(corrected_white_boundary_skeleton)\n",
        "\n",
        "            # initialize counter for the number of sectors in this colony\n",
        "            total_sectors = 0\n",
        "\n",
        "            # Make copy of colony mask and place sectors on top\n",
        "            #colony_mask_faded = copy.deepcopy(colony_mask).astype(np.uint8)\n",
        "            #colony_mask_faded[colony_mask_faded > 0] = 20\n",
        "\n",
        "            corrected_colony_mask_faded = copy.deepcopy(corrected_colony_mask).astype(np.uint8)\n",
        "            corrected_colony_mask_faded[corrected_colony_mask_faded > 0] = 20\n",
        "\n",
        "            sector_scores = []\n",
        "            sector_ious = []\n",
        "\n",
        "            # Create figure for annotating the corrected colony segmentations.  Annotations will be saved onto the image.\n",
        "            fig2, ax2 = plt.subplots()\n",
        "            ax2.imshow(corrected_colony_image_padded, cmap='gray')\n",
        "\n",
        "            # Compute the scores of the regions one more time.\n",
        "            # All regions should pass the consistency check by this point.  If not, then something is wrong.\n",
        "            red_component_endpoints = []\n",
        "            red_component_scores = []\n",
        "            red_component_checks = []\n",
        "            red_component_sizes = []\n",
        "\n",
        "            white_component_endpoints = []\n",
        "            white_component_scores = []\n",
        "            white_component_checks = []\n",
        "            white_component_sizes = []\n",
        "\n",
        "            num_red_boundaries = len(np.unique(red_labels)[1:]) # number of red boundaries present\n",
        "            num_white_boundaries = len(np.unique(white_labels)[1:]) # number of white boundaries present\n",
        "\n",
        "            #if ((num_red_boundaries == 1) & (num_white_boundaries == 0)):\n",
        "            if (num_white_boundaries == 0):\n",
        "                cured_colony_after.append(True)\n",
        "            else:\n",
        "                cured_colony_after.append(False)\n",
        "\n",
        "            #if ((num_red_boundaries == 0) & (num_white_boundaries == 1)):\n",
        "            if (num_red_boundaries == 0):\n",
        "                stable_colony_after.append(True)\n",
        "            else:\n",
        "                stable_colony_after.append(False)\n",
        "\n",
        "            for this_label in np.unique(red_labels)[1:]:\n",
        "                red_component = copy.deepcopy(red_labels)\n",
        "                red_component = red_component == this_label\n",
        "                red_component = red_component.astype(np.int32)\n",
        "\n",
        "                post_red_boundary_mask = np.logical_or(post_red_boundary_mask, red_component > 0)\n",
        "\n",
        "                # Function to get endpoints of connected component\n",
        "                full_endpoints_list = get_boundary_component_endpoints(corrected_colony_image[:,:], red_component)\n",
        "\n",
        "                # If exactly two points are found, then everything's good.\n",
        "\n",
        "                # Function to get mask representing sector boundary\n",
        "                sector_boundary, sector_interior, sector_filled = get_sector_masks(red_component, full_endpoints_list)\n",
        "\n",
        "                # Fill initial region mask with the filled sector\n",
        "                post_red_region_mask = np.logical_or(post_red_region_mask, sector_filled)\n",
        "\n",
        "                # Apply consistency check to score region\n",
        "                confirm_check, prop_interior = check_for_consistency_2(sector_filled, corrected_red_colony_mask)\n",
        "\n",
        "                # Update score mask to denote where the consistency check failed\n",
        "                if confirm_check == False:\n",
        "                    print('Double check your code.  The red consistency check failed for this colony with score ' + str(prop_interior))\n",
        "                    #raise IOError('Something is wrong with how regions are being scored')\n",
        "\n",
        "                # Append scores and info to lists\n",
        "                red_component_endpoints.append(full_endpoints_list)\n",
        "                red_component_scores.append(prop_interior)\n",
        "                red_component_checks.append(confirm_check)\n",
        "                red_component_sizes.append(np.sum(post_red_region_mask))\n",
        "\n",
        "                # Code for plotting the annotations\n",
        "\n",
        "                # For the consistent sectors, get the angles of the endpoints relative to the center\n",
        "                # colony mask, or any other array with the same size and shape, will work as input as it's only needed for size info\n",
        "                [endpoint_angles, endpoint_locations, endpoints_x, endpoints_y] = get_endpoint_locations(full_endpoints_list, corrected_colony_mask, colony_locations[\"Radius\"][this_index])\n",
        "                #print(endpoints_x)\n",
        "\n",
        "                # Add to mask containg sector locations\n",
        "                #sector_filled = np.logical_or(sector_boundary, sector_interior)\n",
        "                all_sector_bounds = np.logical_or(all_sector_bounds, sector_boundary)\n",
        "                all_sector_filled = np.logical_or(all_sector_filled, sector_filled)\n",
        "                all_sector_filled_labels[sector_filled.astype(bool)] = this_label\n",
        "                total_sectors = total_sectors + 1\n",
        "                corrected_colony_mask_faded[sector_filled.astype(bool)] = 255 / this_label\n",
        "\n",
        "                # Get a score for sectoriness.  We want to be sure we are capturing the entire sector\n",
        "                this_sector_mask = np.logical_and(sector_filled, red_colony_mask)\n",
        "                this_union_mask = np.logical_or(sector_filled, red_colony_mask)\n",
        "                this_sector_score = np.sum(this_sector_mask) / np.sum(sector_filled)\n",
        "                this_sector_iou = np.sum(this_sector_mask) / np.sum(this_union_mask)\n",
        "                sector_scores.append(this_sector_score)\n",
        "                sector_ious.append(this_sector_iou)\n",
        "\n",
        "                # # Plot the lines of the sector (and the boundary line) onto the colony segmentation\n",
        "                # length_points = len(endpoints_x)\n",
        "                # #print(length_points)\n",
        "                # #print(endpoints_x)\n",
        "                # if len(np.unique(red_labels)[1:]) > 0:\n",
        "                #     plot_bounds_x = []\n",
        "                #     plot_bounds_y = []\n",
        "                #     plot_bounds_x.append(endpoints_x[0] + 5)\n",
        "                #     plot_bounds_y.append(endpoints_y[0] + 5)\n",
        "                #     # Get list of center and endpoints on the boundary\n",
        "                #     for this_bound in range(0, length_points-1):\n",
        "                #         plot_bounds_x.append(endpoints_x[this_bound+1] + 5)\n",
        "                #         plot_bounds_y.append(endpoints_y[this_bound+1] + 5)\n",
        "                #         #plt.plot(plot_points_y, plot_points_x, color='blue')\n",
        "                #         #print(endpoints_x[0:2])\n",
        "                #         #print(endpoints_y[0:2])\n",
        "                #     plot_bounds_x = np.roll(np.array(plot_bounds_x), 1)\n",
        "                #     plot_bounds_y = np.roll(np.array(plot_bounds_y), 1)\n",
        "                #     #print(plot_bounds_x)\n",
        "                #     #print(plot_bounds_y)\n",
        "                #     line_style = ':' if (len(plot_bounds_x) == 2) else '-'\n",
        "                #     ax2.plot(plot_bounds_y, plot_bounds_x, linewidth=5, linestyle=line_style, alpha=0.85)\n",
        "                #     if len(plot_bounds_x) == 1:\n",
        "                #         full_circle = Circle((plot_bounds_y, plot_bounds_x), radius=colony_locations[\"Radius\"][this_index], color='blue', fill=False, linewidth=5, alpha=0.85)\n",
        "                #         ax2.add_patch(full_circle)\n",
        "\n",
        "\n",
        "\n",
        "            for this_label in np.unique(white_labels)[1:]:\n",
        "                white_component = copy.deepcopy(white_labels)\n",
        "                white_component = white_component == this_label\n",
        "                white_component = white_component.astype(np.int32)\n",
        "\n",
        "                post_white_boundary_mask = np.logical_or(post_white_boundary_mask, white_component > 0)\n",
        "\n",
        "                # Function to get endpoints of connected component\n",
        "                full_endpoints_list = get_boundary_component_endpoints(corrected_colony_image[:,:], white_component)\n",
        "\n",
        "                # If exactly two points are found, then everything's good.\n",
        "\n",
        "                # Function to get mask representing sector boundary\n",
        "                sector_boundary, sector_interior, sector_filled = get_sector_masks(white_component, full_endpoints_list)\n",
        "\n",
        "                # Fill initial region mask with the filled sector\n",
        "                post_white_region_mask = np.logical_or(post_white_region_mask, sector_filled)\n",
        "\n",
        "                # Apply consistency check to score region\n",
        "                confirm_check, prop_interior = check_for_consistency_2(sector_filled, corrected_white_colony_mask)\n",
        "\n",
        "                # Update score mask to denote where the consistency check failed\n",
        "                if confirm_check == False:\n",
        "                    print('Double check your code.  The white consistency check failed for this colony with score ' + str(prop_interior))\n",
        "\n",
        "                # Append scores and info to lists\n",
        "                white_component_endpoints.append(full_endpoints_list)\n",
        "                white_component_scores.append(prop_interior)\n",
        "                white_component_checks.append(confirm_check)\n",
        "                white_component_sizes.append(np.sum(post_white_region_mask))\n",
        "\n",
        "            print('Scores for red regions: ' + str(red_component_scores))\n",
        "            print('Scores for white regions: ' + str(white_component_scores))\n",
        "\n",
        "            # Store the purity scores in a sublist, along with a second sublist indicating the color of each region\n",
        "\n",
        "            all_component_scores = []\n",
        "            all_region_colors = []\n",
        "            all_region_sizes = []\n",
        "\n",
        "            if not red_component_scores:\n",
        "                all_region_colors = all_region_colors + ['red']\n",
        "                all_component_scores = all_component_scores + [np.nan]\n",
        "                all_region_sizes = all_region_sizes + [np.nan]\n",
        "            else:\n",
        "                all_region_colors = all_region_colors + (['red'] * len(red_component_scores))\n",
        "                all_component_scores = all_component_scores + red_component_scores\n",
        "                all_region_sizes = all_region_sizes + red_component_sizes\n",
        "\n",
        "            if not white_component_scores:\n",
        "                all_region_colors = all_region_colors + ['white']\n",
        "                all_component_scores = all_component_scores + [np.nan]\n",
        "                all_region_sizes = all_region_sizes + [np.nan]\n",
        "            else:\n",
        "                all_region_colors = all_region_colors + (['white'] * len(white_component_scores))\n",
        "                all_component_scores = all_component_scores + white_component_scores\n",
        "                all_region_sizes = all_region_sizes + white_component_sizes\n",
        "\n",
        "            region_purity_after.append(all_component_scores)\n",
        "            region_color_after.append(all_region_colors)\n",
        "            region_sizes_after.append(all_region_sizes)\n",
        "\n",
        "            # Compute weighted purity scores over all regions, for white only, and for red only\n",
        "\n",
        "            total_red_sum = np.nansum(red_component_sizes)\n",
        "            total_white_sum = np.nansum(white_component_sizes)\n",
        "\n",
        "            if not red_component_scores:\n",
        "                red_region_weights = np.array([0])\n",
        "                weighted_red_scores = np.array([0])\n",
        "            else:\n",
        "                red_region_weights = np.divide(np.array(red_component_sizes), total_red_sum) # this vector should add to 1, as this is a normalization of the weights\n",
        "                weighted_red_scores = np.multiply(np.array(red_component_scores), red_region_weights)\n",
        "\n",
        "            if not white_component_scores:\n",
        "                white_region_weights = np.array([0])\n",
        "                weighted_white_scores = np.array([0])\n",
        "            else:\n",
        "                white_region_weights = np.divide(np.array(white_component_sizes), total_white_sum) # this vector should add to 1, as this is a normalization of the weights\n",
        "                weighted_white_scores = np.multiply(np.array(white_component_scores), white_region_weights)\n",
        "\n",
        "            # Get weighted average over both regions together\n",
        "            all_region_sum = np.nansum(all_region_sizes)\n",
        "            all_region_weights = np.divide(np.array(red_component_sizes + white_component_sizes), all_region_sum)\n",
        "            all_region_weighted_scores = np.multiply(np.array(red_component_scores + white_component_scores), all_region_weights)\n",
        "\n",
        "            weighted_purity_red_after.append(list(weighted_red_scores))\n",
        "            weighted_purity_white_after.append(list(weighted_white_scores))\n",
        "            weighted_purity_after.append(list(all_region_weighted_scores))\n",
        "            weighted_red_sector_score_after.append(np.nansum(weighted_red_scores))\n",
        "            weighted_white_sector_score_after.append(np.nansum(weighted_white_scores))\n",
        "            weighted_sector_score_after.append(np.nansum(all_region_weighted_scores))\n",
        "  \n",
        "            # Now, create the masks containing the initial_regions\n",
        "            post_region_mask = np.maximum(post_red_region_mask.astype(np.uint8), 2*post_white_region_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            post_boundary_mask = np.maximum(post_red_boundary_mask.astype(np.uint8), 2*post_white_boundary_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            post_score_mask = np.maximum(post_red_score_mask.astype(np.uint8), 2*post_white_score_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "\n",
        "            post_region_mask = np.pad(post_region_mask, image_padding)\n",
        "            post_boundary_mask = np.pad(post_boundary_mask, image_padding)\n",
        "            post_score_mask = np.pad(post_score_mask, image_padding)\n",
        "\n",
        "            #if not cv2.imwrite(output_crops_folder + '/Colony Corrected Regions/' + pathlib.Path(test_image).stem + '_Colony_' + str(this_index) + '.png', post_region_mask):\n",
        "            #    raise Exception('Could not write image.')\n",
        "\n",
        "            #post_region_mask = np.pad(post_region_mask, 5)\n",
        "                \n",
        "            # if save_all_annotations == True:\n",
        "            #     if not cv2.imwrite(output_crops_folder + '/cor_bounds/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', post_boundary_mask):\n",
        "            #         raise Exception('Could not write image.')\n",
        "            #     if not cv2.imwrite(output_crops_folder + '/cor_regions/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', post_region_mask):\n",
        "            #         raise Exception('Could not write image.')\n",
        "            #     if not cv2.imwrite(output_crops_folder + '/cor_bad/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', post_score_mask):\n",
        "            #         raise Exception('Could not write image.')\n",
        "            plt.axis('off')\n",
        "            # if save_all_annotations == True:\n",
        "            #     fig2.savefig(output_crops_folder + '/cor_partitions/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', bbox_inches='tight', pad_inches=0)\n",
        "            plt.close(fig2);\n",
        "                    \n",
        "                \n",
        "            #------------------------------------------------------------------\n",
        "\n",
        "            # PRINTING RESULTS OF COLONY\n",
        "\n",
        "            if not sector_scores:\n",
        "                sector_scores = 0\n",
        "                sector_ious = 0\n",
        "            average_sector_score.append(np.mean(sector_scores))\n",
        "            average_sector_iou.append(np.mean(sector_ious))\n",
        "            #print('Colony ' + str(this_index))\n",
        "            print('Estimated number of sectors: ' + str(total_sectors))\n",
        "            all_sector_counts.append(total_sectors)\n",
        "            print('Average sector score: ' + str(average_sector_score[-1]))\n",
        "            print('Average sector score (IoU): ' + str(average_sector_iou[-1]))\n",
        "\n",
        "            # plt.axis('off')\n",
        "            # plt.savefig(output_crops_folder + '/Colony Corrected Sector Bounds/' + pathlib.Path(test_image).stem + '_Colony_' + str(this_index) + '.png', bbox_inches='tight', pad_inches=0)\n",
        "            # plt.close();\n",
        "            #raise NameError('Text to read') \n",
        "\n",
        "            corrected_white_region_sum.append(np.sum(np.logical_xor(corrected_colony_mask, all_sector_filled)))\n",
        "            corrected_red_region_sum.append(np.sum(all_sector_filled))\n",
        "            corrected_sector_region_sum.append(np.sum(all_sector_filled) / np.sum(corrected_colony_mask))\n",
        "\n",
        "            true_sector_count = 0\n",
        "            true_sector_counts.append(true_sector_count)\n",
        "            true_sector_region_sum.append(0)\n",
        "            corrected_colony_mask_faded[corrected_colony_mask == 0] = 0\n",
        "\n",
        "            corrected_colony_mask_faded = np.pad(corrected_colony_mask_faded, image_padding)\n",
        "            corrected_red_colony_mask_padded = np.pad(corrected_red_colony_mask, image_padding)\n",
        "            corrected_sector_comp_mask = np.multiply(corrected_red_colony_mask_padded, corrected_colony_mask_faded)\n",
        "\n",
        "            #colony_image_padded = np.pad(colony_image, image_padding)\n",
        "            #cv2_imshow(colony_mask_faded)\n",
        "            # if save_all_annotations == True:\n",
        "            #     if not cv2.imwrite(output_crops_folder + '/sectors/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', corrected_colony_mask_faded):\n",
        "            #         raise Exception('Could not write image.')\n",
        "            #     if not cv2.imwrite(output_crops_folder + '/sector_comps/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', corrected_sector_comp_mask):\n",
        "            #         raise Exception('Could not write image.')\n",
        "            \n",
        "            # # Plot image and lines with matplotlib\n",
        "            # Recall that endpoints_x[0], endpoints_y[0] is the center of the colony, and\n",
        "            # endpoints_x[#], endpoints_y[#] is a point on the boundary representing the interfacial point of a sector\n",
        "            \n",
        "\n",
        "            # Output labellings of colonies to directory\n",
        "\n",
        "            # 1. Get the sectors labellings you defined.\n",
        "            # 2. Get intersection of this labelling with the colony mask.\n",
        "            # 3. Create copy of colony mask that is faded.  (sectors will be overlayed on this in the next step)\n",
        "            # 4. Save cropping to Colony Sectors folder \n",
        "\n",
        "            # colony_cropping = p[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1)]\n",
        "\n",
        "            # height, width = colony_cropping.shape[:2]\n",
        "            # # Do some plotting to see the results in action, and to find potential problems\n",
        "            # cv2_imshow(255*cv2.resize(x[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1)], (4*width, 4*height)))\n",
        "            # cv2_imshow(cv2.resize(colony_cropping, (4*width, 4*height)))\n",
        "            # fig, ax = plt.subplots(1,4)\n",
        "            # ax[0].imshow(np.squeeze(colony_image))\n",
        "            # ax[1].imshow(all_sector_bounds)\n",
        "            # ax[2].imshow(all_sector_filled)\n",
        "            # ax[3].imshow(all_sector_filled_labels * (255 / (total_sectors+1)))\n",
        "            # plt.show()\n",
        "\n",
        "            # these_thetas_sorted, sorted_points = sort_thetas(edge_mask_unpadded)\n",
        "            # intensity_sum_red, full_seg_sum_red = get_intensity_map(red_colony_mask, sorted_points)\n",
        "            # intensity_sum_white, full_seg_sum_white = get_intensity_map(white_colony_mask, sorted_points)\n",
        "            # intensity_sum_full, full_seg_sum_full = get_intensity_map(colony_mask, sorted_points)\n",
        "\n",
        "            # fig, ax = plt.subplots(1,3,subplot_kw={'projection': 'polar'}, figsize=(15, 4))\n",
        "\n",
        "            # ax[0].plot(these_thetas_sorted, intensity_sum_red)\n",
        "            # #ax.plot(these_thetas_sorted, full_seg_sum)\n",
        "            # ax[0].set_rmax(max(colony_image.shape)/2.0)\n",
        "            # ax[0].grid(True)\n",
        "            # ax[0].set_title(\"Red Pixels by Angle\", va='bottom')\n",
        "\n",
        "            # ax[1].plot(these_thetas_sorted, intensity_sum_white)\n",
        "            # #ax.plot(these_thetas_sorted, full_seg_sum)\n",
        "            # ax[1].set_rmax(max(colony_image.shape)/2.0)\n",
        "            # ax[1].grid(True)\n",
        "            # ax[1].set_title(\"White Pixels by Angle\", va='bottom')\n",
        "\n",
        "            # ax[2].plot(these_thetas_sorted, intensity_sum_full)\n",
        "            # #ax.plot(these_thetas_sorted, full_seg_sum)\n",
        "            # ax[2].set_rmax(max(colony_image.shape)/2.0)\n",
        "            # ax[2].grid(True)\n",
        "            # ax[2].set_title(\"Colony Pixels by Angle\", va='bottom')\n",
        "\n",
        "            # plt.show()\n",
        "\n",
        "\n",
        "\n",
        "        # This ends the loop on the isolated colonies\n",
        "\n",
        "        # Ensure that the number of sectors are integers\n",
        "        \n",
        "        \n",
        "        # Construct a dataframe with the nubmer of sectors and the proportion of red present\n",
        "\n",
        "        all_sector_counts_array = np.array(all_sector_counts).astype(int)\n",
        "        true_sector_counts = np.array(true_sector_counts).astype(int)\n",
        "        #true_sector_counts = np.repeat(1,len(indiv_good))\n",
        "        correct_sector_count = np.abs(true_sector_counts - all_sector_counts_array) == 0\n",
        "\n",
        "        sides_vert_top_array = np.array(sides_vert_top)\n",
        "        sides_vert_bottom_array = np.array(sides_vert_bottom)\n",
        "        sides_horz_left_array = np.array(sides_horz_left)\n",
        "        sides_horz_right_array = np.array(sides_horz_right)\n",
        "        \n",
        "        # Gather all data that that can be created as a numpy array\n",
        "        d = {'Plate Name': plate_names,\n",
        "            'Colony Number': colony_numbers.astype(int),\n",
        "            'True # Sectors': true_sector_counts,\n",
        "            'Initial # Regions': np.array(initial_region_counts).astype(int),\n",
        "            'Pred # Sectors': all_sector_counts_array,\n",
        "            'Correct # Sectors?': correct_sector_count,\n",
        "            'White Area (Seg)': white_region_sum,\n",
        "            'Red Area (Seg)': red_region_sum,\n",
        "            'Colony Area (Seg)': (np.array(white_region_sum) + np.array(red_region_sum)),\n",
        "            'White Area (Corr)': corrected_white_region_sum,\n",
        "            'Red Area (Corr)': corrected_red_region_sum,\n",
        "            'Colony Area (Corr)': (np.array(corrected_white_region_sum) + np.array(corrected_red_region_sum)),\n",
        "            'Avg Sector Score': average_sector_score,\n",
        "            'Avg Sector Score (IoU)': average_sector_iou,\n",
        "            'Side Top': sides_vert_top_array,\n",
        "            'Side Bottom': sides_vert_bottom_array,\n",
        "            'Side Left': sides_horz_left_array,\n",
        "            'Side Right': sides_horz_right_array,\n",
        "            '1 Comp': np.array(colony_is_connected),\n",
        "            '1 Comp (Approx)': np.array(colony_is_approx_connected),\n",
        "            'Bound Comp': np.array(boundary_is_connected),\n",
        "            'No Holes': np.array(colony_is_whole),\n",
        "            'Approx Convex': np.array(colony_is_approx_convex),\n",
        "            'Approx Circle': np.array(colony_is_approx_circular),\n",
        "            'Hausdorff Convex': np.array(hausdorff_dist_convex),\n",
        "            'Hausdorff Circle': np.array(hausdorff_dist_circle)}\n",
        "\n",
        "        # # Gasther data based on what else we used as input\n",
        "        # if use_expert_counts == True:\n",
        "        #     d['Quantifiable'] = np.array(quantifiable_colony)\n",
        "        #     d['Quantifiable Cured'] = np.array(quantifiable_cured)\n",
        "        #     d['Quantifiable Stable'] = np.array(quantifiable_stable)\n",
        "        #     d['Quantifiable Sectored'] = np.array(quantifiable_sectored)\n",
        "\n",
        "        df = pd.DataFrame(data=d)\n",
        "\n",
        "        # Gather data that could NOT be stored as a numpy array, such as nested lists\n",
        "\n",
        "        df['(BC) Regional Color Classes'] = list(region_color_before)\n",
        "        df['(BC) Regional Sizes'] = list(region_sizes_before)\n",
        "        df['(BC) Regional Purity Scores'] = list(region_purity_before)\n",
        "        df['(BC) Red Purity Scores Weighted'] = list(weighted_purity_red_before)\n",
        "        df['(BC) White Purity Scores Weighted'] = list(weighted_purity_white_before)\n",
        "        df['(BC) Weighted Red Average Score'] = weighted_red_sector_score_before\n",
        "        df['(BC) Weighted White Average Score'] = weighted_white_sector_score_before\n",
        "        df['(BC) Weighted Full Average Score'] = weighted_sector_score_before\n",
        "        df['(BC) Cured'] = cured_colony_before\n",
        "        df['(BC) Stable'] = stable_colony_before\n",
        "\n",
        "        df['(AC) Regional Color Classes'] = list(region_color_after)\n",
        "        df['(AC) Regional Sizes'] = list(region_sizes_after)\n",
        "        df['(AC) Regional Purity Scores'] = list(region_purity_after)\n",
        "        df['(AC) Red Purity Scores Weighted'] = list(weighted_purity_red_after)\n",
        "        df['(AC) White Purity Scores Weighted'] = list(weighted_purity_white_after)\n",
        "        df['(AC) Weighted Red Average Score'] = weighted_red_sector_score_after\n",
        "        df['(AC) Weighted White Average Score'] = weighted_white_sector_score_after\n",
        "        df['(AC) Weighted Full Average Score'] = weighted_sector_score_after\n",
        "        df['(AC) Cured'] = cured_colony_after\n",
        "        df['(AC) Stable'] = stable_colony_after\n",
        "\n",
        "        df.to_pickle(train_output_table_folder + '/' + str(plate_stem) + '.pkl')\n",
        "\n",
        "        # if starting_image == False:\n",
        "        #     #print('This ran.')\n",
        "        #     all_df = pd.concat([all_df, df], axis=0, ignore_index=True)\n",
        "        #     #print('The dataframe was appended.')\n",
        "        # else:\n",
        "        #     starting_image = False\n",
        "        #     all_df = copy.deepcopy(df)\n",
        "\n",
        "    #all_df\n",
        "    # all_df.to_pickle(test_output_folder + '/' + str(weights_file) + '_colony_data.pkl')\n",
        "    # unpickled_all_df = pd.read_pickle(test_output_folder + '/' + str(weights_file) + '_colony_data.pkl')\n",
        "    # unpickled_all_df.to_csv(test_output_folder + '/' + str(weights_file) + '_colony_data.csv')\n",
        "\n",
        "    # unpickled_all_df"
      ],
      "metadata": {
        "id": "QLQs8yr8kPha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge output tables into one"
      ],
      "metadata": {
        "id": "75EugnbipD9h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read in all the files of data\n",
        "sorted_tables = sorted(glob.glob(train_output_table_folder + '/' + '*'))\n",
        "print(sorted_tables)\n",
        "\n",
        "first_table = True\n",
        "\n",
        "for this_table in sorted_tables:\n",
        "    this_table_data = pd.read_pickle(this_table)\n",
        "    if first_table == True:\n",
        "        first_table = False\n",
        "        all_table_data = copy.deepcopy(this_table_data)\n",
        "    else:\n",
        "        all_table_data = pd.concat([all_table_data, this_table_data], axis=0, ignore_index=True)\n",
        "\n",
        "all_table_data.to_pickle(train_output_folder + '/' + str(weights_file) + '_colony_data.pkl')"
      ],
      "metadata": {
        "id": "XsPEwuYKpHR5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load table with training data"
      ],
      "metadata": {
        "id": "9kjS3mwwp9TV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#colony_data = pd.read_csv(output_data_folder + '/' + str(weights_file) + '_colony_data_CHT_' + str(num_classes) + '_puritycheck_byregion.csv')\n",
        "#colony_data = pd.read_csv(test_output_folder + '/' + str(weights_file) + '_colony_data_CHT_puritycheck_byregion.csv')\n",
        "#colony_data = pd.read_csv(test_output_folder + '/' + str(weights_file) + '_colony_data_2.csv')\n",
        "colony_data = pd.read_pickle(train_output_folder + '/' + str(weights_file) + '_colony_data.pkl')\n",
        "\n",
        "#print(colony_data)\n",
        "all_plate_names = colony_data['Plate Name'].unique()\n",
        "all_sector_values = list(range(0, int(np.max(colony_data['Pred # Sectors']))+1))\n",
        "\n",
        "# Include true sector counts if available\n",
        "if use_true_sector_counts == True:\n",
        "\n",
        "    # Read in table with true sector counts\n",
        "    true_sector_counts = pd.read_csv(train_output_folder + '/true_colony_data.csv') # load file containing true sector counts\n",
        "    colony_data['True # Sectors'] = true_sector_counts['True # Sectors'] # insert the true sector counts in the data\n",
        "    matching_sector_counts = colony_data['True # Sectors'] == colony_data['Pred # Sectors'] # compare the true and predicted sector counts\n",
        "    colony_data['Correct # Sectors?'] = matching_sector_counts # mark where the counts match and insert this into the data\n",
        "\n",
        "if use_quantifiable_counts_from_table == True:\n",
        "    true_quant_colonies = pd.read_csv(train_output_folder + '/true_quantifiable_colonies.csv') # load file containing whether colony is cured\n",
        "    colony_data['Quantifiable'] = true_quant_colonies['Quantifiable'] # insert this data into the original table\n",
        "    \n",
        "if use_true_cured_colonies_from_table == True:\n",
        "    # Read in table with true cured colonies\n",
        "    true_cured_colonies = pd.read_csv(train_output_folder + '/true_cured_colonies.csv') # load file containing whether colony is cured\n",
        "    colony_data['Is Cured?'] = true_cured_colonies['Is Cured?'] # insert this data into the original table\n",
        "\n",
        "if (use_true_sector_counts == True) & (use_quantifiable_counts_from_table == True) & (use_true_cured_colonies_from_table == True):\n",
        "    colony_data['Quantifiable Cured'] = (colony_data['Quantifiable'] == True) & (colony_data['Is Cured?'] == True)\n",
        "    colony_data['Quantifiable Stable'] = (colony_data['Quantifiable'] == True) & (colony_data['True # Sectors'] == 0)\n",
        "    colony_data['Quantifiable Sectored'] = (colony_data['Quantifiable'] == True) & (colony_data['True # Sectors'] > 0) & (colony_data['Is Cured?'] == False)\n",
        "\n",
        "# Since this is training data, we know the number of sectors\n",
        "colony_data['True # Sectors'] = np.repeat(1, len(colony_data['Pred # Sectors']))\n",
        "colony_data['Is Cured?'] = np.repeat(False, len(colony_data['Pred # Sectors']))\n",
        "colony_data['Is Stable?'] = np.repeat(False, len(colony_data['Pred # Sectors']))\n",
        "    \n",
        "colony_data.to_pickle(train_output_folder + '/' + str(weights_file) + '_colony_data.pkl')\n",
        "#colony_data.to_pickle(output_data_folder + '/' + str(weights_file) + '_colony_data_CHT_' + str(num_classes) + '_puritycheck_byregion.pkl')\n",
        "#colony_data.to_csv(output_data_folder + '/' + str(weights_file) + '_colony_data_CHT_' + str(num_classes) + '_puritycheck_byregion.csv')\n",
        "\n",
        "colony_data.to_csv(train_output_folder + '/' + str(weights_file) + '_colony_data.csv')\n",
        "colony_data\n"
      ],
      "metadata": {
        "id": "-oE0i-0Kvuth"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get colony labels ([PSI+], [psi-], and Sectored)"
      ],
      "metadata": {
        "id": "J7F7EcLcvcSY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "colony_states_before = np.array(['UNFILLED' for i in range(0, len(colony_data))])\n",
        "colony_states_after = np.array(['UNFILLED' for i in range(0, len(colony_data))])\n",
        "colony_states_true = np.array(['UNFILLED' for i in range(0, len(colony_data))])\n",
        "#colony_states_set = set(colony_states)\n",
        "#print(colony_states_set)\n",
        "\n",
        "max_sector_count_before = max(colony_data['Initial # Regions'])\n",
        "max_sector_count_after = max(colony_data['Pred # Sectors'])\n",
        "max_sector_count_true = max(colony_data['True # Sectors'])\n",
        "\n",
        "max_sector_count_all = max([max_sector_count_before, max_sector_count_after, max_sector_count_true])\n",
        "\n",
        "# [PSI+]: Get all colonies with no red regions\n",
        "\n",
        "colony_states_before[(colony_data['(BC) Stable'] == True)] = '[PSI+]'\n",
        "colony_states_after[(colony_data['(AC) Stable'] == True)] = '[PSI+]'\n",
        "colony_states_true[(colony_data['Is Stable?'] == True)] = '[PSI+]'\n",
        "\n",
        "# [psi-]: Get all quantifiable colonies with no white regions\n",
        "\n",
        "colony_states_before[(colony_data['(BC) Cured'] == True)] = '[psi-]'\n",
        "colony_states_after[(colony_data['(AC) Cured'] == True)] = '[psi-]'\n",
        "colony_states_true[(colony_data['Is Cured?'] == True)] = '[psi-]'\n",
        "\n",
        "# Sx: Get all quantifiable colonies with at least 1 white region and exactly x red regions \n",
        "\n",
        "for num_regions in range(1, max_sector_count_all+1):\n",
        "    colony_states_before[(colony_data['(BC) Cured'] == False) & (colony_data['(BC) Stable'] == False) & (colony_data['Initial # Regions'] == num_regions)] = str('S' + str(num_regions))\n",
        "    colony_states_after[(colony_data['(AC) Cured'] == False) & (colony_data['(AC) Stable'] == False) & (colony_data['Pred # Sectors'] == num_regions)] = str('S' + str(num_regions))\n",
        "    colony_states_true[(colony_data['Is Cured?'] == False) & (colony_data['Is Stable?'] == False) & (colony_data['True # Sectors'] == num_regions).astype(bool)] = str('S' + str(num_regions))\n",
        "\n",
        "#print(np.unique(colony_states_before))\n",
        "#print(np.unique(colony_states_after))\n",
        "#print(np.unique(colony_states_true))\n",
        "\n",
        "unmarked_locations = np.where(colony_states_true == 'UNFILLED')\n",
        "\n",
        "# Make corrections to the table for unfilled locations\n",
        "\n",
        "\n",
        "# Display any colony locations what are marked as UNFILLED\n",
        "\n",
        "colony_row = colony_data.iloc[unmarked_locations]\n",
        "#print(colony_row)\n",
        "#print(colony_row.index)\n",
        "\n",
        "#print(colony_states_before)\n",
        "\n",
        "# If every location has been filled, then add these to the merged table\n",
        "colony_data['Label Before'] = colony_states_before\n",
        "colony_data['Label After'] = colony_states_after\n",
        "colony_data['Label True'] = colony_states_true\n",
        "\n",
        "#print(quantifiable_colony_data['Label Before'])\n",
        "# counter = 0\n",
        "\n",
        "# for ind in colony_row.index:\n",
        "#     colony_number = colony_row['Colony Number'].iloc[counter]\n",
        "#     plate_name = colony_row['Plate Name'].iloc[counter]\n",
        "#     set_number = colony_row['Set'].iloc[counter]\n",
        "\n",
        "#     #if counter == 0:\n",
        "#     #    merged_table['Quantifiable Stable'] = \n",
        "\n",
        "#     # Get image\n",
        "#     if set_number == 2:\n",
        "#         image_to_display = read_image(sector_project_folder + '/Real Images/Wes Plates/Set 2 Prepro/' + plate_name)*255\n",
        "#     image_to_display = cv2.rectangle(image_to_display, (colony_row['Side Left'].iloc[counter], colony_row['Side Top'].iloc[counter]), (colony_row['Side Right'].iloc[counter], colony_row['Side Bottom'].iloc[counter]), (255, 0, 0), 2)\n",
        "#     #cv2_imshow(image_to_display)"
      ],
      "metadata": {
        "id": "dIwrbX6Zvd1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Ysr_hassEH5"
      },
      "source": [
        "## Plots on Training Data"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions Only"
      ],
      "metadata": {
        "id": "trN1I-t_5-zl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Colony States (no sector counts)"
      ],
      "metadata": {
        "id": "zajlYSuC6Gwr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#print(sampled_colony_data.keys())\n",
        "#print(sampled_colony_data['Is it a colony? '])\n",
        "\n",
        "\n",
        "max_initial = np.max(colony_data['Initial # Regions'])\n",
        "max_pred = np.max(colony_data['Pred # Sectors'])\n",
        "#max_true = np.max(colony_data['True # Sectors'])\n",
        "max_all = np.max([max_initial, max_pred])\n",
        "#diff_count_before = np.abs(colony_data['Initial # Regions'] - colony_data['True # Sectors'])\n",
        "#diff_count_after = np.abs(colony_data['Pred # Sectors'] - colony_data['True # Sectors'])\n",
        "\n",
        "initial_correct_counts = []\n",
        "post_correct_counts = []\n",
        "#true_correct_counts = []\n",
        "all_counts = []\n",
        "\n",
        "label_names = ['[PSI+]', '[psi-]', 'Sectored']\n",
        "\n",
        "# print(np.unique(colony_data['Label True']))\n",
        "\n",
        "# Gather [PSI+] counts\n",
        "#true_white_labels = colony_data[(colony_data['Label True'] == '[PSI+]')]\n",
        "correct_white_labels_before = colony_data[(colony_data['Label Before'] == '[PSI+]')]\n",
        "correct_white_labels_after = colony_data[(colony_data['Label After'] == '[PSI+]')]\n",
        "\n",
        "initial_correct_counts.append(len(correct_white_labels_before))\n",
        "post_correct_counts.append(len(correct_white_labels_after))\n",
        "#true_correct_counts.append(len(true_white_labels))\n",
        "\n",
        "# Gather [psi-] counts\n",
        "#true_red_labels = colony_data[(colony_data['Label True'] == '[psi-]')]\n",
        "correct_red_labels_before = colony_data[(colony_data['Label Before'] == '[psi-]')]\n",
        "correct_red_labels_after = colony_data[(colony_data['Label After'] == '[psi-]')]\n",
        "\n",
        "initial_correct_counts.append(len(correct_red_labels_before))\n",
        "post_correct_counts.append(len(correct_red_labels_after))\n",
        "#true_correct_counts.append(len(true_red_labels))\n",
        "\n",
        "\n",
        "# Gather sectored counts\n",
        "correct_sector_labels_before = colony_data[(colony_data['Label Before'].str.startswith('S'))]\n",
        "correct_sector_labels_after = colony_data[(colony_data['Label After'].str.startswith('S'))]\n",
        "\n",
        "initial_correct_counts.append(len(correct_sector_labels_before))\n",
        "post_correct_counts.append(len(correct_sector_labels_after))\n",
        "#max_sector_counts = max([np.nanmax(colony_data['Initial # Regions'].astype(int)), np.nanmax(colony_data['Pred # Sectors'].astype(int)), np.nanmax(colony_data['True # Sectors'].astype(int))])\n",
        "# print(max_sector_counts)\n",
        "\n",
        "# for this_num_sectors in range(1, max_sector_counts+1):\n",
        "#     #true_sector_labels = colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors))]\n",
        "#     correct_sector_labels_before = colony_data[(colony_data['Label Before'] == 'S'+str(this_num_sectors))]\n",
        "#     correct_sector_labels_after = colony_data[(colony_data['Label After'] == 'S'+str(this_num_sectors))]\n",
        "\n",
        "#     initial_correct_counts.append(len(correct_sector_labels_before))\n",
        "#     post_correct_counts.append(len(correct_sector_labels_after))\n",
        "#     #true_correct_counts.append(len(true_sector_labels))\n",
        "\n",
        "# print(colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors)) & (colony_data['Label After'] == 'S'+str(this_num_sectors))])\n",
        "#sector_labels = ['S'+str(i) for i in (range(1, max_sector_counts+1))]\n",
        "# print(sector_labels)\n",
        "#label_names = label_names + sector_labels\n",
        "# print(label_names)\n",
        "x = np.arange(len(label_names))\n",
        "# print(len(x))\n",
        "# print(len(initial_correct_counts))\n",
        "\n",
        "\n",
        "\n",
        "width = 0.25  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,5), sharey=True)\n",
        "#x - width/2\n",
        "ax.set_ylim(bottom=0, top=max(initial_correct_counts + post_correct_counts)+50)\n",
        "rects1 = ax.bar(x - width/2, initial_correct_counts, width, label='Original Predictions', color='blue')\n",
        "rects2 = ax.bar(x+width/2, post_correct_counts, width, label='With Purity Correction', color='red')\n",
        "#rects2 = ax.bar(x + width/2, all_counts, width, label='All Colonies', color='red')\n",
        "#rects3 = ax.bar(x + width, true_correct_counts, width, label='Manual Counts', color='green')\n",
        "\n",
        "#print(true_single_frequency)\n",
        "#print(pred_single_frequency)\n",
        "\n",
        "ax.set_xlabel('Colony States')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title('Classified Colonies', fontsize=16)\n",
        "ax.xaxis.label.set_fontsize(14)\n",
        "ax.yaxis.label.set_fontsize(14)\n",
        "ax.set_xticks(np.arange(0, 3, step=1))\n",
        "ax.set_xticklabels(label_names)\n",
        "ax.tick_params(axis='both', labelsize=12)\n",
        "ax.legend(loc='best')\n",
        "\n",
        "xtickslocs = ax.get_xticks()\n",
        "print(xtickslocs)\n",
        "\n",
        "addlabels_centered(xtickslocs-width/2, initial_correct_counts, 9)\n",
        "addlabels_centered(xtickslocs+width/2, post_correct_counts, 9)\n",
        "#addlabels_pred(x, all_counts, 10)\n",
        "#addlabels_truemarks(x, true_correct_counts, 9)\n",
        "\n",
        "ax.axvline(x = 0.5, color = 'k', linestyle = '--')\n",
        "ax.axvline(x = 1.5, color = 'k', linestyle = '--')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "V7fKsaGN6N4t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Colony States (with sector counts)"
      ],
      "metadata": {
        "id": "xctSQ_9O6QLE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#print(sampled_colony_data.keys())\n",
        "#print(sampled_colony_data['Is it a colony? '])\n",
        "\n",
        "\n",
        "max_initial = np.max(colony_data['Initial # Regions'])\n",
        "max_pred = np.max(colony_data['Pred # Sectors'])\n",
        "#max_true = np.max(colony_data['True # Sectors'])\n",
        "max_all = np.max([max_initial, max_pred])\n",
        "#diff_count_before = np.abs(colony_data['Initial # Regions'] - colony_data['True # Sectors'])\n",
        "#diff_count_after = np.abs(colony_data['Pred # Sectors'] - colony_data['True # Sectors'])\n",
        "\n",
        "initial_correct_counts = []\n",
        "post_correct_counts = []\n",
        "#true_correct_counts = []\n",
        "all_counts = []\n",
        "\n",
        "label_names = ['[PSI+]', '[psi-]']\n",
        "\n",
        "# print(np.unique(colony_data['Label True']))\n",
        "\n",
        "# Gather [PSI+] counts\n",
        "#true_white_labels = colony_data[(colony_data['Label True'] == '[PSI+]')]\n",
        "correct_white_labels_before = colony_data[(colony_data['Label Before'] == '[PSI+]')]\n",
        "correct_white_labels_after = colony_data[(colony_data['Label After'] == '[PSI+]')]\n",
        "\n",
        "initial_correct_counts.append(len(correct_white_labels_before))\n",
        "post_correct_counts.append(len(correct_white_labels_after))\n",
        "#true_correct_counts.append(len(true_white_labels))\n",
        "\n",
        "# Gather [psi-] counts\n",
        "#true_red_labels = colony_data[(colony_data['Label True'] == '[psi-]')]\n",
        "correct_red_labels_before = colony_data[(colony_data['Label Before'] == '[psi-]')]\n",
        "correct_red_labels_after = colony_data[(colony_data['Label After'] == '[psi-]')]\n",
        "\n",
        "initial_correct_counts.append(len(correct_red_labels_before))\n",
        "post_correct_counts.append(len(correct_red_labels_after))\n",
        "#true_correct_counts.append(len(true_red_labels))\n",
        "\n",
        "\n",
        "# Gather sectored counts\n",
        "max_sector_counts = max([np.nanmax(colony_data['Initial # Regions'].astype(int)), np.nanmax(colony_data['Pred # Sectors'].astype(int)), np.nanmax(colony_data['True # Sectors'].astype(int))])\n",
        "# print(max_sector_counts)\n",
        "\n",
        "for this_num_sectors in range(1, max_sector_counts+1):\n",
        "    #true_sector_labels = colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors))]\n",
        "    correct_sector_labels_before = colony_data[(colony_data['Label Before'] == 'S'+str(this_num_sectors))]\n",
        "    correct_sector_labels_after = colony_data[(colony_data['Label After'] == 'S'+str(this_num_sectors))]\n",
        "\n",
        "    initial_correct_counts.append(len(correct_sector_labels_before))\n",
        "    post_correct_counts.append(len(correct_sector_labels_after))\n",
        "    #true_correct_counts.append(len(true_sector_labels))\n",
        "\n",
        "# print(colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors)) & (colony_data['Label After'] == 'S'+str(this_num_sectors))])\n",
        "sector_labels = ['S'+str(i) for i in (range(1, max_sector_counts+1))]\n",
        "# print(sector_labels)\n",
        "label_names = label_names + sector_labels\n",
        "# print(label_names)\n",
        "x = np.arange(len(label_names))\n",
        "# print(len(x))\n",
        "# print(len(initial_correct_counts))\n",
        "\n",
        "\n",
        "\n",
        "width = 0.25  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,5), sharey=True)\n",
        "#x - width/2\n",
        "ax.set_ylim(bottom=0, top=max(initial_correct_counts + post_correct_counts)+50)\n",
        "rects1 = ax.bar(x - width/2, initial_correct_counts, width, label='Original Predictions', color='blue')\n",
        "rects2 = ax.bar(x+width/2, post_correct_counts, width, label='With Purity Correction', color='red')\n",
        "#rects2 = ax.bar(x + width/2, all_counts, width, label='All Colonies', color='red')\n",
        "#rects3 = ax.bar(x + width, true_correct_counts, width, label='Manual Counts', color='green')\n",
        "\n",
        "#print(true_single_frequency)\n",
        "#print(pred_single_frequency)\n",
        "\n",
        "ax.set_xlabel('Colony States')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title('Classified Colonies', fontsize=16)\n",
        "ax.xaxis.label.set_fontsize(14)\n",
        "ax.yaxis.label.set_fontsize(14)\n",
        "ax.set_xticks(np.arange(0, max_sector_counts+2, step=1))\n",
        "ax.set_xticklabels(label_names)\n",
        "ax.tick_params(axis='both', labelsize=12)\n",
        "ax.legend(loc='best')\n",
        "\n",
        "xtickslocs = ax.get_xticks()\n",
        "print(xtickslocs)\n",
        "\n",
        "addlabels_centered(xtickslocs-width/2, initial_correct_counts, 9)\n",
        "addlabels_centered(xtickslocs+width/2, post_correct_counts, 9)\n",
        "#addlabels_pred(x, all_counts, 10)\n",
        "#addlabels_truemarks(x, true_correct_counts, 9)\n",
        "\n",
        "ax.axvline(x = 0.5, color = 'k', linestyle = '--')\n",
        "ax.axvline(x = 1.5, color = 'k', linestyle = '--')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "yl9J4DrB6SxF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### With True Annotations"
      ],
      "metadata": {
        "id": "nGmZMZOX6T6l"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-wIjKbapsEH7"
      },
      "source": [
        "#### Colony States"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl3cqWbysEH7"
      },
      "outputs": [],
      "source": [
        "\n",
        "#print(sampled_colony_data.keys())\n",
        "#print(sampled_colony_data['Is it a colony? '])\n",
        "\n",
        "\n",
        "max_initial = np.max(colony_data['Initial # Regions'])\n",
        "max_pred = np.max(colony_data['Pred # Sectors'])\n",
        "max_true = np.max(colony_data['True # Sectors'])\n",
        "max_all = np.max([max_initial, max_pred, max_true])\n",
        "diff_count_before = np.abs(colony_data['Initial # Regions'] - colony_data['True # Sectors'])\n",
        "diff_count_after = np.abs(colony_data['Pred # Sectors'] - colony_data['True # Sectors'])\n",
        "\n",
        "initial_correct_counts = []\n",
        "post_correct_counts = []\n",
        "true_correct_counts = []\n",
        "all_counts = []\n",
        "\n",
        "label_names = ['[PSI+]', '[psi-]']\n",
        "\n",
        "# print(np.unique(colony_data['Label True']))\n",
        "\n",
        "# Gather [PSI+] counts\n",
        "true_white_labels = colony_data[(colony_data['Label True'] == '[PSI+]')]\n",
        "correct_white_labels_before = colony_data[(colony_data['Label True'] == '[PSI+]') & (colony_data['Label Before'] == '[PSI+]')]\n",
        "correct_white_labels_after = colony_data[(colony_data['Label True'] == '[PSI+]') & (colony_data['Label After'] == '[PSI+]')]\n",
        "\n",
        "initial_correct_counts.append(len(correct_white_labels_before))\n",
        "post_correct_counts.append(len(correct_white_labels_after))\n",
        "true_correct_counts.append(len(true_white_labels))\n",
        "\n",
        "# Gather [psi-] counts\n",
        "true_red_labels = colony_data[(colony_data['Label True'] == '[psi-]')]\n",
        "correct_red_labels_before = colony_data[(colony_data['Label True'] == '[psi-]') & (colony_data['Label Before'] == '[psi-]')]\n",
        "correct_red_labels_after = colony_data[(colony_data['Label True'] == '[psi-]') & (colony_data['Label After'] == '[psi-]')]\n",
        "\n",
        "initial_correct_counts.append(len(correct_red_labels_before))\n",
        "post_correct_counts.append(len(correct_red_labels_after))\n",
        "true_correct_counts.append(len(true_red_labels))\n",
        "\n",
        "\n",
        "# Gather sectored counts\n",
        "max_sector_counts = max([np.nanmax(colony_data['Initial # Regions'].astype(int)), np.nanmax(colony_data['Pred # Sectors'].astype(int)), np.nanmax(colony_data['True # Sectors'].astype(int))])\n",
        "# print(max_sector_counts)\n",
        "\n",
        "for this_num_sectors in range(1, max_sector_counts+1):\n",
        "    true_sector_labels = colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors))]\n",
        "    correct_sector_labels_before = colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors)) & (colony_data['Label Before'] == 'S'+str(this_num_sectors))]\n",
        "    correct_sector_labels_after = colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors)) & (colony_data['Label After'] == 'S'+str(this_num_sectors))]\n",
        "\n",
        "    initial_correct_counts.append(len(correct_sector_labels_before))\n",
        "    post_correct_counts.append(len(correct_sector_labels_after))\n",
        "    true_correct_counts.append(len(true_sector_labels))\n",
        "\n",
        "# print(colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors)) & (colony_data['Label After'] == 'S'+str(this_num_sectors))])\n",
        "sector_labels = ['S'+str(i) for i in (range(1, max_sector_counts+1))]\n",
        "# print(sector_labels)\n",
        "label_names = label_names + sector_labels\n",
        "# print(label_names)\n",
        "x = np.arange(len(label_names))\n",
        "# print(len(x))\n",
        "# print(len(initial_correct_counts))\n",
        "\n",
        "\n",
        "\n",
        "width = 0.25  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,5), sharey=True)\n",
        "#x - width/2\n",
        "ax.set_ylim(bottom=0, top=max(initial_correct_counts + post_correct_counts + true_correct_counts)+50)\n",
        "rects1 = ax.bar(x - width, initial_correct_counts, width, label='Original Predictions', color='blue')\n",
        "rects2 = ax.bar(x, post_correct_counts, width, label='With Purity Correction', color='red')\n",
        "#rects2 = ax.bar(x + width/2, all_counts, width, label='All Colonies', color='red')\n",
        "rects3 = ax.bar(x + width, true_correct_counts, width, label='Manual Counts', color='green')\n",
        "\n",
        "#print(true_single_frequency)\n",
        "#print(pred_single_frequency)\n",
        "\n",
        "ax.set_xlabel('Colony States')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title('Correctly Classified Quantifiable Colonies', fontsize=16)\n",
        "ax.xaxis.label.set_fontsize(14)\n",
        "ax.yaxis.label.set_fontsize(14)\n",
        "ax.set_xticks(np.arange(0, max_sector_counts+2, step=1))\n",
        "ax.set_xticklabels(label_names)\n",
        "ax.tick_params(axis='both', labelsize=12)\n",
        "ax.legend(loc='best')\n",
        "\n",
        "addlabels_initial(x, initial_correct_counts, 9)\n",
        "addlabels_prediction(x, post_correct_counts, 9)\n",
        "#addlabels_pred(x, all_counts, 10)\n",
        "addlabels_truemarks(x, true_correct_counts, 9)\n",
        "\n",
        "ax.axvline(x = 0.5, color = 'k', linestyle = '--')\n",
        "ax.axvline(x = 1.5, color = 'k', linestyle = '--')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tp8nxwlFsEH8"
      },
      "source": [
        "#### Confusion Matrices"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NyE7sqP1sEH-"
      },
      "outputs": [],
      "source": [
        "conf_mat_before = sklearn.metrics.confusion_matrix(colony_data['Label True'], colony_data['Label Before'], labels=label_names)\n",
        "# print(conf_mat_before)\n",
        "# print(type(conf_mat_before))\n",
        "# disp_before = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=conf_mat_before)\n",
        "\n",
        "# disp_before.plot()\n",
        "# plt.ylim([5.5, -0.5])\n",
        "# plt.title('Confusion Matrix of Sector Predictions\\nNo Purity Correction')\n",
        "# plt.ylabel('True # Sectors')\n",
        "# plt.xlabel('Predicted # Sectors')\n",
        "\n",
        "#plt.show()\n",
        "\n",
        "conf_mat_after = sklearn.metrics.confusion_matrix(colony_data['Label True'], colony_data['Label After'], labels=label_names)\n",
        "#disp_after = sklearn.metrics.ConfusionMatrixDisplay(confusion_matrix=conf_mat_after)\n",
        "\n",
        "#disp_after.plot()\n",
        "#plt.title('Confusion Matrix of Sector Predictions\\nWith Purity Correction')\n",
        "#plt.ylabel('True # Sectors')\n",
        "#plt.xlabel('Predicted # Sectors')\n",
        "\n",
        "#plt.show()\n",
        "\n",
        "\n",
        "\n",
        "ax = sns.heatmap(conf_mat_before, annot=True, fmt='.5g')\n",
        "ax.set_xlabel('Predicted States')\n",
        "ax.set_ylabel('True States')\n",
        "ax.set_title('Confusion Matrix of Colony Predictions\\nOriginal Predictions')\n",
        "ax.set_xticklabels(label_names, rotation=0)\n",
        "ax.set_yticklabels(label_names, rotation=0)\n",
        "plt.show()\n",
        "\n",
        "ax = sns.heatmap(conf_mat_after, annot=True, fmt='.5g')\n",
        "ax.set_xlabel('Predicted States')\n",
        "ax.set_ylabel('True # States')\n",
        "ax.set_title('Confusion Matrix of Colony Predictions\\nWith Purity Correction')\n",
        "ax.set_xticklabels(label_names, rotation=0)\n",
        "ax.set_yticklabels(label_names, rotation=0)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IpCXE01DsEH_"
      },
      "outputs": [],
      "source": [
        "# Look at the incorrectly labeled colonies\n",
        "\n",
        "incorrect_before = colony_data[(colony_data['Label True'] == 'S1') & (colony_data['Label Before'] != 'S1')]\n",
        "incorrect_after = colony_data[(colony_data['Label True'] == 'S1') & (colony_data['Label After'] != 'S1')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9A1ZJdosEH_"
      },
      "outputs": [],
      "source": [
        "incorrect_after\n",
        "fig,ax = plt.subplots()\n",
        "ax.hist(incorrect_before['Red Area (Seg)'] / incorrect_before['Colony Area (Seg)'], bins = 100)\n",
        "ax.set_title('Percentage of Colony Covered by its Sector\\nIncorrect Classsifications Before (N=' + str(len(incorrect_before['Red Area (Seg)'])) + ')')\n",
        "ax.set_xlabel('Proportion of Red')\n",
        "ax.set_ylabel('Frequency')\n",
        "fig.show()\n",
        "\n",
        "fig,ax = plt.subplots()\n",
        "ax.hist(incorrect_after['Red Area (Seg)'] / incorrect_after['Colony Area (Seg)'], bins = 100)\n",
        "ax.set_title('Percentage of Colony Covered by its Sector\\nIncorrect Classsifications After (N=' + str(len(incorrect_after['Red Area (Seg)'])) + ')')\n",
        "ax.set_xlabel('Proportion of Red')\n",
        "ax.set_ylabel('Frequency')\n",
        "fig.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7t-wDbEvsEHx"
      },
      "outputs": [],
      "source": [
        "colony_states_before = np.array(['UNFILLED' for i in range(0, len(colony_data))])\n",
        "colony_states_after = np.array(['UNFILLED' for i in range(0, len(colony_data))])\n",
        "colony_states_true = np.array(['UNFILLED' for i in range(0, len(colony_data))])\n",
        "#colony_states_set = set(colony_states)\n",
        "#print(colony_states_set)\n",
        "\n",
        "max_sector_count_before = max(colony_data['Initial # Regions'])\n",
        "max_sector_count_after = max(colony_data['Pred # Sectors'])\n",
        "max_sector_count_true = max(colony_data['True # Sectors'])\n",
        "\n",
        "max_sector_count_all = max([max_sector_count_before, max_sector_count_after, max_sector_count_true])\n",
        "\n",
        "# [PSI+]: Get all colonies with no red regions\n",
        "\n",
        "colony_states_before[(colony_data['(BC) Stable'] == True)] = '[PSI+]'\n",
        "colony_states_after[(colony_data['(AC) Stable'] == True)] = '[PSI+]'\n",
        "colony_states_true[(colony_data['Is Stable?'] == True)] = '[PSI+]'\n",
        "\n",
        "# [psi-]: Get all quantifiable colonies with no white regions\n",
        "\n",
        "colony_states_before[(colony_data['(BC) Cured'] == True)] = '[psi-]'\n",
        "colony_states_after[(colony_data['(AC) Cured'] == True)] = '[psi-]'\n",
        "colony_states_true[(colony_data['Is Cured?'] == True)] = '[psi-]'\n",
        "\n",
        "# Sx: Get all quantifiable colonies with at least 1 white region and exactly x red regions \n",
        "\n",
        "for num_regions in range(1, max_sector_count_all+1):\n",
        "    colony_states_before[(colony_data['(BC) Cured'] == False) & (colony_data['(BC) Stable'] == False) & (colony_data['Initial # Regions'] == num_regions)] = str('S' + str(num_regions))\n",
        "    colony_states_after[(colony_data['(AC) Cured'] == False) & (colony_data['(AC) Stable'] == False) & (colony_data['Pred # Sectors'] == num_regions)] = str('S' + str(num_regions))\n",
        "    colony_states_true[(colony_data['Is Cured?'] == False) & (colony_data['Is Stable?'] == False) & (colony_data['True # Sectors'] == num_regions).astype(bool)] = str('S' + str(num_regions))\n",
        "\n",
        "#print(np.unique(colony_states_before))\n",
        "#print(np.unique(colony_states_after))\n",
        "#print(np.unique(colony_states_true))\n",
        "\n",
        "unmarked_locations = np.where(colony_states_true == 'UNFILLED')\n",
        "\n",
        "# Make corrections to the table for unfilled locations\n",
        "\n",
        "\n",
        "# Display any colony locations what are marked as UNFILLED\n",
        "\n",
        "colony_row = colony_data.iloc[unmarked_locations]\n",
        "#print(colony_row)\n",
        "#print(colony_row.index)\n",
        "\n",
        "#print(colony_states_before)\n",
        "\n",
        "# If every location has been filled, then add these to the merged table\n",
        "colony_data['Label Before'] = colony_states_before\n",
        "colony_data['Label After'] = colony_states_after\n",
        "colony_data['Label True'] = colony_states_true\n",
        "\n",
        "#print(quantifiable_colony_data['Label Before'])\n",
        "# counter = 0\n",
        "\n",
        "# for ind in colony_row.index:\n",
        "#     colony_number = colony_row['Colony Number'].iloc[counter]\n",
        "#     plate_name = colony_row['Plate Name'].iloc[counter]\n",
        "#     set_number = colony_row['Set'].iloc[counter]\n",
        "\n",
        "#     #if counter == 0:\n",
        "#     #    merged_table['Quantifiable Stable'] = \n",
        "\n",
        "#     # Get image\n",
        "#     if set_number == 2:\n",
        "#         image_to_display = read_image(sector_project_folder + '/Real Images/Wes Plates/Set 2 Prepro/' + plate_name)*255\n",
        "#     image_to_display = cv2.rectangle(image_to_display, (colony_row['Side Left'].iloc[counter], colony_row['Side Top'].iloc[counter]), (colony_row['Side Right'].iloc[counter], colony_row['Side Bottom'].iloc[counter]), (255, 0, 0), 2)\n",
        "#     #cv2_imshow(image_to_display)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# TESTING Image Segmentation and Classification"
      ],
      "metadata": {
        "id": "aks8Z4iaqNSf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get locations of testing images"
      ],
      "metadata": {
        "id": "vsE4URThqlhJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dYfPeEVxqCl6"
      },
      "outputs": [],
      "source": [
        "test_images = sorted(glob.glob(real_image_folder + '/' + '*'))\n",
        "print('Number of images found: ' + str(len(test_images)))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Segment testing images"
      ],
      "metadata": {
        "id": "mXKL7Y2Pqoeo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AlSZTEsS0DFd"
      },
      "outputs": [],
      "source": [
        "# Code for image segmentation (involves Python and Octave code (requires oct2py module))\n",
        "# 1. Python - Ready u_net for input.\n",
        "# 2. Python - Feed image to U-Net.\n",
        "# 3. Python - Get output segmentation of image.\n",
        "# 4. Octave - Use isolated colonies to estimate a range of radii to search for circular colonies.\n",
        "# 5. Octave - Obtain centers and radii in image with circle Hough transform.\n",
        "# 6. Octave (or Python maybe pandas) - Save csv files of circle locations and sizes in each image respectively.\n",
        "# 7. Octave (or Python maybe matplotlib) - Make mask of image showing where the circles are found.\n",
        "# 8. Repeat steps 2-7 for each image\n",
        "\n",
        "if get_testing_segs == True:\n",
        "\n",
        "    %matplotlib inline\n",
        "\n",
        "    for this_image in test_images:\n",
        "\n",
        "        # Steps 1-3: get output segmentation and save it\n",
        "\n",
        "        this_plate = pathlib.PurePath(this_image)\n",
        "        plate_name = this_plate.name\n",
        "\n",
        "        print('Reading plate: ' + str(plate_name))\n",
        "\n",
        "        x = read_image(this_image)\n",
        "        \n",
        "        # Predict the class of each pixel, and partition output the same way\n",
        "        p = model.predict(np.expand_dims(x,axis=0))[0]\n",
        "        p = np.argmax(p,axis=-1)\n",
        "        p = np.expand_dims(p,axis=-1)\n",
        "        p = p * (255/(num_classes-1))\n",
        "        print(p.shape)\n",
        "        #print(np.max(p))\n",
        "        p = p.astype(np.int32)\n",
        "        #print(np.max(p))\n",
        "\n",
        "        p_full = tf.identity(p).numpy()\n",
        "        in_class = tf.math.greater(tf.constant(p_full), tf.constant([0])).numpy()\n",
        "\n",
        "        p = p.astype(np.uint8)\n",
        "        # white pixels (should be 255)\n",
        "        p_1 = tf.math.equal(tf.constant(p_full), tf.constant([255])).numpy().astype(np.uint8) * 255\n",
        "        # red pixels (should be 127)\n",
        "        p_2 = tf.math.equal(tf.constant(p_full), tf.constant([127])).numpy().astype(np.uint8) * 255\n",
        "        p_full = 255 * in_class.astype(np.uint8)\n",
        "        #print(p.shape)\n",
        "\n",
        "        cv2_imshow(p)\n",
        "        \n",
        "        # Show and/or save image\n",
        "        #plt.imshow(p * 255/(num_classes-1))\n",
        "        #cv2.cvtColor(p * 255/(num_classes-1), cv2.COLOR_BGR2RGB)\n",
        "        #plt.imshow(cv2.cvtColor(p * 255/(num_classes-1), cv2.COLOR_BGR2GRAY))\n",
        "        #plt.imshow(p, cmap='binary')\n",
        "        #plt.show()\n",
        "        #print(np.unique(p[20:40, 900:920]))\n",
        "        my_image = PIL.Image.fromarray(np.squeeze(p, axis=-1), \"L\")\n",
        "        #display(my_image.resize((256,256)))\n",
        "        my_image.save(test_seg_folder + '/' + this_plate.stem + '.png')\n",
        "\n",
        "        # Steps 4-6: Run Matlab code in Octave to use CHT, and store colony location data\n",
        "        octave.feval('get_circular_data.m', this_image, test_seg_folder + '/' + this_plate.stem + '.png', test_circle_data_folder)\n",
        "        try:\n",
        "            radii_table = pd.read_csv(test_circle_data_folder + '/' + this_plate.stem + '.csv', header=None)\n",
        "            radii_table.columns = ['Colony', 'Center (x)', 'Center (y)', 'Radius', 'Top Left (x)', 'Top Left (y)', 'Width', 'Height', 'Estimated Center (x)', 'Estimated Center (y)']\n",
        "            radii_table.to_csv(test_circle_data_folder + '/' + this_plate.stem + '.csv')\n",
        "\n",
        "            # Step 7: Plot the image with the circles overlayed, and save it\n",
        "            #radii_table = pd.read_csv(test_circle_data_folder + '/' + this_plate.stem + '.csv')\n",
        "\n",
        "            fig, ax = plt.subplots()\n",
        "            plt.imshow(cv2.cvtColor(x, cv2.COLOR_BGR2RGB))\n",
        "            fig.set_size_inches(1024/96, 1024/96)\n",
        "            for index, row in radii_table.iterrows():\n",
        "                full_circle = Circle((row['Estimated Center (x)'], row['Estimated Center (y)']), radius=row['Radius'], color='blue', fill=False, linewidth=1, alpha=0.9)\n",
        "                ax.add_patch(full_circle)\n",
        "            plt.axis('off')\n",
        "            plt.savefig(test_circle_folder + '/' + pathlib.Path(this_image).stem + '.jpg', bbox_inches='tight', pad_inches=0)\n",
        "            plt.close()\n",
        "\n",
        "        except pd.errors.EmptyDataError: # If an error is about to be thrown due to an empty csv file, run these lines instead\n",
        "            print('No colonies were detected.  Skipping this image.')\n",
        "            my_table_columns = ['Colony', 'Center (x)', 'Center (y)', 'Radius', 'Top Left (x)', 'Top Left (y)', 'Width', 'Height', 'Estimated Center (x)', 'Estimated Center (y)']\n",
        "            radii_table = pd.DataFrame(columns=my_table_columns)\n",
        "            radii_table.to_csv(test_circle_data_folder + '/' + this_plate.stem + '.csv')\n",
        "\n",
        "            # Step 7: Plot the image with the circles overlayed, and save it\n",
        "            #radii_table = pd.read_csv(test_circle_data_folder + '/' + this_plate.stem + '.csv')\n",
        "\n",
        "            fig, ax = plt.subplots()\n",
        "            plt.imshow(cv2.cvtColor(x, cv2.COLOR_BGR2RGB))\n",
        "            fig.set_size_inches(1024/96, 1024/96) # set because the small screen pixel size is 96 dpi\n",
        "            plt.axis('off')\n",
        "            plt.savefig(test_circle_folder + '/' + pathlib.Path(this_image).stem + '.jpg', bbox_inches='tight', pad_inches=0)\n",
        "            plt.close()\n",
        "        #print(radii_table)\n",
        "        #raise FileExistsError('The script finished without errors.')\n",
        "        #octave.run('octave_test.m')\n",
        "        \n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Get names of segmented testing images"
      ],
      "metadata": {
        "id": "c3c33gd9q9b7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_images = sorted(glob.glob(real_image_folder + '/' + '*'))\n",
        "print('Number of images found: ' + str(len(test_images)))\n",
        "\n",
        "test_CHT_images = sorted(glob.glob(test_circle_folder + '/' + '*'))\n",
        "print('Number of images found: ' + str(len(test_CHT_images)))\n",
        "\n",
        "test_image_pairs = tuple(zip(test_images, test_CHT_images))\n",
        "print(test_image_pairs)\n",
        "\n",
        "\n",
        "# Create reference table for plate names, and store it as a csv file in the main annotation directory\n",
        "file_dict = {}\n",
        "for this_plate_number in range(1, len(test_images)+1):\n",
        "    this_plate = pathlib.PurePath(test_images[this_plate_number - 1])\n",
        "    plate_name = this_plate.name\n",
        "    plate_stem = os.path.splitext(plate_name)[0]\n",
        "    file_dict[plate_name] = 'Plate ' + str(this_plate_number)\n",
        "print(file_dict)\n",
        "file_items = file_dict.items()\n",
        "file_list = list(file_items)\n",
        "file_df = pd.DataFrame(file_items, columns = ['Plate Name', 'Folder Name'])\n",
        "print(file_df)\n",
        "\n",
        "\n",
        "# If you are trying to save the crops and annotations of each colony, the below will run as well.\n",
        "\n",
        "if save_all_annotations == True:\n",
        "\n",
        "    # Save this table as a csv file\n",
        "    file_df.to_csv(output_crops_folder + '/Plate_References.csv')\n",
        "\n",
        "    for index, row in file_df.iterrows():\n",
        "\n",
        "        # Make subdirectories for each annotation class, organized by plate\n",
        "        if os.path.exists(output_crops_folder + '/raw/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/raw/' + row['Folder Name']) # where the original colonies are cropped and stored\n",
        "\n",
        "        if use_expert_counts == True:\n",
        "            if os.path.exists(output_crops_folder + '/counted/' + row['Folder Name']) == False:\n",
        "                os.makedirs(output_crops_folder + '/counted/' + row['Folder Name']) # where the original quantifiable colonies are cropped and stored\n",
        "\n",
        "        if os.path.exists(output_crops_folder + '/circles/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/circles/' + row['Folder Name']) # same as before, but a circle is overlayed on the colony\n",
        "\n",
        "        if os.path.exists(output_crops_folder + '/segs/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/segs/' + row['Folder Name']) # the output from the U-Net segmentation such that only nonzero pixels in the circle are kept\n",
        "\n",
        "\n",
        "        if os.path.exists(output_crops_folder + '/init_regions/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/init_regions/' + row['Folder Name']) # A segmentation outlining the possible sector-like regions of the colony, both red and white\n",
        "\n",
        "        if os.path.exists(output_crops_folder + '/init_bounds/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/init_bounds/' + row['Folder Name']) # The raw segmentation containing only the boundary of the colony\n",
        "\n",
        "        if os.path.exists(output_crops_folder + '/init_partitions/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/init_partitions/' + row['Folder Name']) # same as the raw segmentation, but with lines annotated to represent locations of sector borders\n",
        "\n",
        "        if os.path.exists(output_crops_folder + '/init_bad/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/init_bad/' + row['Folder Name']) # A segmentation outlining the sector-like regions that failed the consistency check\n",
        "\n",
        "\n",
        "        if os.path.exists(output_crops_folder + '/cor_segs/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/cor_segs/' + row['Folder Name']) # the output from the U-Net segmentation such that only nonzero pixels in the circle are kept\n",
        "\n",
        "        if os.path.exists(output_crops_folder + '/cor_bounds/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/cor_bounds/' + row['Folder Name']) # The corrected segmentation containing only the boundary of the colony\n",
        "\n",
        "        if os.path.exists(output_crops_folder + '/cor_regions/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/cor_regions/' + row['Folder Name']) # the output from the U-Net segmentation such that only nonzero pixels in the circle are kept\n",
        "\n",
        "        if os.path.exists(output_crops_folder + '/cor_partitions/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/cor_partitions/' + row['Folder Name']) # same as the raw segmentation, but with lines annotated to represent locations of sector borders\n",
        "\n",
        "        if os.path.exists(output_crops_folder + '/cor_bad/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/cor_bad/' + row['Folder Name']) # A segmentation outlining the sector-like regions that failed the consistency check\n",
        "\n",
        "\n",
        "        if os.path.exists(output_crops_folder + '/sectors/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/sectors/' + row['Folder Name']) # the output containing the regions in the segmentation where a sector is predicted\n",
        "\n",
        "        if os.path.exists(output_crops_folder + '/sector_comps/' + row['Folder Name']) == False:\n",
        "            os.makedirs(output_crops_folder + '/sector_comps/' + row['Folder Name']) # same as before, but only red pxieks in the segmentation are considered"
      ],
      "metadata": {
        "id": "NDwigt1QrCsh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qh74WEI_sEGd"
      },
      "source": [
        "## Classify colonies in testing images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfqGz80FsEGe"
      },
      "outputs": [],
      "source": [
        "# Code for colony classification (this should be all python code)\n",
        "# 1. Read in image and corresponding segmentation.\n",
        "# 2. Read in csv files containing circle locations.\n",
        "# 3. For each row in the csv file, crop out the circular region, estimate size.\n",
        "# 4. Restrict data collection to pixels within the circle detected, exclusing all other pixels.\n",
        "# 5. Split the components of the image into red, white and background.\n",
        "# 6. Get boundary components of the colony, check for consistency.\n",
        "# 7. Output predicted number of sectors and their sizes after the consistency check.\n",
        "# 8. Save the cropping of the colony in a few ways:\n",
        "#   - the raw colony\n",
        "#   - the raw colony with circle overlayed\n",
        "#   - the segmentation of the colony within the circular region\n",
        "#   - the segmentation of the colony with lines drawn on the image to repreent sector borders\n",
        "#   - the predicted sector like regions, where each sector is a different shade of gray.\n",
        "#   - similar to the previous, but keeping pixels classified only as red pixels.\n",
        "#   - the segmentation that is corrected following the consistency check (possibly doing an additional check on the white pixels)\n",
        "# 9. Save data on the colony itself, including the sector information, to a row in a table.\n",
        "# 10. Save the table to a csv file.\n",
        "# 11. Repeat all steps above for each image.\n",
        "\n",
        "# Issues to work on:\n",
        "# Verify that the purity metric is properly being utilized\n",
        "# Figure out what to do with the holes inside colony segmentations.\n",
        "#   -- A hole has its own boundary, so could look for the boundary of the hole.\n",
        "#   -- The boundary of the hole MUST be smaller than the boundary of the entire colony\n",
        "#   -- Find all connected compoents of the boundary, then exclude the LARGEST one.\n",
        "#   -- For all other boundary components, these are expected to be the holes.  You need a procedure to fill them.\n",
        "#   -- The procedure could be as simple as filling the hole with the class pertaining to the most common pixel on the boundary.\n",
        "\n",
        "# Implementation already existing:\n",
        "\n",
        "\n",
        "\n",
        "if classify_testing_colonies == True:\n",
        "\n",
        "    %matplotlib inline\n",
        "\n",
        "    starting_image = True\n",
        "\n",
        "    if use_expert_counts == True:\n",
        "        dot_quant_images = sorted(glob.glob(additional_data_folder + '/Quant/' + '*'))\n",
        "        dot_state_images = sorted(glob.glob(additional_data_folder + '/State/' + '*'))\n",
        "\n",
        "\n",
        "    # Run each plate through the classification pipeline\n",
        "\n",
        "    for (test_image, CHT_image) in test_image_pairs:\n",
        "\n",
        "        # Get plate name \n",
        "        this_plate = pathlib.PurePath(test_image)\n",
        "        plate_name = this_plate.name\n",
        "        plate_stem = os.path.splitext(plate_name)[0]\n",
        "\n",
        "        print('Plate: ' + str(plate_name) + ':')\n",
        "        if save_all_annotations == True:\n",
        "            print('Annotations will be saved within subfolders named ' + \"\\'\" + file_dict[plate_name] + \"\\'\")\n",
        "\n",
        "        # Read images of the plate\n",
        "        x = read_image(test_image)\n",
        "        x_CHT = read_image(CHT_image)\n",
        "\n",
        "        # initialize lists for storing values\n",
        "        all_cropped_colonies = []\n",
        "\n",
        "        # Sizes of regions in pixels\n",
        "        white_region_sum = []\n",
        "        red_region_sum = []\n",
        "        colony_region_sum = []\n",
        "        sector_region_sum = []\n",
        "\n",
        "        corrected_white_region_sum = []\n",
        "        corrected_red_region_sum = []\n",
        "        corrected_sector_region_sum = []\n",
        "\n",
        "        true_white_region_sum = []\n",
        "        true_red_region_sum = []\n",
        "        true_colony_region_sum = []\n",
        "        true_sector_region_sum = []\n",
        "\n",
        "        # Counting sectors\n",
        "        initial_region_counts = []\n",
        "        all_sector_counts = []\n",
        "        true_sector_counts = []\n",
        "\n",
        "        \n",
        "\n",
        "        boundary_region_sum = []\n",
        "        colony_prop_sum = []\n",
        "\n",
        "        # Purity scores for regions and colonies\n",
        "        average_sector_score = []\n",
        "        average_sector_iou = []\n",
        "\n",
        "        weighted_sector_score_before = []\n",
        "        weighted_red_sector_score_before = []\n",
        "        weighted_white_sector_score_before = []\n",
        "\n",
        "        weighted_sector_score_after = []\n",
        "        weighted_red_sector_score_after = []\n",
        "        weighted_white_sector_score_after = []\n",
        "\n",
        "        # Bounding box info for colonies in images\n",
        "        sides_vert_top = [];\n",
        "        sides_vert_bottom = [];\n",
        "        sides_horz_left = [];\n",
        "        sides_horz_right = [];\n",
        "\n",
        "        # Test lists\n",
        "        colony_is_connected = []\n",
        "        colony_is_approx_connected = []\n",
        "        boundary_is_connected = []\n",
        "        colony_is_whole = []\n",
        "        boundary_is_hamilton = []\n",
        "        colony_is_approx_convex = []\n",
        "        colony_is_approx_circular = []\n",
        "        hausdorff_dist_convex = []\n",
        "        hausdorff_dist_circle = []\n",
        "\n",
        "        # Lists to store purity scores of each region and the color of the region\n",
        "        region_purity_before = []\n",
        "        region_color_before = []\n",
        "        region_sizes_before = []\n",
        "\n",
        "        weighted_purity_before = []\n",
        "        weighted_purity_red_before = []\n",
        "        weighted_purity_white_before = []\n",
        "\n",
        "        region_purity_after = []\n",
        "        region_color_after = []\n",
        "        region_sizes_after = []\n",
        "\n",
        "        weighted_purity_after = []\n",
        "        weighted_purity_red_after = []\n",
        "        weighted_purity_white_after = []\n",
        "\n",
        "        cured_colony_before = []\n",
        "        cured_colony_after = []\n",
        "\n",
        "        stable_colony_before = []\n",
        "        stable_colony_after = []\n",
        "\n",
        "        # Load images here if using quantifable colony data/annotations\n",
        "        if use_expert_counts == True:\n",
        "            x_quant = read_image(additional_data_folder + '/Quant/' + plate_stem + '.tif')\n",
        "            x_state = read_image(additional_data_folder + '/State/' + plate_stem + '.tif')\n",
        "            quantifiable_colony = []\n",
        "            quantifiable_cured = []\n",
        "            quantifiable_stable = []\n",
        "            quantifiable_sectored = []\n",
        "\n",
        "        #------------------------------\n",
        "        # Read in plate and locate colonies\n",
        "        #------------------------------\n",
        "        \n",
        "        # Read the segmentation of the plate, and keep track of which class each pixel belongs to\n",
        "        p = read_mask(test_seg_folder + '/' + this_plate.stem + '.png')\n",
        "        #p = read_mask(main_folder + '/Test Segs/' + specific_test_folder + '/Class_3/' + this_plate.stem + '.png')\n",
        "\n",
        "        p_full = tf.identity(p).numpy()\n",
        "        in_class = tf.math.greater(tf.constant(p_full), tf.constant([0])).numpy()\n",
        "\n",
        "        p = p.astype(np.uint8)\n",
        "        # white pixels\n",
        "        p_1 = tf.math.equal(tf.constant(p_full), tf.constant([255])).numpy().astype(np.uint8) * 255\n",
        "        # red pixels\n",
        "        p_2 = tf.math.equal(tf.constant(p_full), tf.constant([127])).numpy().astype(np.uint8) * 255\n",
        "        p_full = 255 * in_class.astype(np.uint8)\n",
        "\n",
        "        # Gather the location and radii data from the colonies\n",
        "        # If there are no colonies detected, or there is no table, skip this section at once\n",
        "\n",
        "        colony_locations = pd.read_csv(test_circle_data_folder + '/' + pathlib.Path(test_image).stem + '.csv')\n",
        "        #colony_locations = pd.read_csv(main_folder + '/Test Segs CHT Data/' + specific_test_folder + '/Class_3/' + pathlib.Path(test_image).stem + '.csv')\n",
        "\n",
        "        # Output information from the imported csv\n",
        "        print(str(len(colony_locations[\"Radius\"])) + ' colonies found using circle Hough transform')\n",
        "        plate_names = np.repeat(plate_name, len(colony_locations[\"Radius\"]))\n",
        "        colony_numbers = np.array(range(len(colony_locations[\"Radius\"])))\n",
        "\n",
        "        #---------------------------------------------------------------------\n",
        "\n",
        "        # CLASSIFICATION PIPELINE START\n",
        "        # Pre-processing step\n",
        "\n",
        "        # Images to save:\n",
        "        # - Cropping of the colony\n",
        "        # - Cropping of the colony with the overalyed circle\n",
        "        # - Original colony segmentation, such that only the pixels inside the overlayed circle are considered.\n",
        "\n",
        "        for this_index in range(0,len(colony_numbers)):\n",
        "\n",
        "            print('')\n",
        "            print('Colony ' + str(this_index))\n",
        "            # get example image using bounding indices\n",
        "            #this_index = 2\n",
        "\n",
        "            # Copy location data from colony image\n",
        "            top_left_x = colony_locations[\"Top Left (x)\"][this_index]\n",
        "            top_left_y = colony_locations[\"Top Left (y)\"][this_index]\n",
        "            box_width = colony_locations[\"Width\"][this_index]\n",
        "            box_height = colony_locations[\"Height\"][this_index]\n",
        "\n",
        "            # Store the locations in another set of lists\n",
        "            sides_vert_top.append(top_left_y)\n",
        "            sides_vert_bottom.append(top_left_y + box_height - 1)\n",
        "            sides_horz_left.append(top_left_x)\n",
        "            sides_horz_right.append(top_left_x + box_width - 1)\n",
        "\n",
        "            # Grab segmentation of colony using coordinates copied above\n",
        "            # The colony image is NOT a boolean array\n",
        "            colony_image = p[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1)]\n",
        "            ellipse_array = create_filled_ellipse_in_array(colony_image)\n",
        "            colony_image = np.multiply(colony_image, ellipse_array) # unpadded segmentation with the pixels inside the overlayed circle\n",
        "\n",
        "            if use_expert_counts == True:\n",
        "                quant_image = x_quant[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1), :]\n",
        "                state_image = x_state[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1), :]\n",
        "\n",
        "            # The colony mask IS a boolean array.  Keep all the pixels of each class.\n",
        "            white_colony_mask = p_1[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1)] > 0\n",
        "            red_colony_mask = p_2[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1)] > 0 \n",
        "            colony_mask = np.logical_or(white_colony_mask, red_colony_mask) # sanity check to see of this is the same as colony image\n",
        "\n",
        "            # Add segmentation of the pixels inside the circular region of detection, and apply the mask.  This ensures we only use the pixels inside the circle for analysis.\n",
        "            # Booleans are inputs, and booleans are outputs\n",
        "            # Force a circle in colonies detected in the circle detection step\n",
        "            white_colony_mask = np.multiply(white_colony_mask, ellipse_array)\n",
        "            red_colony_mask = np.multiply(red_colony_mask, ellipse_array)\n",
        "            colony_mask = np.logical_or(white_colony_mask, red_colony_mask)\n",
        "\n",
        "            # Get initial measure of the sizes of the red and white regions of the colony\n",
        "            white_region_sum.append(np.sum(white_colony_mask))\n",
        "            red_region_sum.append(np.sum(red_colony_mask))\n",
        "            colony_region_sum.append(np.sum(colony_mask))\n",
        "            sector_region_sum.append(np.sum(red_colony_mask) / np.sum(colony_mask))\n",
        "\n",
        "            # Find colony boundaries, ensuring that the boundaries are ON the colony, not ADJACENT to it.\n",
        "            edge_mask_unpadded = get_colony_boundary_binary(colony_image) # The function is above\n",
        "            interior_mask_unpadded = np.logical_xor(colony_image > 0, edge_mask_unpadded) # Second mask containing only the interior pixels of the segmentation\n",
        "            interior_colony = np.multiply(colony_image, interior_mask_unpadded) # This is NOT a boolean\n",
        "\n",
        "            #---------------------------------------------------------------\n",
        "            # Get quantifiable colony labels (if applicable)\n",
        "            #---------------------------------------------------------------\n",
        "\n",
        "            # If we have locations of quantifiable colonies, use this to gather the colonies.\n",
        "            if use_expert_counts == True:\n",
        "                #----------------------------------\n",
        "                # Determine where the quantifiable colonies are (they have black dots on them)\n",
        "                # Set color boundaries for the markers in the counted images\n",
        "                black_dot_boundaries = [([0, 0, 0], [5, 5, 5])]\n",
        "\n",
        "                for (lower, upper) in black_dot_boundaries:\n",
        "                # create NumPy arrays from the boundaries\n",
        "                    lower = np.array(lower, dtype = \"uint8\")\n",
        "                    upper = np.array(upper, dtype = \"uint8\")\n",
        "                    # find the colors within the specified boundaries and apply\n",
        "                    # the mask\n",
        "                    dot_mask = cv2.inRange((quant_image*255).astype(np.uint8), lower, upper)\n",
        "                    #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n",
        "                    # Get connected components of the detected pixels\n",
        "                    black_labels = label(dot_mask)\n",
        "                    num_black_labels = len(np.unique(black_labels))\n",
        "                    if num_black_labels <= 1:\n",
        "                        # No dot was detected.  Thus the colony was considered non-quantifiable.\n",
        "                        colony_is_quantifiable = False\n",
        "                    else:\n",
        "                        # Loop through each component.  Find one component that is not too small and is directly on the colony\n",
        "                        colony_center_y = (quant_image.shape[0] - 1) / 2.0\n",
        "                        colony_center_x = (quant_image.shape[1] - 1) / 2.0\n",
        "                        for this_comp in range(1, num_black_labels):\n",
        "                            this_dot_comp = black_labels == this_comp\n",
        "                            # Get centroid of component\n",
        "                            (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(this_dot_comp)\n",
        "                            dot_dist = math.sqrt(((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n",
        "                            if dot_dist < colony_locations[\"Radius\"][this_index]:\n",
        "                                colony_is_quantifiable = True\n",
        "                                break\n",
        "                                # end the loop, as we found a dot on the colony\n",
        "                            \n",
        "                            if this_comp == (num_black_labels - 1):\n",
        "                                # We looped through all the dots, but none of them were on the colony.  Don't analyze this colony.\n",
        "                                colony_is_quantifiable = False\n",
        "\n",
        "                quantifiable_colony.append(colony_is_quantifiable)\n",
        "\n",
        "                #print('Colony', this_index, ': Quantifiable:', colony_is_quantifiable)\n",
        "\n",
        "                #----------------------------------------\n",
        "                # Determine if colony is cured, stable, or sectored\n",
        "\n",
        "                # RGB version\n",
        "                # cured_dot_boundaries = [([34-5, 177-5, 76-5], [34+5, 177+5, 76+5])]\n",
        "                # stable_dot_boundaries = [([237-5, 28-5, 36-5], [237+5, 28+5, 36+5])]\n",
        "                # sectored_dot_boundaries = [([63-5, 72-5, 204-5], [63+5, 72+5, 204+5])]\n",
        "\n",
        "                # BGR version (cv2 needs this)\n",
        "                # Marker colors were manaully chosen, so info below is based on that.\n",
        "                # Wes annotations\n",
        "                cured_dot_boundaries = [([76-5, 177-5, 34-5], [76+5, 177+5, 34+5])]\n",
        "                stable_dot_boundaries = [([36-5, 28-5, 237-5], [36+5, 28+5, 237+5])]\n",
        "                sectored_dot_boundaries = [([204-5, 72-5, 63-5], [204+5, 72+5, 63+5])]\n",
        "\n",
        "                # Nicole annotations\n",
        "                # cured_dot_boundaries = [([0, 250, 0], [0, 255, 0])]\n",
        "                # stable_dot_boundaries = [([0, 0, 250], [0, 0, 255])]\n",
        "                # sectored_dot_boundaries = [([250, 250, 0], [255, 255, 0])]\n",
        "\n",
        "                # cured_dot_boundaries = [([0, 250, 0], [0, 255, 0])]\n",
        "                # stable_dot_boundaries = [([0, 0, 250], [0, 0, 255])]\n",
        "                # sectored_dot_boundaries = [([250, 0, 0], [255, 0, 0])]\n",
        "\n",
        "                for (lower, upper) in cured_dot_boundaries:\n",
        "                # create NumPy arrays from the boundaries\n",
        "                    lower = np.array(lower, dtype = \"uint8\")\n",
        "                    upper = np.array(upper, dtype = \"uint8\")\n",
        "                    # find the colors within the specified boundaries and apply\n",
        "                    # the mask\n",
        "                    #print(np.unique((colony_image*255).astype(np.uint8)))\n",
        "                    dot_mask = cv2.inRange((state_image*255).astype(np.uint8), lower, upper)\n",
        "                    #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n",
        "                    # Get connected components of the detected dot pixels\n",
        "                    #print(np.unique(dot_mask))\n",
        "                    cured_labels = label(dot_mask)\n",
        "                    num_cured_labels = len(np.unique(cured_labels))\n",
        "                    if num_cured_labels <= 1:\n",
        "                        # No dot was detected.  Thus the colony was considered non-quantifiable.\n",
        "                        colony_is_cured = False\n",
        "                    else:\n",
        "                        # Loop through each component.  Find one component that is not too small and is directly on the colony\n",
        "                        colony_center_y = (state_image.shape[0] - 1) / 2.0\n",
        "                        colony_center_x = (state_image.shape[1] - 1) / 2.0\n",
        "                        for this_comp in range(1, num_cured_labels):\n",
        "                            this_dot_comp = cured_labels == this_comp\n",
        "                            # Get centroid of component\n",
        "                            (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(this_dot_comp)\n",
        "                            dot_dist = math.sqrt(((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n",
        "                            if dot_dist < colony_locations[\"Radius\"][this_index]:\n",
        "                                colony_is_cured = True\n",
        "                                break\n",
        "                                # end the loop, as we found a dot on the colony\n",
        "                            \n",
        "                            if this_comp == (num_cured_labels - 1):\n",
        "                                # We looped through all the dots, but none of them were on the colony.  Don't analyze this colony.\n",
        "                                colony_is_cured = False\n",
        "\n",
        "                quantifiable_cured.append(colony_is_cured)\n",
        "\n",
        "                #print('Colony', this_index, ': Cured:', colony_is_cured)\n",
        "\n",
        "\n",
        "                for (lower, upper) in stable_dot_boundaries:\n",
        "                # create NumPy arrays from the boundaries\n",
        "                    lower = np.array(lower, dtype = \"uint8\")\n",
        "                    upper = np.array(upper, dtype = \"uint8\")\n",
        "                    # find the colors within the specified boundaries and apply\n",
        "                    # the mask\n",
        "                    #print(np.unique((colony_image*255).astype(np.uint8)))\n",
        "                    dot_mask = cv2.inRange((state_image*255).astype(np.uint8), lower, upper)\n",
        "                    #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n",
        "                    # Get connected components of the detected pixels\n",
        "                    #print(np.unique(dot_mask))\n",
        "                    stable_labels = label(dot_mask)\n",
        "                    num_stable_labels = len(np.unique(stable_labels))\n",
        "                    if num_stable_labels <= 1:\n",
        "                        # No dot was detected.  Thus the colony was considered non-quantifiable.\n",
        "                        colony_is_stable = False\n",
        "                    else:\n",
        "                        # Loop through each component.  Find one component that is not too small and is directly on the colony\n",
        "                        colony_center_y = (state_image.shape[0] - 1) / 2.0\n",
        "                        colony_center_x = (state_image.shape[1] - 1) / 2.0\n",
        "                        for this_comp in range(1, num_stable_labels):\n",
        "                            this_dot_comp = stable_labels == this_comp\n",
        "                            # Get centroid of component\n",
        "                            (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(this_dot_comp)\n",
        "                            dot_dist = math.sqrt(((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n",
        "                            if dot_dist < colony_locations[\"Radius\"][this_index]:\n",
        "                                colony_is_stable = True\n",
        "                                break\n",
        "                                # end the loop, as we found a dot on the colony\n",
        "                            \n",
        "                            if this_comp == (num_stable_labels - 1):\n",
        "                                # We looped through all the dots, but none of them were on the colony.  Don't analyze this colony.\n",
        "                                colony_is_stable = False\n",
        "\n",
        "                quantifiable_stable.append(colony_is_stable)\n",
        "\n",
        "                #print('Colony', this_index, ': Stable:', colony_is_stable)\n",
        "\n",
        "\n",
        "                for (lower, upper) in sectored_dot_boundaries:\n",
        "                # create NumPy arrays from the boundaries\n",
        "                    lower = np.array(lower, dtype = \"uint8\")\n",
        "                    upper = np.array(upper, dtype = \"uint8\")\n",
        "                    # find the colors within the specified boundaries and apply\n",
        "                    # the mask\n",
        "                    #print(np.unique((colony_image*255).astype(np.uint8)))\n",
        "                    dot_mask = cv2.inRange((state_image*255).astype(np.uint8), lower, upper)\n",
        "                    #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n",
        "                    # Get connected components of the detected pixels\n",
        "                    #print(np.unique(dot_mask))\n",
        "                    sectored_labels = label(dot_mask)\n",
        "                    num_sectored_labels = len(np.unique(sectored_labels))\n",
        "                    if num_sectored_labels <= 1:\n",
        "                        # No dot was detected.  Thus the colony was considered non-quantifiable.\n",
        "                        colony_is_sectored = False\n",
        "                    else:\n",
        "                        # Loop through each component.  Find one component that is not too small and is directly on the colony\n",
        "                        colony_center_y = (state_image.shape[0] - 1) / 2.0\n",
        "                        colony_center_x = (state_image.shape[1] - 1) / 2.0\n",
        "                        for this_comp in range(1, num_sectored_labels):\n",
        "                            this_dot_comp = sectored_labels == this_comp\n",
        "                            # Get centroid of component\n",
        "                            (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(this_dot_comp)\n",
        "                            dot_dist = math.sqrt(((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n",
        "                            if dot_dist < colony_locations[\"Radius\"][this_index]:\n",
        "                                colony_is_sectored = True\n",
        "                                break\n",
        "                                # end the loop, as we found a dot on the colony\n",
        "                            \n",
        "                            if this_comp == (num_sectored_labels - 1):\n",
        "                                # We looped through all the dots, but none of them were on the colony.  Don't analyze this colony.\n",
        "                                colony_is_sectored = False\n",
        "\n",
        "                quantifiable_sectored.append(colony_is_sectored)\n",
        "\n",
        "                #print('Colony', this_index, ': Sectored:', colony_is_sectored)\n",
        "\n",
        "\n",
        "                #----------------------------------\n",
        "\n",
        "            #-----------------------------------------------------\n",
        "            # Get connectedness properties of the segmentation\n",
        "            #-----------------------------------------------------\n",
        "\n",
        "            # Use this information to test whether the segmentation meets the conditions\n",
        "\n",
        "            # Condition 1 test: is the segmentation one connected component?\n",
        "            condition_1_test_strong, condition_1_test_weak = check_components_of_colony(colony_mask)\n",
        "            colony_is_connected.append(condition_1_test_strong)\n",
        "            colony_is_approx_connected.append(condition_1_test_weak)\n",
        "            #print('Condition 1: Seg is one component: ' + str(condition_1_test_strong))\n",
        "            #print(\"Condition 1: Seg is \\'approximately\\' one component: \" + str(condition_1_test_weak))\n",
        "\n",
        "            # Condition 2 test: Is the boundary one connected component?\n",
        "            condition_2_test = check_components_of_boundary(edge_mask_unpadded)\n",
        "            boundary_is_connected.append(condition_2_test)\n",
        "            #print('Condition 2: Boundary is one component: ' + str(condition_2_test))\n",
        "\n",
        "            # Condition 3 test: Are there holes in the segmentation?\n",
        "            condition_3_test = check_for_holes(colony_mask, edge_mask_unpadded)\n",
        "            colony_is_whole.append(condition_3_test)\n",
        "            #print('Condition 3: Segmentation has no holes: ' + str(condition_3_test))\n",
        "\n",
        "            # Condition 4 test: Is the boundary a Hamiltonian cycle? (no ready yet)\n",
        "            #condition_4_test = get_hamilton_cycle(colony_mask, edge_mask_unpadded)\n",
        "            #print('Has Hamiltonian cycle: ' + str(condition_4_test))\n",
        "\n",
        "            # Condition 5: Check circularity and convexity\n",
        "            condition_5_convex, condition_5_circular = compare_convex_hull(colony_mask, edge_mask_unpadded)\n",
        "            colony_is_approx_convex.append(condition_5_convex)\n",
        "            colony_is_approx_circular.append(condition_5_circular)\n",
        "            #print('Condition 5: Segmentation is approximately convex: ' + str(condition_5_convex))\n",
        "            #print('Condition 5: Segmentation is approximately circular: ' + str(condition_5_circular))\n",
        "\n",
        "            # Condition 6: Check hausdorff distance\n",
        "            hausdorff_chull, hausdorff_circle = get_hausdorff_distance(colony_mask, edge_mask_unpadded)\n",
        "            hausdorff_dist_convex.append(hausdorff_chull)\n",
        "            hausdorff_dist_circle.append(hausdorff_circle)\n",
        "            #print('Condition 6: Hausdorff distance between boundary and convex hull: ' + str(hausdorff_chull))\n",
        "            #print('Condition 6: Hausdorff distance between boundary and circle: ' + str(hausdorff_circle))\n",
        "\n",
        "            #----------------------------------------\n",
        "            # Partition the boundaries into red and white components\n",
        "\n",
        "            # Get 'ideal' boundary of the colony\n",
        "            ideal_circle = create_circle_boundary(edge_mask_unpadded, colony_locations[\"Radius\"][this_index])\n",
        "\n",
        "            # Find connected components of the red and white pixels found on the boundary\n",
        "            red_boundary_skeleton, white_boundary_skeleton, boundary_mask_h, boundary_mask_w = get_boundary_partitions(red_colony_mask, white_colony_mask, edge_mask_unpadded)\n",
        "\n",
        "            #plt.imshow(red_boundary_skeleton)\n",
        "            #plt.title('Red Boundary Skeleton')\n",
        "\n",
        "            # Save the three images using this data\n",
        "            #   - Oringinal image padded\n",
        "            #   - CHT image padded\n",
        "            #   - Segmentation padded\n",
        "            # Force a circle like previously\n",
        "            padded_x = 255 * x[max((top_left_y-1)-image_padding, 0):min((top_left_y + box_height - 1)+image_padding, H-1), max((top_left_x-1) - image_padding, 0):min((top_left_x + box_width - 1)+image_padding, W-1), :]\n",
        "            padded_x_CHT = 255 * x_CHT[max((top_left_y-1)-image_padding, 0):min((top_left_y + box_height - 1)+image_padding, H-1), max((top_left_x-1) - image_padding, 0):min((top_left_x + box_width - 1)+image_padding, W-1), :]\n",
        "            padded_mask = p[max((top_left_y-1)-image_padding, 0):min((top_left_y + box_height - 1)+image_padding, H-1), max((top_left_x-1) - image_padding, 0):min((top_left_x + box_width - 1)+image_padding, W-1)]\n",
        "            ellipse_array_2 = create_filled_ellipse_in_array(padded_mask, padding = image_padding)\n",
        "            padded_mask = np.multiply(padded_mask, ellipse_array_2)\n",
        "\n",
        "            # Save the colony images as previously\n",
        "            if save_all_annotations == True:\n",
        "                if not cv2.imwrite(output_crops_folder + '/raw/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.jpg', padded_x):\n",
        "                    raise Exception('Could not write image.')\n",
        "                if not cv2.imwrite(output_crops_folder + '/circles/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.jpg', padded_x_CHT):\n",
        "                    raise Exception('Could not write image.')\n",
        "                if not cv2.imwrite(output_crops_folder + '/segs/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', padded_mask):\n",
        "                    raise Exception('Could not write image.')\n",
        "\n",
        "            # Save the croppings for individual colonies which were annotated\n",
        "                if use_expert_counts == True:\n",
        "                    padded_x_count = 255 * x_quant[max((top_left_y-1)-image_padding, 0):min((top_left_y + box_height - 1)+image_padding, H-1), max((top_left_x-1) - image_padding, 0):min((top_left_x + box_width - 1)+image_padding, W-1), :]\n",
        "                    if not cv2.imwrite(output_crops_folder + '/counted/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', padded_x_count):\n",
        "                        raise Exception('Could not write image.')\n",
        "            #-------------------------------------------------------------\n",
        "\n",
        "            # CLASSIFICATION STEP BEGINS\n",
        "            # GET INITIAL REGIONAL BREAKDOWN AND RED REGION ANNOTATIONS OF THE COLONY\n",
        "\n",
        "            # Should store information about the following:\n",
        "            #   - Idealized red and white regions\n",
        "            #   - The boundaries of each red and white region\n",
        "            #   - The sizes of each region\n",
        "            #   - The purity scores of each region\n",
        "            #   - the states of each colony (cured, stable)\n",
        "\n",
        "            # Images to save in this section\n",
        "            # - Regional segmentation\n",
        "            # - Boundary of the colony\n",
        "            # - Red region boundary annotation\n",
        "            # - Regions that fail consistency check\n",
        "\n",
        "            # Plot padded version of the initial segmentation.  Annotations will be saved onto the image.\n",
        "            colony_image_padded = np.pad(colony_image, 5)\n",
        "            fig1, ax1 = plt.subplots()\n",
        "            ax1.imshow(colony_image_padded, cmap='gray')\n",
        "\n",
        "\n",
        "            recheck_boundaries = True # initialized to true so that we can look at show each step of the pipeline is performing\n",
        "\n",
        "            # Using boundary information, find and extract potential red and white regions of the colony\n",
        "\n",
        "            red_labels = label(red_boundary_skeleton)\n",
        "            white_labels = label(white_boundary_skeleton)\n",
        "\n",
        "            # Initialize masks separating potential red and white regions\n",
        "            initial_red_region_mask = np.zeros_like(red_boundary_skeleton)\n",
        "            initial_white_region_mask = np.zeros_like(white_boundary_skeleton)\n",
        "            initial_red_boundary_mask = np.zeros_like(red_boundary_skeleton)\n",
        "            initial_white_boundary_mask = np.zeros_like(white_boundary_skeleton)\n",
        "\n",
        "            # keep track of regions which fail the consistency check\n",
        "            initial_bad_red_score_mask = np.zeros_like(red_boundary_skeleton)\n",
        "            initial_bad_white_score_mask = np.zeros_like(white_boundary_skeleton)\n",
        "\n",
        "            # Keep track of boundaries whihc fail the consistency check\n",
        "            boundary_correction = np.zeros_like(red_boundary_skeleton)\n",
        "\n",
        "            # Initialize lists to store characteristics about each region\n",
        "            # This includes endpoints on the sector, the purity of the sector, and an indicator for the purity being above the 50 percent threshold\n",
        "            red_component_endpoints = []\n",
        "            red_component_scores = []\n",
        "            red_component_checks = []\n",
        "            red_component_sizes = []\n",
        "\n",
        "            white_component_endpoints = []\n",
        "            white_component_scores = []\n",
        "            white_component_checks = []\n",
        "            white_component_sizes = []\n",
        "\n",
        "            # How many boundaries of each color are there?\n",
        "            num_red_boundaries = len(np.unique(red_labels)[1:]) # number of red boundaries present\n",
        "            num_white_boundaries = len(np.unique(white_labels)[1:]) # number of white boundaries present\n",
        "\n",
        "            # Initial count of the number of sectors is the number of red boundaries\n",
        "            initial_region_counts.append(num_red_boundaries)\n",
        "\n",
        "            # States can be initialy predicted using the number of red and white boundaries\n",
        "            #if ((num_red_boundaries == 1) & (num_white_boundaries == 0)):\n",
        "            if (num_white_boundaries == 0):\n",
        "                cured_colony_before.append(True)\n",
        "            else:\n",
        "                cured_colony_before.append(False)\n",
        "\n",
        "            #if ((num_red_boundaries == 0) & (num_white_boundaries == 1)):\n",
        "            if (num_red_boundaries == 0):\n",
        "                stable_colony_before.append(True)\n",
        "            else:\n",
        "                stable_colony_before.append(False)\n",
        "\n",
        "            # Now, to analyze each of the regions to determine if they are sectored\n",
        "\n",
        "            # Analyze the initial red regions of the colony\n",
        "            for this_label in np.unique(red_labels)[1:]:\n",
        "                red_component = copy.deepcopy(red_labels)\n",
        "                red_component = red_component == this_label\n",
        "                red_component = red_component.astype(np.int32)\n",
        "\n",
        "                # Append the red boundary pixels on this component to the red boundary mask\n",
        "                initial_red_boundary_mask = np.logical_or(initial_red_boundary_mask, red_component > 0)\n",
        "\n",
        "                # Function to get endpoints of connected component\n",
        "                full_endpoints_list = get_boundary_component_endpoints(colony_image[:,:], red_component)\n",
        "\n",
        "                # If exactly two points are found, then everything's good.\n",
        "\n",
        "                # Get the angle of the endpoints relative to the colony center\n",
        "                [endpoint_angles, endpoint_locations, endpoints_x, endpoints_y] = get_endpoint_locations(full_endpoints_list, colony_mask, colony_locations[\"Radius\"][this_index])\n",
        "\n",
        "                # Function to get mask representing sector boundary\n",
        "                sector_boundary, sector_interior, sector_filled = get_sector_masks(red_component, full_endpoints_list)\n",
        "\n",
        "                # Append the predicted filled region to the red region mask\n",
        "                initial_red_region_mask = np.logical_or(initial_red_region_mask, sector_filled)\n",
        "\n",
        "                # Apply consistency check to score the region\n",
        "                confirm_check, prop_interior = check_for_consistency_2(sector_filled, red_colony_mask)\n",
        "\n",
        "                # Update score mask to denote where the consistency check failed\n",
        "                if confirm_check == False:\n",
        "                    recheck_boundaries = True\n",
        "                    initial_bad_red_score_mask = np.logical_or(initial_bad_red_score_mask, sector_filled)\n",
        "\n",
        "                # Append scores and info to lists\n",
        "                red_component_endpoints.append(full_endpoints_list) # endpoints of the connected compponent on the boundary\n",
        "                red_component_scores.append(prop_interior) # purity score of the region\n",
        "                red_component_checks.append(confirm_check) # whether the purity score was at least 0.5\n",
        "                red_component_sizes.append(np.sum(initial_red_region_mask)) # the number of pixels in the region\n",
        "                \n",
        "                # ---ANNOTATION PROCEDURE---\n",
        "\n",
        "                # Plot the lines of the sector (and the boundary line) onto the colony segmentation\n",
        "                length_points = len(endpoints_x)\n",
        "                #print(length_points)\n",
        "                #print(endpoints_x)\n",
        "                if len(np.unique(red_labels)[1:]) > 0: # only plots lines if there are divided regions\n",
        "                    plot_bounds_x = []\n",
        "                    plot_bounds_y = []\n",
        "                    plot_bounds_x.append(endpoints_x[0] + image_padding)\n",
        "                    plot_bounds_y.append(endpoints_y[0] + image_padding)\n",
        "                    # Get list of center and endpoints on the boundary\n",
        "                    for this_bound in range(0, length_points-1):\n",
        "                        plot_bounds_x.append(endpoints_x[this_bound+1] + image_padding)\n",
        "                        plot_bounds_y.append(endpoints_y[this_bound+1] + image_padding)\n",
        "                        #plt.plot(plot_points_y, plot_points_x, color='blue')\n",
        "                        #print(endpoints_x[0:2])\n",
        "                        #print(endpoints_y[0:2])\n",
        "                    plot_bounds_x = np.roll(np.array(plot_bounds_x), 1)\n",
        "                    plot_bounds_y = np.roll(np.array(plot_bounds_y), 1)\n",
        "                    #print(plot_bounds_x)\n",
        "                    #print(plot_bounds_y)\n",
        "                    line_style = ':' if (len(plot_bounds_x) == 2) else '-'\n",
        "                    ax1.plot(plot_bounds_y, plot_bounds_x, linewidth=5, linestyle=line_style, alpha=0.85)\n",
        "                    if len(plot_bounds_x) == 1:\n",
        "                        full_circle = Circle((plot_bounds_y, plot_bounds_x), radius=colony_locations[\"Radius\"][this_index], color='blue', fill=False, linewidth=5, alpha=0.85)\n",
        "                        ax1.add_patch(full_circle)\n",
        "\n",
        "\n",
        "            # Do the same for the white regions\n",
        "            for this_label in np.unique(white_labels)[1:]:\n",
        "                white_component = copy.deepcopy(white_labels)\n",
        "                white_component = white_component == this_label\n",
        "                white_component = white_component.astype(np.int32)\n",
        "\n",
        "                initial_white_boundary_mask = np.logical_or(initial_white_boundary_mask, white_component > 0)\n",
        "\n",
        "                # Function to get endpoints of connected component\n",
        "                full_endpoints_list = get_boundary_component_endpoints(colony_image[:,:], white_component)\n",
        "\n",
        "                # If exactly two points are found, then everything's good.\n",
        "\n",
        "                # Function to get mask representing sector boundary\n",
        "                sector_boundary, sector_interior, sector_filled = get_sector_masks(white_component, full_endpoints_list)\n",
        "\n",
        "                # Fill initial region mask with the filled sector\n",
        "                initial_white_region_mask = np.logical_or(initial_white_region_mask, sector_filled)\n",
        "\n",
        "                # Apply consistency check to score region\n",
        "                confirm_check, prop_interior = check_for_consistency_2(sector_filled, white_colony_mask)\n",
        "\n",
        "                # Update score mask to denote where the consistency check failed\n",
        "                if confirm_check == False:\n",
        "                    recheck_boundaries = True\n",
        "                    initial_bad_white_score_mask = np.logical_or(initial_bad_white_score_mask, sector_filled)\n",
        "\n",
        "                # Append scores and info to lists\n",
        "                white_component_endpoints.append(full_endpoints_list)\n",
        "                white_component_scores.append(prop_interior)\n",
        "                white_component_checks.append(confirm_check)\n",
        "                white_component_sizes.append(np.sum(initial_white_region_mask))\n",
        "\n",
        "            # At this point, you should have two masks, one for the red and white regions respectivey.\n",
        "            # You should also have the endponts of each component, stored as a collection of lists, one list per component\n",
        "            # Finally, you should have a score for those components\n",
        "\n",
        "            # -------------------------------------\n",
        "            # Store the purity scores in a sublist, along with a second sublist indicating the color of each region\n",
        "            # -------------------------------------\n",
        "\n",
        "            all_component_scores = []\n",
        "            all_region_colors = []\n",
        "            all_region_sizes = []\n",
        "\n",
        "            if not red_component_scores:\n",
        "                all_region_colors = all_region_colors + ['red']\n",
        "                all_component_scores = all_component_scores + [np.nan]\n",
        "                all_region_sizes = all_region_sizes + [np.nan]\n",
        "            else:\n",
        "                all_region_colors = all_region_colors + (['red'] * len(red_component_scores))\n",
        "                all_component_scores = all_component_scores + red_component_scores\n",
        "                all_region_sizes = all_region_sizes + red_component_sizes\n",
        "\n",
        "            if not white_component_scores:\n",
        "                all_region_colors = all_region_colors + ['white']\n",
        "                all_component_scores = all_component_scores + [np.nan]\n",
        "                all_region_sizes = all_region_sizes + [np.nan]\n",
        "            else:\n",
        "                all_region_colors = all_region_colors + (['white'] * len(white_component_scores))\n",
        "                all_component_scores = all_component_scores + white_component_scores\n",
        "                all_region_sizes = all_region_sizes + white_component_sizes\n",
        "\n",
        "            region_purity_before.append(all_component_scores)\n",
        "            region_color_before.append(all_region_colors)\n",
        "            region_sizes_before.append(all_region_sizes)\n",
        "\n",
        "            # -------------------------------------\n",
        "            # Do the same for the weighted purity scores across the entire colony\n",
        "            # -------------------------------------\n",
        "\n",
        "            # Compute weighted purity scores over all regions, for white only, and for red only\n",
        "\n",
        "            total_red_sum = np.nansum(red_component_sizes)\n",
        "            total_white_sum = np.nansum(white_component_sizes)\n",
        "\n",
        "            if not red_component_scores:\n",
        "                red_region_weights = np.array([0])\n",
        "                weighted_red_scores = np.array([0])\n",
        "            else:\n",
        "                red_region_weights = np.divide(np.array(red_component_sizes), total_red_sum) # this vector should add to 1, as this is a normalization of the weights\n",
        "                weighted_red_scores = np.multiply(np.array(red_component_scores), red_region_weights)\n",
        "\n",
        "            if not white_component_scores:\n",
        "                white_region_weights = np.array([0])\n",
        "                weighted_white_scores = np.array([0])\n",
        "            else:\n",
        "                white_region_weights = np.divide(np.array(white_component_sizes), total_white_sum) # this vector should add to 1, as this is a normalization of the weights\n",
        "                weighted_white_scores = np.multiply(np.array(white_component_scores), white_region_weights)\n",
        "\n",
        "            # Get weighted average over both regions together\n",
        "            all_region_sum = np.nansum(all_region_sizes)\n",
        "            all_region_weights = np.divide(np.array(red_component_sizes + white_component_sizes), all_region_sum)\n",
        "            all_region_weighted_scores = np.multiply(np.array(red_component_scores + white_component_scores), all_region_weights)\n",
        "\n",
        "            weighted_purity_red_before.append(list(weighted_red_scores))\n",
        "            weighted_purity_white_before.append(list(weighted_white_scores))\n",
        "            weighted_purity_before.append(list(all_region_weighted_scores))\n",
        "            weighted_red_sector_score_before.append(np.nansum(weighted_red_scores))\n",
        "            weighted_white_sector_score_before.append(np.nansum(weighted_white_scores))\n",
        "            weighted_sector_score_before.append(np.nansum(all_region_weighted_scores))\n",
        "\n",
        "            # Now, create the masks containing the initial_regions\n",
        "            initial_region_mask = np.maximum(initial_red_region_mask.astype(np.uint8), 2*initial_white_region_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            initial_boundary_mask = np.maximum(initial_red_boundary_mask.astype(np.uint8), 2*initial_white_boundary_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            initial_score_mask = np.maximum(initial_bad_red_score_mask.astype(np.uint8), 2*initial_bad_white_score_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "\n",
        "            # Make sure to pad them in the same way as the output segmentation\n",
        "            initial_region_mask = np.pad(initial_region_mask, image_padding)\n",
        "            initial_boundary_mask = np.pad(initial_boundary_mask, image_padding)\n",
        "            initial_score_mask = np.pad(initial_score_mask, image_padding)\n",
        "\n",
        "            # Save the initial region and boundary mask.  Also save image indicating regions which should be investigted further.\n",
        "            if save_all_annotations == True:\n",
        "                if not cv2.imwrite(output_crops_folder + '/init_regions/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', initial_region_mask):\n",
        "                    raise Exception('Could not write image.')\n",
        "                if not cv2.imwrite(output_crops_folder + '/init_bounds/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', initial_boundary_mask):\n",
        "                    raise Exception('Could not write image.')\n",
        "                if not cv2.imwrite(output_crops_folder + '/init_bad/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', initial_score_mask):\n",
        "                    raise Exception('Could not write image.')\n",
        "            plt.axis('off')\n",
        "            if save_all_annotations == True:\n",
        "                fig1.savefig(output_crops_folder + '/init_partitions/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', bbox_inches='tight', pad_inches=0)\n",
        "            plt.close(fig1);\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "            #------------------------------------------------------------------\n",
        "\n",
        "            # CLASS SWITCH/MERGING STEP\n",
        "\n",
        "            # This is only applied to regions where the consistency check fails.\n",
        "            # i.e. less than 50% of pixels in the predicted region are of the same class\n",
        "            # as the outer boundary pixels\n",
        "\n",
        "            # The process will repeat until all regions pass the consisency check\n",
        "\n",
        "            # NOTE: This section is only executed if one of either the red or\n",
        "            # white regions estimated above, fails the constency check.\n",
        "            # If all regions predicted are consistent in class, the below will\n",
        "            # not execute, as it will do exactly the same stuff as just done above.\n",
        "\n",
        "            # Therefore, this section is purposely redundant and helps us keep\n",
        "            # track of which regions are being updated.\n",
        "\n",
        "\n",
        "\n",
        "            repetition_counter = 0\n",
        "            performing_correction = False # initialize at the beginning\n",
        "\n",
        "            while recheck_boundaries == True:\n",
        "\n",
        "                recheck_boundaries = False # reset.\n",
        "                repetition_counter = repetition_counter + 1\n",
        "\n",
        "                # The above should be switched back to True if there is a potentially misclassified boundary\n",
        "\n",
        "\n",
        "                # Find the connected components of the skeleton.\n",
        "                # The number of red connected components gives the initial number of sectors.\n",
        "                # The number of white connected components are the regions separating the red sectors.\n",
        "                # A score for sectoriness will be applied to both sets of regions.\n",
        "                red_labels = label(red_boundary_skeleton)\n",
        "                white_labels = label(white_boundary_skeleton)\n",
        "\n",
        "                # Initialize masks separating potential red and white regions\n",
        "                red_region_mask = np.zeros_like(red_boundary_skeleton)\n",
        "                white_region_mask = np.zeros_like(white_boundary_skeleton)\n",
        "                red_boundary_mask = np.zeros_like(red_boundary_skeleton)\n",
        "                white_boundary_mask = np.zeros_like(white_boundary_skeleton)\n",
        "                red_score_mask = np.zeros_like(red_boundary_skeleton)\n",
        "                white_score_mask = np.zeros_like(white_boundary_skeleton)\n",
        "\n",
        "                # Intialize array to change boundary.\n",
        "                # This is only updated when there is a potentially misclassified boundary.\n",
        "                boundary_correction_red = np.zeros_like(red_boundary_skeleton)\n",
        "                boundary_correction_white = np.zeros_like(white_boundary_skeleton)\n",
        "\n",
        "                # Generate regions directly from segmentation\n",
        "                # Iterate through each component and collect some information\n",
        "                # Collect info about component endpoints and purity scores\n",
        "                red_component_endpoints = []\n",
        "                red_component_scores = []\n",
        "                red_component_checks = []\n",
        "\n",
        "                white_component_endpoints = []\n",
        "                white_component_scores = []\n",
        "                white_component_checks = []\n",
        "\n",
        "               # print('Number of red components: ' + str(max(np.unique(red_labels)[1:])))\n",
        "\n",
        "                # Iterate through the red components\n",
        "                for this_label in np.unique(red_labels)[1:]:\n",
        "                    #print('Running the red check.')\n",
        "                    red_component = copy.deepcopy(red_labels)\n",
        "                    red_component = red_component == this_label\n",
        "                    red_component = red_component.astype(np.int32)\n",
        "\n",
        "                    red_boundary_mask = np.logical_or(red_boundary_mask, red_component > 0)\n",
        "\n",
        "                    # Function to get endpoints of connected component\n",
        "                    full_endpoints_list = get_boundary_component_endpoints(colony_image[:,:], red_component)\n",
        "\n",
        "                    # If exactly two points are found, then everything's good.\n",
        "\n",
        "                    # Function to get mask representing sector boundary\n",
        "                    sector_boundary, sector_interior, sector_filled = get_sector_masks(red_component, full_endpoints_list)\n",
        "\n",
        "                    # Fill initial region mask with the filled sector\n",
        "                    red_region_mask = np.logical_or(red_region_mask, sector_filled)\n",
        "\n",
        "                    # Apply consistency check to score region\n",
        "                    confirm_check, prop_interior = check_for_consistency_2(sector_filled, red_colony_mask)\n",
        "\n",
        "                    # Update score mask to denote where the consistency check failed\n",
        "                    if confirm_check == False:\n",
        "                        #performing_correction = True # This signifies that boundary information will be different from the initial breakdown\n",
        "                        recheck_boundaries = True\n",
        "                        boundary_correction_red = np.logical_or(boundary_correction_red, red_component)\n",
        "\n",
        "\n",
        "                    # Append scores and info to lists\n",
        "                    red_component_endpoints.append(full_endpoints_list)\n",
        "                    red_component_scores.append(prop_interior)\n",
        "                    red_component_checks.append(confirm_check)\n",
        "\n",
        "                \n",
        "                # Do the same for the white components\n",
        "                for this_label in np.unique(white_labels)[1:]:\n",
        "\n",
        "                    white_component = copy.deepcopy(white_labels)\n",
        "                    white_component = white_component == this_label\n",
        "                    white_component = white_component.astype(np.int32)\n",
        "\n",
        "                    white_boundary_mask = np.logical_or(white_boundary_mask, white_component > 0)\n",
        "\n",
        "                    # Function to get endpoints of connected component\n",
        "                    full_endpoints_list = get_boundary_component_endpoints(colony_image[:,:], white_component)\n",
        "\n",
        "                    # If exactly two points are found, then everything's good.\n",
        "\n",
        "                    # Function to get mask representing sector boundary\n",
        "                    sector_boundary, sector_interior, sector_filled = get_sector_masks(white_component, full_endpoints_list)\n",
        "\n",
        "                    # Fill initial region mask with the filled sector\n",
        "                    white_region_mask = np.logical_or(white_region_mask, sector_filled)\n",
        "\n",
        "                    # Apply consistency check to score region\n",
        "                    confirm_check, prop_interior = check_for_consistency_2(sector_filled, white_colony_mask)\n",
        "\n",
        "                    # Update score mask to denote where the consistency check failed\n",
        "                    if confirm_check == False:\n",
        "                        #performing_correction = True # This signifies that boundary information will be different from the initial breakdown\n",
        "                        recheck_boundaries = True\n",
        "                        boundary_correction_white = np.logical_or(boundary_correction_white, white_component)\n",
        "\n",
        "                    # Append scores and info to lists\n",
        "                    white_component_endpoints.append(full_endpoints_list)\n",
        "                    white_component_scores.append(prop_interior)\n",
        "                    white_component_checks.append(confirm_check)\n",
        "\n",
        "                # If there were regions that failed the consistency check, swap the classes on the boundary\n",
        "                if recheck_boundaries == True:\n",
        "\n",
        "                    performing_correction = True # This signifies that boundary information will be different from the initial breakdown\n",
        "\n",
        "                    # Run the swap functions\n",
        "                    red_boundary_skeleton = grow_boundary(red_boundary_skeleton, boundary_correction_white) # takes the bad white boundaries and switches them to the red class\n",
        "                    red_boundary_skeleton = shrink_boundary(red_boundary_skeleton, boundary_correction_red) # removes the bad red boundaries\n",
        "\n",
        "                    white_boundary_skeleton = grow_boundary(white_boundary_skeleton, boundary_correction_red) # takes the bad red boundaries and switches them to the white class\n",
        "                    white_boundary_skeleton = shrink_boundary(white_boundary_skeleton, boundary_correction_white) # removes the bad white boundaries\n",
        "\n",
        "                # Only run the block below if this colony cannot be analyzed appropriatly with this pipeline (may be an awful segmentation)\n",
        "                if repetition_counter > 20:\n",
        "                    warnings.warn('Corrections have been applied too many times.  The colony segmentation used here is likely unsuitable for this pipeline.')\n",
        "                    break\n",
        "\n",
        "                    # Once the swap is done, you will head back to the top of this while loop.\n",
        "\n",
        "            # At this point, you should have two masks, one for the red and white regions respectivey.\n",
        "            # You should also have the endponts of each components, stored as a collection of lists, one list per component\n",
        "            # Finally, you should have a score for those components\n",
        "\n",
        "            # Now, create the masks containing the regions that pass the consistency check\n",
        "            corrected_region_mask = np.maximum(red_region_mask.astype(np.uint8), 2*white_region_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            corrected_boundary_mask = np.maximum(red_boundary_mask.astype(np.uint8), 2*white_boundary_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "\n",
        "            red_labels = label(red_boundary_skeleton)\n",
        "            white_labels = label(white_boundary_skeleton)\n",
        "\n",
        "            #corrected_boundary_mask = np.maximum((white_labels > 0).astype(np.uint8), 2*((red_labels > 0).astype(np.uint8)))*(255/(num_classes-1))\n",
        "\n",
        "            # Use the corrected boundary_mask to piece together the corrected colony segmentation\n",
        "            corrected_colony_image = np.add(interior_colony, corrected_boundary_mask).astype(np.uint8)\n",
        "            corrected_colony_image_padded = np.pad(corrected_colony_image, image_padding)\n",
        "\n",
        "            # Re-partition the image following correction\n",
        "            corrected_full = tf.identity(corrected_colony_image).numpy().astype(np.int32)\n",
        "            corrected_white_colony_mask = tf.math.equal(tf.constant(corrected_full), tf.constant([255])).numpy().astype(np.uint8)\n",
        "            corrected_red_colony_mask = tf.math.equal(tf.constant(corrected_full), tf.constant([127])).numpy().astype(np.uint8)\n",
        "            corrected_colony_mask = np.logical_or(corrected_white_colony_mask, corrected_red_colony_mask) # sanity check to see of this is the same as colony image\n",
        "\n",
        "\n",
        "            # if performing_correction == True:\n",
        "            #     corrected_region_mask = np.maximum(white_region_mask.astype(np.uint8), 2*red_region_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            #     corrected_boundary_mask = np.maximum(white_boundary_mask.astype(np.uint8), 2*red_boundary_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            #     #score_mask = np.maximum(initial_bad_white_score_mask.astype(np.uint8), 2*initial_bad_red_score_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            # else:\n",
        "            #     corrected_region_mask = np.maximum(initial_white_region_mask.astype(np.uint8), 2*initial_red_region_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            #     corrected_boundary_mask = np.maximum(initial_white_boundary_mask.astype(np.uint8), 2*initial_red_boundary_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "\n",
        "            \n",
        "            #score_mask = np.pad(score_mask, 5)\n",
        "\n",
        "            #--------------------------------------------------\n",
        "            # Get corrected segmentations and regions\n",
        "\n",
        "\n",
        "            # Get boundary information from the boundary corrected/merged segmentation\n",
        "            corrected_red_boundary_skeleton, corrected_white_boundary_skeleton, corrected_boundary_mask_h, corrected_boundary_mask_w = get_boundary_partitions(corrected_red_colony_mask, corrected_white_colony_mask, edge_mask_unpadded)\n",
        "\n",
        "            red_labels = label(corrected_red_boundary_skeleton)\n",
        "            white_labels = label(corrected_white_boundary_skeleton)\n",
        "\n",
        "            corrected_boundary_mask = np.maximum((red_labels > 0).astype(np.uint8), 2*((white_labels > 0).astype(np.uint8)))*(255/(num_classes-1))\n",
        "\n",
        "            # Use the corrected boundary_mask to piece together the corrected colony segmentation\n",
        "            corrected_colony_image = np.add(interior_colony, corrected_boundary_mask).astype(np.uint8)\n",
        "            corrected_colony_image_padded = np.pad(corrected_colony_image, image_padding)\n",
        "\n",
        "            corrected_region_mask = np.maximum(red_region_mask.astype(np.uint8), 2*white_region_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            corrected_boundary_mask = np.maximum(red_boundary_mask.astype(np.uint8), 2*white_boundary_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            #score_mask = np.maximum(initial_bad_white_score_mask.astype(np.uint8), 2*initial_bad_red_score_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "\n",
        "            # Re-partition the image following correction\n",
        "            corrected_full = tf.identity(corrected_colony_image).numpy().astype(np.int32)\n",
        "            corrected_white_colony_mask = tf.math.equal(tf.constant(corrected_full), tf.constant([255])).numpy().astype(np.uint8)\n",
        "            corrected_red_colony_mask = tf.math.equal(tf.constant(corrected_full), tf.constant([127])).numpy().astype(np.uint8)\n",
        "            corrected_colony_mask = np.logical_or(corrected_white_colony_mask, corrected_red_colony_mask) # sanity check to see of this is the same as colony image\n",
        "\n",
        "            \n",
        "\n",
        "            #-------------------------------------------------------------------\n",
        "\n",
        "            # PROCESSING THE CORRECTED REGIONS\n",
        "            # If you got to this point, then the boundaries should be consistent with the interior of the colony.\n",
        "\n",
        "            # Images to save in this section\n",
        "            # - Regional segmentation with the corrected boundary\n",
        "            # - Red region boundary annotation with the corrected boundary\n",
        "            # - Red regions remaining after correction applied\n",
        "\n",
        "            \n",
        "\n",
        "            # initialize masks containing the sector locations\n",
        "            all_sector_bounds = np.zeros_like(colony_mask).astype(np.int32)\n",
        "            all_sector_filled = np.zeros_like(colony_mask).astype(np.int32)\n",
        "            all_sector_filled_labels = np.zeros_like(colony_mask).astype(np.int32)\n",
        "\n",
        "            # Use the corrected boundary_mask to piece together the corrected colony segmentation\n",
        "            # corrected_colony_image = np.add(interior_colony, corrected_boundary_mask).astype(np.uint8)\n",
        "            # corrected_colony_image_padded = np.pad(corrected_colony_image, image_padding)\n",
        "\n",
        "            # # Re-partition the image followng correction\n",
        "            # corrected_full = tf.identity(corrected_colony_image).numpy().astype(np.int32)\n",
        "            # corrected_white_colony_mask = tf.math.equal(tf.constant(corrected_full), tf.constant([127])).numpy().astype(np.uint8)\n",
        "            # corrected_red_colony_mask = tf.math.equal(tf.constant(corrected_full), tf.constant([255])).numpy().astype(np.uint8)\n",
        "            # corrected_colony_mask = np.logical_or(corrected_white_colony_mask, corrected_red_colony_mask) # sanity check to see of this is the same as colony image\n",
        "            #print(np.unique(corrected_colony_image))\n",
        "            #plt.imshow(corrected_colony_mask, cmap='gray')\n",
        "            #raise NameError('Corrected colony mask')\n",
        "\n",
        "            # Save the corrected segmentation\n",
        "            if save_all_annotations == True:\n",
        "                if not cv2.imwrite(output_crops_folder + '/cor_segs/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', corrected_colony_image_padded):\n",
        "                    raise Exception('Could not write image.')\n",
        "\n",
        "            # # Get boundary information from the corrected segmentation\n",
        "            # corrected_red_boundary_skeleton, corrected_white_boundary_skeleton, corrected_boundary_mask_h, corrected_boundary_mask_w = get_boundary_partitions(corrected_red_colony_mask, corrected_white_colony_mask, edge_mask_unpadded)\n",
        "\n",
        "            # Initialize masks separating potential red and white regions\n",
        "            post_red_region_mask = np.zeros_like(corrected_red_boundary_skeleton)\n",
        "            post_white_region_mask = np.zeros_like(corrected_white_boundary_skeleton)\n",
        "            post_red_boundary_mask = np.zeros_like(corrected_red_boundary_skeleton)\n",
        "            post_white_boundary_mask = np.zeros_like(corrected_white_boundary_skeleton)\n",
        "            post_red_score_mask = np.zeros_like(corrected_red_boundary_skeleton)\n",
        "            post_white_score_mask = np.zeros_like(corrected_white_boundary_skeleton)\n",
        "\n",
        "            # red_labels = label(corrected_red_boundary_skeleton)\n",
        "            # white_labels = label(corrected_white_boundary_skeleton)\n",
        "\n",
        "            # initialize counter for the number of sectors in this colony\n",
        "            total_sectors = 0\n",
        "\n",
        "            # Make copy of colony mask and place sectors on top\n",
        "            #colony_mask_faded = copy.deepcopy(colony_mask).astype(np.uint8)\n",
        "            #colony_mask_faded[colony_mask_faded > 0] = 20\n",
        "\n",
        "            corrected_colony_mask_faded = copy.deepcopy(corrected_colony_mask).astype(np.uint8)\n",
        "            corrected_colony_mask_faded[corrected_colony_mask_faded > 0] = 20\n",
        "\n",
        "            sector_scores = []\n",
        "            sector_ious = []\n",
        "\n",
        "            # Create figure for annotating the corrected colony segmentations.  Annotations will be saved onto the image.\n",
        "            fig2, ax2 = plt.subplots()\n",
        "            ax2.imshow(corrected_colony_image_padded, cmap='gray')\n",
        "\n",
        "            # Compute the scores of the regions one more time.\n",
        "            # All regions should pass the consistency check by this point.  If not, then something is wrong.\n",
        "            red_component_endpoints = []\n",
        "            red_component_scores = []\n",
        "            red_component_checks = []\n",
        "            red_component_sizes = []\n",
        "\n",
        "            white_component_endpoints = []\n",
        "            white_component_scores = []\n",
        "            white_component_checks = []\n",
        "            white_component_sizes = []\n",
        "\n",
        "            num_red_boundaries = len(np.unique(red_labels)[1:]) # number of red boundaries present\n",
        "            num_white_boundaries = len(np.unique(white_labels)[1:]) # number of white boundaries present\n",
        "\n",
        "            #if ((num_red_boundaries == 1) & (num_white_boundaries == 0)):\n",
        "            if (num_white_boundaries == 0):\n",
        "                cured_colony_after.append(True)\n",
        "            else:\n",
        "                cured_colony_after.append(False)\n",
        "\n",
        "            #if ((num_red_boundaries == 0) & (num_white_boundaries == 1)):\n",
        "            if (num_red_boundaries == 0):\n",
        "                stable_colony_after.append(True)\n",
        "            else:\n",
        "                stable_colony_after.append(False)\n",
        "\n",
        "            for this_label in np.unique(red_labels)[1:]:\n",
        "                red_component = copy.deepcopy(red_labels)\n",
        "                red_component = red_component == this_label\n",
        "                red_component = red_component.astype(np.int32)\n",
        "\n",
        "                post_red_boundary_mask = np.logical_or(post_red_boundary_mask, red_component > 0)\n",
        "\n",
        "                # Function to get endpoints of connected component\n",
        "                full_endpoints_list = get_boundary_component_endpoints(corrected_colony_image[:,:], red_component)\n",
        "\n",
        "                # If exactly two points are found, then everything's good.\n",
        "\n",
        "                # Function to get mask representing sector boundary\n",
        "                sector_boundary, sector_interior, sector_filled = get_sector_masks(red_component, full_endpoints_list)\n",
        "\n",
        "                # Fill initial region mask with the filled sector\n",
        "                post_red_region_mask = np.logical_or(post_red_region_mask, sector_filled)\n",
        "\n",
        "                # Apply consistency check to score region\n",
        "                confirm_check, prop_interior = check_for_consistency_2(sector_filled, corrected_red_colony_mask)\n",
        "\n",
        "                # Update score mask to denote where the consistency check failed\n",
        "                if confirm_check == False:\n",
        "                    print('Double check your code.  The red consistency check failed for this colony with score ' + str(prop_interior))\n",
        "                    #raise IOError('Something is wrong with how regions are being scored')\n",
        "\n",
        "                # Append scores and info to lists\n",
        "                red_component_endpoints.append(full_endpoints_list)\n",
        "                red_component_scores.append(prop_interior)\n",
        "                red_component_checks.append(confirm_check)\n",
        "                red_component_sizes.append(np.sum(post_red_region_mask))\n",
        "\n",
        "                # Code for plotting the annotations\n",
        "\n",
        "                # For the consistent sectors, get the angles of the endpoints relative to the center\n",
        "                # colony mask, or any other array with the same size and shape, will work as input as it's only needed for size info\n",
        "                [endpoint_angles, endpoint_locations, endpoints_x, endpoints_y] = get_endpoint_locations(full_endpoints_list, corrected_colony_mask, colony_locations[\"Radius\"][this_index])\n",
        "                #print(endpoints_x)\n",
        "\n",
        "                # Add to mask containg sector locations\n",
        "                #sector_filled = np.logical_or(sector_boundary, sector_interior)\n",
        "                all_sector_bounds = np.logical_or(all_sector_bounds, sector_boundary)\n",
        "                all_sector_filled = np.logical_or(all_sector_filled, sector_filled)\n",
        "                all_sector_filled_labels[sector_filled.astype(bool)] = this_label\n",
        "                total_sectors = total_sectors + 1\n",
        "                corrected_colony_mask_faded[sector_filled.astype(bool)] = 255 / this_label\n",
        "\n",
        "                # Get a score for sectoriness.  We want to be sure we are capturing the entire sector\n",
        "                this_sector_mask = np.logical_and(sector_filled, red_colony_mask)\n",
        "                this_union_mask = np.logical_or(sector_filled, red_colony_mask)\n",
        "                this_sector_score = np.sum(this_sector_mask) / np.sum(sector_filled)\n",
        "                this_sector_iou = np.sum(this_sector_mask) / np.sum(this_union_mask)\n",
        "                sector_scores.append(this_sector_score)\n",
        "                sector_ious.append(this_sector_iou)\n",
        "\n",
        "                # Plot the lines of the sector (and the boundary line) onto the colony segmentation\n",
        "                length_points = len(endpoints_x)\n",
        "                #print(length_points)\n",
        "                #print(endpoints_x)\n",
        "                if len(np.unique(red_labels)[1:]) > 0:\n",
        "                    plot_bounds_x = []\n",
        "                    plot_bounds_y = []\n",
        "                    plot_bounds_x.append(endpoints_x[0] + 5)\n",
        "                    plot_bounds_y.append(endpoints_y[0] + 5)\n",
        "                    # Get list of center and endpoints on the boundary\n",
        "                    for this_bound in range(0, length_points-1):\n",
        "                        plot_bounds_x.append(endpoints_x[this_bound+1] + 5)\n",
        "                        plot_bounds_y.append(endpoints_y[this_bound+1] + 5)\n",
        "                        #plt.plot(plot_points_y, plot_points_x, color='blue')\n",
        "                        #print(endpoints_x[0:2])\n",
        "                        #print(endpoints_y[0:2])\n",
        "                    plot_bounds_x = np.roll(np.array(plot_bounds_x), 1)\n",
        "                    plot_bounds_y = np.roll(np.array(plot_bounds_y), 1)\n",
        "                    #print(plot_bounds_x)\n",
        "                    #print(plot_bounds_y)\n",
        "                    line_style = ':' if (len(plot_bounds_x) == 2) else '-'\n",
        "                    ax2.plot(plot_bounds_y, plot_bounds_x, linewidth=5, linestyle=line_style, alpha=0.85)\n",
        "                    if len(plot_bounds_x) == 1:\n",
        "                        full_circle = Circle((plot_bounds_y, plot_bounds_x), radius=colony_locations[\"Radius\"][this_index], color='blue', fill=False, linewidth=5, alpha=0.85)\n",
        "                        ax2.add_patch(full_circle)\n",
        "\n",
        "\n",
        "\n",
        "            for this_label in np.unique(white_labels)[1:]:\n",
        "                white_component = copy.deepcopy(white_labels)\n",
        "                white_component = white_component == this_label\n",
        "                white_component = white_component.astype(np.int32)\n",
        "\n",
        "                post_white_boundary_mask = np.logical_or(post_white_boundary_mask, white_component > 0)\n",
        "\n",
        "                # Function to get endpoints of connected component\n",
        "                full_endpoints_list = get_boundary_component_endpoints(corrected_colony_image[:,:], white_component)\n",
        "\n",
        "                # If exactly two points are found, then everything's good.\n",
        "\n",
        "                # Function to get mask representing sector boundary\n",
        "                sector_boundary, sector_interior, sector_filled = get_sector_masks(white_component, full_endpoints_list)\n",
        "\n",
        "                # Fill initial region mask with the filled sector\n",
        "                post_white_region_mask = np.logical_or(post_white_region_mask, sector_filled)\n",
        "\n",
        "                # Apply consistency check to score region\n",
        "                confirm_check, prop_interior = check_for_consistency_2(sector_filled, corrected_white_colony_mask)\n",
        "\n",
        "                # Update score mask to denote where the consistency check failed\n",
        "                if confirm_check == False:\n",
        "                    print('Double check your code.  The white consistency check failed for this colony with score ' + str(prop_interior))\n",
        "\n",
        "                # Append scores and info to lists\n",
        "                white_component_endpoints.append(full_endpoints_list)\n",
        "                white_component_scores.append(prop_interior)\n",
        "                white_component_checks.append(confirm_check)\n",
        "                white_component_sizes.append(np.sum(post_white_region_mask))\n",
        "\n",
        "            print('Scores for red regions: ' + str(red_component_scores))\n",
        "            print('Scores for white regions: ' + str(white_component_scores))\n",
        "\n",
        "            # Store the purity scores in a sublist, along with a second sublist indicating the color of each region\n",
        "\n",
        "            all_component_scores = []\n",
        "            all_region_colors = []\n",
        "            all_region_sizes = []\n",
        "\n",
        "            if not red_component_scores:\n",
        "                all_region_colors = all_region_colors + ['red']\n",
        "                all_component_scores = all_component_scores + [np.nan]\n",
        "                all_region_sizes = all_region_sizes + [np.nan]\n",
        "            else:\n",
        "                all_region_colors = all_region_colors + (['red'] * len(red_component_scores))\n",
        "                all_component_scores = all_component_scores + red_component_scores\n",
        "                all_region_sizes = all_region_sizes + red_component_sizes\n",
        "\n",
        "            if not white_component_scores:\n",
        "                all_region_colors = all_region_colors + ['white']\n",
        "                all_component_scores = all_component_scores + [np.nan]\n",
        "                all_region_sizes = all_region_sizes + [np.nan]\n",
        "            else:\n",
        "                all_region_colors = all_region_colors + (['white'] * len(white_component_scores))\n",
        "                all_component_scores = all_component_scores + white_component_scores\n",
        "                all_region_sizes = all_region_sizes + white_component_sizes\n",
        "\n",
        "            region_purity_after.append(all_component_scores)\n",
        "            region_color_after.append(all_region_colors)\n",
        "            region_sizes_after.append(all_region_sizes)\n",
        "\n",
        "            # Compute weighted purity scores over all regions, for white only, and for red only\n",
        "\n",
        "            total_red_sum = np.nansum(red_component_sizes)\n",
        "            total_white_sum = np.nansum(white_component_sizes)\n",
        "\n",
        "            if not red_component_scores:\n",
        "                red_region_weights = np.array([0])\n",
        "                weighted_red_scores = np.array([0])\n",
        "            else:\n",
        "                red_region_weights = np.divide(np.array(red_component_sizes), total_red_sum) # this vector should add to 1, as this is a normalization of the weights\n",
        "                weighted_red_scores = np.multiply(np.array(red_component_scores), red_region_weights)\n",
        "\n",
        "            if not white_component_scores:\n",
        "                white_region_weights = np.array([0])\n",
        "                weighted_white_scores = np.array([0])\n",
        "            else:\n",
        "                white_region_weights = np.divide(np.array(white_component_sizes), total_white_sum) # this vector should add to 1, as this is a normalization of the weights\n",
        "                weighted_white_scores = np.multiply(np.array(white_component_scores), white_region_weights)\n",
        "\n",
        "            # Get weighted average over both regions together\n",
        "            all_region_sum = np.nansum(all_region_sizes)\n",
        "            all_region_weights = np.divide(np.array(red_component_sizes + white_component_sizes), all_region_sum)\n",
        "            all_region_weighted_scores = np.multiply(np.array(red_component_scores + white_component_scores), all_region_weights)\n",
        "\n",
        "            weighted_purity_red_after.append(list(weighted_red_scores))\n",
        "            weighted_purity_white_after.append(list(weighted_white_scores))\n",
        "            weighted_purity_after.append(list(all_region_weighted_scores))\n",
        "            weighted_red_sector_score_after.append(np.nansum(weighted_red_scores))\n",
        "            weighted_white_sector_score_after.append(np.nansum(weighted_white_scores))\n",
        "            weighted_sector_score_after.append(np.nansum(all_region_weighted_scores))\n",
        "  \n",
        "            # Now, create the masks containing the initial_regions\n",
        "            post_region_mask = np.maximum(post_red_region_mask.astype(np.uint8), 2*post_white_region_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            post_boundary_mask = np.maximum(post_red_boundary_mask.astype(np.uint8), 2*post_white_boundary_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "            post_score_mask = np.maximum(post_red_score_mask.astype(np.uint8), 2*post_white_score_mask.astype(np.uint8))*(255/(num_classes-1))\n",
        "\n",
        "            post_region_mask = np.pad(post_region_mask, image_padding)\n",
        "            post_boundary_mask = np.pad(post_boundary_mask, image_padding)\n",
        "            post_score_mask = np.pad(post_score_mask, image_padding)\n",
        "\n",
        "            #if not cv2.imwrite(output_crops_folder + '/Colony Corrected Regions/' + pathlib.Path(test_image).stem + '_Colony_' + str(this_index) + '.png', post_region_mask):\n",
        "            #    raise Exception('Could not write image.')\n",
        "\n",
        "            #post_region_mask = np.pad(post_region_mask, 5)\n",
        "                \n",
        "            if save_all_annotations == True:\n",
        "                if not cv2.imwrite(output_crops_folder + '/cor_bounds/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', post_boundary_mask):\n",
        "                    raise Exception('Could not write image.')\n",
        "                if not cv2.imwrite(output_crops_folder + '/cor_regions/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', post_region_mask):\n",
        "                    raise Exception('Could not write image.')\n",
        "                if not cv2.imwrite(output_crops_folder + '/cor_bad/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', post_score_mask):\n",
        "                    raise Exception('Could not write image.')\n",
        "            plt.axis('off')\n",
        "            if save_all_annotations == True:\n",
        "                fig2.savefig(output_crops_folder + '/cor_partitions/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', bbox_inches='tight', pad_inches=0)\n",
        "            plt.close(fig2);\n",
        "                    \n",
        "                \n",
        "            #------------------------------------------------------------------\n",
        "\n",
        "            # PRINTING RESULTS OF COLONY\n",
        "\n",
        "            if not sector_scores:\n",
        "                sector_scores = 0\n",
        "                sector_ious = 0\n",
        "            average_sector_score.append(np.mean(sector_scores))\n",
        "            average_sector_iou.append(np.mean(sector_ious))\n",
        "            #print('Colony ' + str(this_index))\n",
        "            print('Estimated number of sectors: ' + str(total_sectors))\n",
        "            all_sector_counts.append(total_sectors)\n",
        "            print('Average sector score: ' + str(average_sector_score[-1]))\n",
        "            print('Average sector score (IoU): ' + str(average_sector_iou[-1]))\n",
        "\n",
        "            # plt.axis('off')\n",
        "            # plt.savefig(output_crops_folder + '/Colony Corrected Sector Bounds/' + pathlib.Path(test_image).stem + '_Colony_' + str(this_index) + '.png', bbox_inches='tight', pad_inches=0)\n",
        "            # plt.close();\n",
        "            #raise NameError('Text to read') \n",
        "\n",
        "            corrected_white_region_sum.append(np.sum(np.logical_xor(corrected_colony_mask, all_sector_filled)))\n",
        "            corrected_red_region_sum.append(np.sum(all_sector_filled))\n",
        "            corrected_sector_region_sum.append(np.sum(all_sector_filled) / np.sum(corrected_colony_mask))\n",
        "\n",
        "            true_sector_count = 0\n",
        "            true_sector_counts.append(true_sector_count)\n",
        "            true_sector_region_sum.append(0)\n",
        "            corrected_colony_mask_faded[corrected_colony_mask == 0] = 0\n",
        "\n",
        "            corrected_colony_mask_faded = np.pad(corrected_colony_mask_faded, image_padding)\n",
        "            corrected_red_colony_mask_padded = np.pad(corrected_red_colony_mask, image_padding)\n",
        "            corrected_sector_comp_mask = np.multiply(corrected_red_colony_mask_padded, corrected_colony_mask_faded)\n",
        "\n",
        "            #colony_image_padded = np.pad(colony_image, image_padding)\n",
        "            #cv2_imshow(colony_mask_faded)\n",
        "            if save_all_annotations == True:\n",
        "                if not cv2.imwrite(output_crops_folder + '/sectors/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', corrected_colony_mask_faded):\n",
        "                    raise Exception('Could not write image.')\n",
        "                if not cv2.imwrite(output_crops_folder + '/sector_comps/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', corrected_sector_comp_mask):\n",
        "                    raise Exception('Could not write image.')\n",
        "            \n",
        "            # # Plot image and lines with matplotlib\n",
        "            # Recall that endpoints_x[0], endpoints_y[0] is the center of the colony, and\n",
        "            # endpoints_x[#], endpoints_y[#] is a point on the boundary representing the interfacial point of a sector\n",
        "            \n",
        "\n",
        "            # Output labellings of colonies to directory\n",
        "\n",
        "            # 1. Get the sectors labellings you defined.\n",
        "            # 2. Get intersection of this labelling with the colony mask.\n",
        "            # 3. Create copy of colony mask that is faded.  (sectors will be overlayed on this in the next step)\n",
        "            # 4. Save cropping to Colony Sectors folder \n",
        "\n",
        "            # colony_cropping = p[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1)]\n",
        "\n",
        "            # height, width = colony_cropping.shape[:2]\n",
        "            # # Do some plotting to see the results in action, and to find potential problems\n",
        "            # cv2_imshow(255*cv2.resize(x[(top_left_y-1):(top_left_y + box_height - 1), (top_left_x-1):(top_left_x + box_width - 1)], (4*width, 4*height)))\n",
        "            # cv2_imshow(cv2.resize(colony_cropping, (4*width, 4*height)))\n",
        "            # fig, ax = plt.subplots(1,4)\n",
        "            # ax[0].imshow(np.squeeze(colony_image))\n",
        "            # ax[1].imshow(all_sector_bounds)\n",
        "            # ax[2].imshow(all_sector_filled)\n",
        "            # ax[3].imshow(all_sector_filled_labels * (255 / (total_sectors+1)))\n",
        "            # plt.show()\n",
        "\n",
        "            # these_thetas_sorted, sorted_points = sort_thetas(edge_mask_unpadded)\n",
        "            # intensity_sum_red, full_seg_sum_red = get_intensity_map(red_colony_mask, sorted_points)\n",
        "            # intensity_sum_white, full_seg_sum_white = get_intensity_map(white_colony_mask, sorted_points)\n",
        "            # intensity_sum_full, full_seg_sum_full = get_intensity_map(colony_mask, sorted_points)\n",
        "\n",
        "            # fig, ax = plt.subplots(1,3,subplot_kw={'projection': 'polar'}, figsize=(15, 4))\n",
        "\n",
        "            # ax[0].plot(these_thetas_sorted, intensity_sum_red)\n",
        "            # #ax.plot(these_thetas_sorted, full_seg_sum)\n",
        "            # ax[0].set_rmax(max(colony_image.shape)/2.0)\n",
        "            # ax[0].grid(True)\n",
        "            # ax[0].set_title(\"Red Pixels by Angle\", va='bottom')\n",
        "\n",
        "            # ax[1].plot(these_thetas_sorted, intensity_sum_white)\n",
        "            # #ax.plot(these_thetas_sorted, full_seg_sum)\n",
        "            # ax[1].set_rmax(max(colony_image.shape)/2.0)\n",
        "            # ax[1].grid(True)\n",
        "            # ax[1].set_title(\"White Pixels by Angle\", va='bottom')\n",
        "\n",
        "            # ax[2].plot(these_thetas_sorted, intensity_sum_full)\n",
        "            # #ax.plot(these_thetas_sorted, full_seg_sum)\n",
        "            # ax[2].set_rmax(max(colony_image.shape)/2.0)\n",
        "            # ax[2].grid(True)\n",
        "            # ax[2].set_title(\"Colony Pixels by Angle\", va='bottom')\n",
        "\n",
        "            # plt.show()\n",
        "\n",
        "\n",
        "\n",
        "        # This ends the loop on the isolated colonies\n",
        "\n",
        "        # Ensure that the number of sectors are integers\n",
        "        \n",
        "        \n",
        "        # Construct a dataframe with the nubmer of sectors and the proportion of red present\n",
        "\n",
        "        all_sector_counts_array = np.array(all_sector_counts).astype(int)\n",
        "        true_sector_counts = np.array(true_sector_counts).astype(int)\n",
        "        #true_sector_counts = np.repeat(1,len(indiv_good))\n",
        "        correct_sector_count = np.abs(true_sector_counts - all_sector_counts_array) == 0\n",
        "\n",
        "        sides_vert_top_array = np.array(sides_vert_top)\n",
        "        sides_vert_bottom_array = np.array(sides_vert_bottom)\n",
        "        sides_horz_left_array = np.array(sides_horz_left)\n",
        "        sides_horz_right_array = np.array(sides_horz_right)\n",
        "        \n",
        "        # Gather all data that that can be created as a numpy array\n",
        "        d = {'Plate Name': plate_names,\n",
        "            'Colony Number': colony_numbers.astype(int),\n",
        "            'True # Sectors': true_sector_counts,\n",
        "            'Initial # Regions': np.array(initial_region_counts).astype(int),\n",
        "            'Pred # Sectors': all_sector_counts_array,\n",
        "            'Correct # Sectors?': correct_sector_count,\n",
        "            'White Area (Seg)': white_region_sum,\n",
        "            'Red Area (Seg)': red_region_sum,\n",
        "            'Colony Area (Seg)': (np.array(white_region_sum) + np.array(red_region_sum)),\n",
        "            'White Area (Corr)': corrected_white_region_sum,\n",
        "            'Red Area (Corr)': corrected_red_region_sum,\n",
        "            'Colony Area (Corr)': (np.array(corrected_white_region_sum) + np.array(corrected_red_region_sum)),\n",
        "            'Avg Sector Score': average_sector_score,\n",
        "            'Avg Sector Score (IoU)': average_sector_iou,\n",
        "            'Side Top': sides_vert_top_array,\n",
        "            'Side Bottom': sides_vert_bottom_array,\n",
        "            'Side Left': sides_horz_left_array,\n",
        "            'Side Right': sides_horz_right_array,\n",
        "            '1 Comp': np.array(colony_is_connected),\n",
        "            '1 Comp (Approx)': np.array(colony_is_approx_connected),\n",
        "            'Bound Comp': np.array(boundary_is_connected),\n",
        "            'No Holes': np.array(colony_is_whole),\n",
        "            'Approx Convex': np.array(colony_is_approx_convex),\n",
        "            'Approx Circle': np.array(colony_is_approx_circular),\n",
        "            'Hausdorff Convex': np.array(hausdorff_dist_convex),\n",
        "            'Hausdorff Circle': np.array(hausdorff_dist_circle)}\n",
        "\n",
        "        #Gather data based on what else we used as input\n",
        "        if use_expert_counts == True:\n",
        "            d['Quantifiable'] = np.array(quantifiable_colony)\n",
        "            d['Quantifiable Cured'] = np.array(quantifiable_cured)\n",
        "            d['Quantifiable Stable'] = np.array(quantifiable_stable)\n",
        "            d['Quantifiable Sectored'] = np.array(quantifiable_sectored)\n",
        "\n",
        "        df = pd.DataFrame(data=d)\n",
        "\n",
        "        # Gather data that could NOT be stored as a numpy array, such as nested lists\n",
        "\n",
        "        df['(BC) Regional Color Classes'] = list(region_color_before)\n",
        "        df['(BC) Regional Sizes'] = list(region_sizes_before)\n",
        "        df['(BC) Regional Purity Scores'] = list(region_purity_before)\n",
        "        df['(BC) Red Purity Scores Weighted'] = list(weighted_purity_red_before)\n",
        "        df['(BC) White Purity Scores Weighted'] = list(weighted_purity_white_before)\n",
        "        df['(BC) Weighted Red Average Score'] = weighted_red_sector_score_before\n",
        "        df['(BC) Weighted White Average Score'] = weighted_white_sector_score_before\n",
        "        df['(BC) Weighted Full Average Score'] = weighted_sector_score_before\n",
        "        df['(BC) Cured'] = cured_colony_before\n",
        "        df['(BC) Stable'] = stable_colony_before\n",
        "\n",
        "        df['(AC) Regional Color Classes'] = list(region_color_after)\n",
        "        df['(AC) Regional Sizes'] = list(region_sizes_after)\n",
        "        df['(AC) Regional Purity Scores'] = list(region_purity_after)\n",
        "        df['(AC) Red Purity Scores Weighted'] = list(weighted_purity_red_after)\n",
        "        df['(AC) White Purity Scores Weighted'] = list(weighted_purity_white_after)\n",
        "        df['(AC) Weighted Red Average Score'] = weighted_red_sector_score_after\n",
        "        df['(AC) Weighted White Average Score'] = weighted_white_sector_score_after\n",
        "        df['(AC) Weighted Full Average Score'] = weighted_sector_score_after\n",
        "        df['(AC) Cured'] = cured_colony_after\n",
        "        df['(AC) Stable'] = stable_colony_after\n",
        "\n",
        "        df.to_pickle(test_output_table_folder + '/' + str(plate_stem) + '.pkl')\n",
        "\n",
        "        # if starting_image == False:\n",
        "        #     #print('This ran.')\n",
        "        #     all_df = pd.concat([all_df, df], axis=0, ignore_index=True)\n",
        "        #     #print('The dataframe was appended.')\n",
        "        # else:\n",
        "        #     starting_image = False\n",
        "        #     all_df = copy.deepcopy(df)\n",
        "\n",
        "    #all_df\n",
        "    # all_df.to_pickle(test_output_folder + '/' + str(weights_file) + '_colony_data.pkl')\n",
        "    # unpickled_all_df = pd.read_pickle(test_output_folder + '/' + str(weights_file) + '_colony_data.pkl')\n",
        "    # unpickled_all_df.to_csv(test_output_folder + '/' + str(weights_file) + '_colony_data.csv')\n",
        "\n",
        "    # unpickled_all_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0EAAIKfsEHn"
      },
      "source": [
        "## Merge output tables into one"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLhnWs26sEHq"
      },
      "outputs": [],
      "source": [
        "# Read in all the files of data\n",
        "sorted_tables = sorted(glob.glob(test_output_table_folder + '/' + '*'))\n",
        "print(sorted_tables)\n",
        "\n",
        "first_table = True\n",
        "\n",
        "for this_table in sorted_tables:\n",
        "    this_table_data = pd.read_pickle(this_table)\n",
        "    if first_table == True:\n",
        "        first_table = False\n",
        "        all_table_data = copy.deepcopy(this_table_data)\n",
        "    else:\n",
        "        all_table_data = pd.concat([all_table_data, this_table_data], axis=0, ignore_index=True)\n",
        "\n",
        "all_table_data.to_pickle(test_output_folder + '/' + str(weights_file) + '_colony_data.pkl')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7tNuwGg2sEHr"
      },
      "source": [
        "## Load the merged table on training data and display it"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wcXvHFO8sEHs"
      },
      "outputs": [],
      "source": [
        "#colony_data = pd.read_csv(output_data_folder + '/' + str(weights_file) + '_colony_data_CHT_' + str(num_classes) + '_puritycheck_byregion.csv')\n",
        "#colony_data = pd.read_csv(test_output_folder + '/' + str(weights_file) + '_colony_data_CHT_puritycheck_byregion.csv')\n",
        "#colony_data = pd.read_csv(test_output_folder + '/' + str(weights_file) + '_colony_data_2.csv')\n",
        "colony_data = pd.read_pickle(test_output_folder + '/' + str(weights_file) + '_colony_data.pkl')\n",
        "\n",
        "#print(colony_data)\n",
        "all_plate_names = colony_data['Plate Name'].unique()\n",
        "all_sector_values = list(range(0, int(np.max(colony_data['Pred # Sectors']))+1))\n",
        "\n",
        "# Include true sector counts if available\n",
        "if use_true_sector_counts == True:\n",
        "\n",
        "    # Read in table with true sector counts\n",
        "    true_sector_counts = pd.read_csv(test_output_folder + '/true_colony_data.csv') # load file containing true sector counts\n",
        "    colony_data['True # Sectors'] = true_sector_counts['True # Sectors'] # insert the true sector counts in the data\n",
        "    matching_sector_counts = colony_data['True # Sectors'] == colony_data['Pred # Sectors'] # compare the true and predicted sector counts\n",
        "    colony_data['Correct # Sectors?'] = matching_sector_counts # mark where the counts match and insert this into the data\n",
        "\n",
        "if use_quantifiable_counts_from_table == True:\n",
        "    true_quant_colonies = pd.read_csv(test_output_folder + '/true_quantifiable_colonies.csv') # load file containing whether colony is cured\n",
        "    colony_data['Quantifiable'] = true_quant_colonies['Quantifiable'] # insert this data into the original table\n",
        "    \n",
        "if use_true_cured_colonies_from_table == True:\n",
        "    # Read in table with true cured colonies\n",
        "    true_cured_colonies = pd.read_csv(test_output_folder + '/true_cured_colonies.csv') # load file containing whether colony is cured\n",
        "    colony_data['Is Cured?'] = true_cured_colonies['Is Cured?'] # insert this data into the original table\n",
        "\n",
        "if (use_true_sector_counts == True) & (use_quantifiable_counts_from_table == True) & (use_true_cured_colonies_from_table == True):\n",
        "    colony_data['Quantifiable Cured'] = (colony_data['Quantifiable'] == True) & (colony_data['Is Cured?'] == True)\n",
        "    colony_data['Quantifiable Stable'] = (colony_data['Quantifiable'] == True) & (colony_data['True # Sectors'] == 0)\n",
        "    colony_data['Quantifiable Sectored'] = (colony_data['Quantifiable'] == True) & (colony_data['True # Sectors'] > 0) & (colony_data['Is Cured?'] == False)\n",
        "\n",
        "# Since this is training data, we know the number of sectors\n",
        "colony_data['True # Sectors'] = np.repeat(1, len(colony_data['Pred # Sectors']))\n",
        "colony_data['Is Cured?'] = np.repeat(False, len(colony_data['Pred # Sectors']))\n",
        "colony_data['Is Stable?'] = np.repeat(False, len(colony_data['Pred # Sectors']))\n",
        "    \n",
        "colony_data.to_pickle(test_output_folder + '/' + str(weights_file) + '_colony_data.pkl')\n",
        "#colony_data.to_pickle(output_data_folder + '/' + str(weights_file) + '_colony_data_CHT_' + str(num_classes) + '_puritycheck_byregion.pkl')\n",
        "#colony_data.to_csv(output_data_folder + '/' + str(weights_file) + '_colony_data_CHT_' + str(num_classes) + '_puritycheck_byregion.csv')\n",
        "\n",
        "colony_data.to_csv(test_output_folder + '/' + str(weights_file) + '_colony_data.csv')\n",
        "colony_data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "932e4Gjmwdgi"
      },
      "source": [
        "## Quick Calculations"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15VkgOZfsCKH"
      },
      "source": [
        "### Colonies detected and average purity scores"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "013klDEQwfU-"
      },
      "outputs": [],
      "source": [
        "# Average purity score for a given plate\n",
        "this_plate_data = colony_data[colony_data['Plate Name'] == 'Plate_2.jpg'] # Just example code\n",
        "#print(this_plate_data.iloc[40])\n",
        "for this_plate_name in all_plate_names:\n",
        "    this_plate_data = colony_data[colony_data['Plate Name'] == this_plate_name]\n",
        "    print('')\n",
        "    print('Plate: ' + str(this_plate_name))\n",
        "    print('Number of colonies detected: ' + str(len(this_plate_data['Plate Name'])))\n",
        "    print('Number of Cured Colonies: ' + str(np.sum((this_plate_data['Red Area (Seg)'] / this_plate_data['Colony Area (Seg)']) >= 0.95)))\n",
        "    print('Average purity scores across all colonies detected in the plate: ' + str(np.mean(this_plate_data['(AC) Weighted Full Average Score'])))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2G-caGfsIHc"
      },
      "source": [
        "### Quantifiable colonies detected"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zre4Yf9k-rL4"
      },
      "outputs": [],
      "source": [
        "# Quantifiable colony counts\n",
        "if use_expert_counts == True:\n",
        "    for this_plate_name in all_plate_names:\n",
        "        this_plate_data = colony_data[colony_data['Plate Name'] == this_plate_name]\n",
        "        good_plate_data = this_plate_data[this_plate_data['Quantifiable'] == True]\n",
        "        print('')\n",
        "        print('Plate: ' + str(this_plate_name))\n",
        "        print('Colonies detected: ' + str(len(this_plate_data['Quantifiable'])))\n",
        "        print('Quantifiable colonies detected: ' + str(len(good_plate_data['Quantifiable'])))\n",
        "else:\n",
        "    print('Quantifiable colonies not considered in this set')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ai8FHWFsEHu"
      },
      "source": [
        "## Get colony labels ([PSI+], [psi-], and Sectored)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "colony_states_before = np.array(['UNFILLED' for i in range(0, len(colony_data))])\n",
        "colony_states_after = np.array(['UNFILLED' for i in range(0, len(colony_data))])\n",
        "colony_states_true = np.array(['UNFILLED' for i in range(0, len(colony_data))])\n",
        "#colony_states_set = set(colony_states)\n",
        "#print(colony_states_set)\n",
        "\n",
        "max_sector_count_before = max(colony_data['Initial # Regions'])\n",
        "max_sector_count_after = max(colony_data['Pred # Sectors'])\n",
        "max_sector_count_true = max(colony_data['True # Sectors'])\n",
        "\n",
        "max_sector_count_all = max([max_sector_count_before, max_sector_count_after, max_sector_count_true])\n",
        "\n",
        "# [PSI+]: Get all colonies with no red regions\n",
        "\n",
        "colony_states_before[(colony_data['(BC) Stable'] == True)] = '[PSI+]'\n",
        "colony_states_after[(colony_data['(AC) Stable'] == True)] = '[PSI+]'\n",
        "colony_states_true[(colony_data['Is Stable?'] == True)] = '[PSI+]'\n",
        "\n",
        "# [psi-]: Get all quantifiable colonies with no white regions\n",
        "\n",
        "colony_states_before[(colony_data['(BC) Cured'] == True)] = '[psi-]'\n",
        "colony_states_after[(colony_data['(AC) Cured'] == True)] = '[psi-]'\n",
        "colony_states_true[(colony_data['Is Cured?'] == True)] = '[psi-]'\n",
        "\n",
        "# Sx: Get all quantifiable colonies with at least 1 white region and exactly x red regions \n",
        "\n",
        "for num_regions in range(1, max_sector_count_all+1):\n",
        "    colony_states_before[(colony_data['(BC) Cured'] == False) & (colony_data['(BC) Stable'] == False) & (colony_data['Initial # Regions'] == num_regions)] = str('S' + str(num_regions))\n",
        "    colony_states_after[(colony_data['(AC) Cured'] == False) & (colony_data['(AC) Stable'] == False) & (colony_data['Pred # Sectors'] == num_regions)] = str('S' + str(num_regions))\n",
        "    colony_states_true[(colony_data['Is Cured?'] == False) & (colony_data['Is Stable?'] == False) & (colony_data['True # Sectors'] == num_regions).astype(bool)] = str('S' + str(num_regions))\n",
        "\n",
        "#print(np.unique(colony_states_before))\n",
        "#print(np.unique(colony_states_after))\n",
        "#print(np.unique(colony_states_true))\n",
        "\n",
        "unmarked_locations = np.where(colony_states_true == 'UNFILLED')\n",
        "\n",
        "# Make corrections to the table for unfilled locations\n",
        "\n",
        "\n",
        "# Display any colony locations what are marked as UNFILLED\n",
        "\n",
        "colony_row = colony_data.iloc[unmarked_locations]\n",
        "#print(colony_row)\n",
        "#print(colony_row.index)\n",
        "\n",
        "#print(colony_states_before)\n",
        "\n",
        "# If every location has been filled, then add these to the merged table\n",
        "colony_data['Label Before'] = colony_states_before\n",
        "colony_data['Label After'] = colony_states_after\n",
        "colony_data['Label True'] = colony_states_true\n",
        "\n",
        "#print(quantifiable_colony_data['Label Before'])\n",
        "# counter = 0\n",
        "\n",
        "# for ind in colony_row.index:\n",
        "#     colony_number = colony_row['Colony Number'].iloc[counter]\n",
        "#     plate_name = colony_row['Plate Name'].iloc[counter]\n",
        "#     set_number = colony_row['Set'].iloc[counter]\n",
        "\n",
        "#     #if counter == 0:\n",
        "#     #    merged_table['Quantifiable Stable'] = \n",
        "\n",
        "#     # Get image\n",
        "#     if set_number == 2:\n",
        "#         image_to_display = read_image(sector_project_folder + '/Real Images/Wes Plates/Set 2 Prepro/' + plate_name)*255\n",
        "#     image_to_display = cv2.rectangle(image_to_display, (colony_row['Side Left'].iloc[counter], colony_row['Side Top'].iloc[counter]), (colony_row['Side Right'].iloc[counter], colony_row['Side Bottom'].iloc[counter]), (255, 0, 0), 2)\n",
        "#     #cv2_imshow(image_to_display)"
      ],
      "metadata": {
        "id": "Qzqw1fdA1a3k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27TndfjkmX_M"
      },
      "source": [
        "## Show Locations of Extracted Colonies in Each Image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HroV_MWpmmJg"
      },
      "outputs": [],
      "source": [
        "def get_color_codes(p):\n",
        "    if p == 0: # bad_seg\n",
        "        color_code = (0,255,0)\n",
        "    elif p == 1: # pink\n",
        "        color_code = (255,0,255)\n",
        "    elif p == 2: # red\n",
        "        color_code = (0,0,255)\n",
        "    elif p == 3: # variegating\n",
        "        color_code = (255,0,0)\n",
        "    elif p == 4: # white\n",
        "        color_code = (255,255,255)\n",
        "    return color_code\n",
        "\n",
        "all_plate_names = colony_data['Plate Name'].unique()\n",
        "all_sector_values = list(range(0, np.max(colony_data['Pred # Sectors'])+1))\n",
        "\n",
        "# iterate through each plate\n",
        "for this_plate_name in all_plate_names:\n",
        "\n",
        "    this_plate_stem = os.path.splitext(this_plate_name)[0]\n",
        "    print('Looking at ' + str(this_plate_name) + ':')\n",
        "    this_plate_data = colony_data[colony_data['Plate Name'] == this_plate_name]\n",
        "    number_colonies = len(this_plate_data) # number of colonies found\n",
        "    print(number_colonies)\n",
        "    indicator_array = [] #initialize\n",
        "\n",
        "    for this_colony in range(0, number_colonies):\n",
        "        # Check if the colony was predicted to be red (cured)\n",
        "        if (this_plate_data['(AC) Cured'].iloc[this_colony]) & (this_plate_data['Pred # Sectors'].iloc[this_colony] == 1):\n",
        "            indicator_array.append(2)\n",
        "        # Check if the colony was predicted to be white (stable)\n",
        "        elif (this_plate_data['(AC) Stable'].iloc[this_colony]) & (this_plate_data['Pred # Sectors'].iloc[this_colony] == 0):\n",
        "            indicator_array.append(4)\n",
        "        # Check if the colony was predicted to be variegating (sectored, neither cured nor stable)\n",
        "        elif (not ((this_plate_data['(AC) Stable'].iloc[this_colony]) | (this_plate_data['(AC) Cured'].iloc[this_colony]))) & (this_plate_data['Pred # Sectors'].iloc[this_colony] > 0):\n",
        "            indicator_array.append(3)\n",
        "        # Anything else is a bad segmentation.  Pink colonies are not considered, so 1 is not assigned\n",
        "        else:\n",
        "            indicator_array.append(0)\n",
        "    \n",
        "    indicator_array = np.array(indicator_array)\n",
        "    # Display total number of colonies for each label\n",
        "    print('Bad segementations: ' + str(np.sum(indicator_array == 0)))\n",
        "    print('Fully red colonies: ' + str(np.sum(indicator_array == 2)))\n",
        "    print('Fully white colonies: ' + str(np.sum(indicator_array == 4)))\n",
        "    print('Sectored colonies: ' + str(np.sum(indicator_array == 3)))\n",
        "\n",
        "\n",
        "    # Plot the boxes onto the image\n",
        "    this_image = read_image(real_image_folder + '/' + this_plate_name)\n",
        "    this_img_copy = copy.deepcopy(this_image)*255\n",
        "    print(len(indicator_array))\n",
        "    for this_row in range(0,number_colonies):\n",
        "        this_pred = indicator_array[this_row]\n",
        "        cv2.rectangle(this_img_copy, (this_plate_data['Side Left'].iloc[this_row], this_plate_data['Side Top'].iloc[this_row]), (this_plate_data['Side Right'].iloc[this_row], this_plate_data['Side Bottom'].iloc[this_row]), get_color_codes(this_pred), 2)\n",
        "        #cv2.rectangle(this_img_copy, (this_plate_data['Side Top'].iloc[this_row], this_plate_data['Side Left'].iloc[this_row]), (this_plate_data['Side Bottom'].iloc[this_row], this_plate_data['Side Right'].iloc[this_row]), get_color_codes(this_pred), 2)\n",
        "    cv2_imshow(this_img_copy)\n",
        "\n",
        "    cv2.imwrite(test_boxes_folder + '/' + this_plate_stem + '.jpg', this_img_copy)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Plots of Testing Data"
      ],
      "metadata": {
        "id": "IW6BvXpaA7Ox"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Predictions Only"
      ],
      "metadata": {
        "id": "bhPRlMtpBA2i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Colony States (no sector counts)"
      ],
      "metadata": {
        "id": "E6bBPF7QBDms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#print(sampled_colony_data.keys())\n",
        "#print(sampled_colony_data['Is it a colony? '])\n",
        "\n",
        "\n",
        "max_initial = np.max(colony_data['Initial # Regions'])\n",
        "max_pred = np.max(colony_data['Pred # Sectors'])\n",
        "#max_true = np.max(colony_data['True # Sectors'])\n",
        "max_all = np.max([max_initial, max_pred])\n",
        "#diff_count_before = np.abs(colony_data['Initial # Regions'] - colony_data['True # Sectors'])\n",
        "#diff_count_after = np.abs(colony_data['Pred # Sectors'] - colony_data['True # Sectors'])\n",
        "\n",
        "label_names = ['[PSI+]', '[psi-]', 'Sectored']\n",
        "\n",
        "initial_correct_counts = []\n",
        "post_correct_counts = []\n",
        "#true_correct_counts = []\n",
        "all_counts = []\n",
        "\n",
        "\n",
        "\n",
        "# print(np.unique(colony_data['Label True']))\n",
        "\n",
        "# Gather [PSI+] counts\n",
        "#true_white_labels = colony_data[(colony_data['Label True'] == '[PSI+]')]\n",
        "correct_white_labels_before = colony_data[(colony_data['Label Before'] == '[PSI+]')]\n",
        "correct_white_labels_after = colony_data[(colony_data['Label After'] == '[PSI+]')]\n",
        "\n",
        "initial_correct_counts.append(len(correct_white_labels_before))\n",
        "post_correct_counts.append(len(correct_white_labels_after))\n",
        "#true_correct_counts.append(len(true_white_labels))\n",
        "\n",
        "# Gather [psi-] counts\n",
        "#true_red_labels = colony_data[(colony_data['Label True'] == '[psi-]')]\n",
        "correct_red_labels_before = colony_data[(colony_data['Label Before'] == '[psi-]')]\n",
        "correct_red_labels_after = colony_data[(colony_data['Label After'] == '[psi-]')]\n",
        "\n",
        "initial_correct_counts.append(len(correct_red_labels_before))\n",
        "post_correct_counts.append(len(correct_red_labels_after))\n",
        "#true_correct_counts.append(len(true_red_labels))\n",
        "\n",
        "\n",
        "# Gather sectored counts\n",
        "correct_sector_labels_before = colony_data[(colony_data['Label Before'].str.startswith('S'))]\n",
        "correct_sector_labels_after = colony_data[(colony_data['Label After'].str.startswith('S'))]\n",
        "\n",
        "initial_correct_counts.append(len(correct_sector_labels_before))\n",
        "post_correct_counts.append(len(correct_sector_labels_after))\n",
        "#max_sector_counts = max([np.nanmax(colony_data['Initial # Regions'].astype(int)), np.nanmax(colony_data['Pred # Sectors'].astype(int)), np.nanmax(colony_data['True # Sectors'].astype(int))])\n",
        "# print(max_sector_counts)\n",
        "\n",
        "# for this_num_sectors in range(1, max_sector_counts+1):\n",
        "#     #true_sector_labels = colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors))]\n",
        "#     correct_sector_labels_before = colony_data[(colony_data['Label Before'] == 'S'+str(this_num_sectors))]\n",
        "#     correct_sector_labels_after = colony_data[(colony_data['Label After'] == 'S'+str(this_num_sectors))]\n",
        "\n",
        "#     initial_correct_counts.append(len(correct_sector_labels_before))\n",
        "#     post_correct_counts.append(len(correct_sector_labels_after))\n",
        "#     #true_correct_counts.append(len(true_sector_labels))\n",
        "\n",
        "# print(colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors)) & (colony_data['Label After'] == 'S'+str(this_num_sectors))])\n",
        "#sector_labels = ['S'+str(i) for i in (range(1, max_sector_counts+1))]\n",
        "# print(sector_labels)\n",
        "#label_names = label_names + sector_labels\n",
        "# print(label_names)\n",
        "x = np.arange(len(label_names))\n",
        "# print(len(x))\n",
        "# print(len(initial_correct_counts))\n",
        "\n",
        "\n",
        "\n",
        "width = 0.25  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,5), sharey=True)\n",
        "#x - width/2\n",
        "ax.set_ylim(bottom=0, top=max(initial_correct_counts + post_correct_counts)+50)\n",
        "rects1 = ax.bar(x - width/2, initial_correct_counts, width, label='Original Predictions', color='blue')\n",
        "rects2 = ax.bar(x+width/2, post_correct_counts, width, label='With Purity Correction', color='red')\n",
        "#rects2 = ax.bar(x + width/2, all_counts, width, label='All Colonies', color='red')\n",
        "#rects3 = ax.bar(x + width, true_correct_counts, width, label='Manual Counts', color='green')\n",
        "\n",
        "#print(true_single_frequency)\n",
        "#print(pred_single_frequency)\n",
        "\n",
        "ax.set_xlabel('Colony States')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title('Classified Colonies', fontsize=16)\n",
        "ax.xaxis.label.set_fontsize(14)\n",
        "ax.yaxis.label.set_fontsize(14)\n",
        "ax.set_xticks(np.arange(0, 3, step=1))\n",
        "ax.set_xticklabels(label_names)\n",
        "ax.tick_params(axis='both', labelsize=12)\n",
        "ax.legend(loc='best')\n",
        "\n",
        "xtickslocs = ax.get_xticks()\n",
        "print(xtickslocs)\n",
        "\n",
        "addlabels_centered(xtickslocs-width/2, initial_correct_counts, 9)\n",
        "addlabels_centered(xtickslocs+width/2, post_correct_counts, 9)\n",
        "#addlabels_pred(x, all_counts, 10)\n",
        "#addlabels_truemarks(x, true_correct_counts, 9)\n",
        "\n",
        "ax.axvline(x = 0.5, color = 'k', linestyle = '--')\n",
        "ax.axvline(x = 1.5, color = 'k', linestyle = '--')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "cFCtfOeYBHNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Colony States (with sector counts)"
      ],
      "metadata": {
        "id": "ajNSt08EBHig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#print(sampled_colony_data.keys())\n",
        "#print(sampled_colony_data['Is it a colony? '])\n",
        "\n",
        "\n",
        "max_initial = np.max(colony_data['Initial # Regions'])\n",
        "max_pred = np.max(colony_data['Pred # Sectors'])\n",
        "#max_true = np.max(colony_data['True # Sectors'])\n",
        "max_all = np.max([max_initial, max_pred])\n",
        "#diff_count_before = np.abs(colony_data['Initial # Regions'] - colony_data['True # Sectors'])\n",
        "#diff_count_after = np.abs(colony_data['Pred # Sectors'] - colony_data['True # Sectors'])\n",
        "\n",
        "initial_correct_counts = []\n",
        "post_correct_counts = []\n",
        "#true_correct_counts = []\n",
        "all_counts = []\n",
        "\n",
        "label_names = ['[PSI+]', '[psi-]']\n",
        "\n",
        "# print(np.unique(colony_data['Label True']))\n",
        "\n",
        "# Gather [PSI+] counts\n",
        "#true_white_labels = colony_data[(colony_data['Label True'] == '[PSI+]')]\n",
        "correct_white_labels_before = colony_data[(colony_data['Label Before'] == '[PSI+]')]\n",
        "correct_white_labels_after = colony_data[(colony_data['Label After'] == '[PSI+]')]\n",
        "\n",
        "initial_correct_counts.append(len(correct_white_labels_before))\n",
        "post_correct_counts.append(len(correct_white_labels_after))\n",
        "#true_correct_counts.append(len(true_white_labels))\n",
        "\n",
        "# Gather [psi-] counts\n",
        "#true_red_labels = colony_data[(colony_data['Label True'] == '[psi-]')]\n",
        "correct_red_labels_before = colony_data[(colony_data['Label Before'] == '[psi-]')]\n",
        "correct_red_labels_after = colony_data[(colony_data['Label After'] == '[psi-]')]\n",
        "\n",
        "initial_correct_counts.append(len(correct_red_labels_before))\n",
        "post_correct_counts.append(len(correct_red_labels_after))\n",
        "#true_correct_counts.append(len(true_red_labels))\n",
        "\n",
        "\n",
        "# Gather sectored counts\n",
        "max_sector_counts = max([np.nanmax(colony_data['Initial # Regions'].astype(int)), np.nanmax(colony_data['Pred # Sectors'].astype(int)), np.nanmax(colony_data['True # Sectors'].astype(int))])\n",
        "# print(max_sector_counts)\n",
        "\n",
        "for this_num_sectors in range(1, max_sector_counts+1):\n",
        "    #true_sector_labels = colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors))]\n",
        "    correct_sector_labels_before = colony_data[(colony_data['Label Before'] == 'S'+str(this_num_sectors))]\n",
        "    correct_sector_labels_after = colony_data[(colony_data['Label After'] == 'S'+str(this_num_sectors))]\n",
        "\n",
        "    initial_correct_counts.append(len(correct_sector_labels_before))\n",
        "    post_correct_counts.append(len(correct_sector_labels_after))\n",
        "    #true_correct_counts.append(len(true_sector_labels))\n",
        "\n",
        "# print(colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors)) & (colony_data['Label After'] == 'S'+str(this_num_sectors))])\n",
        "sector_labels = ['S'+str(i) for i in (range(1, max_sector_counts+1))]\n",
        "# print(sector_labels)\n",
        "label_names = label_names + sector_labels\n",
        "# print(label_names)\n",
        "x = np.arange(len(label_names))\n",
        "# print(len(x))\n",
        "# print(len(initial_correct_counts))\n",
        "\n",
        "\n",
        "\n",
        "width = 0.25  # the width of the bars\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(12,5), sharey=True)\n",
        "#x - width/2\n",
        "ax.set_ylim(bottom=0, top=max(initial_correct_counts + post_correct_counts)+50)\n",
        "rects1 = ax.bar(x - width/2, initial_correct_counts, width, label='Original Predictions', color='blue')\n",
        "rects2 = ax.bar(x+width/2, post_correct_counts, width, label='With Purity Correction', color='red')\n",
        "#rects2 = ax.bar(x + width/2, all_counts, width, label='All Colonies', color='red')\n",
        "#rects3 = ax.bar(x + width, true_correct_counts, width, label='Manual Counts', color='green')\n",
        "\n",
        "#print(true_single_frequency)\n",
        "#print(pred_single_frequency)\n",
        "\n",
        "ax.set_xlabel('Colony States')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.set_title('Classified Colonies', fontsize=16)\n",
        "ax.xaxis.label.set_fontsize(14)\n",
        "ax.yaxis.label.set_fontsize(14)\n",
        "ax.set_xticks(np.arange(0, max_sector_counts+2, step=1))\n",
        "ax.set_xticklabels(label_names)\n",
        "ax.tick_params(axis='both', labelsize=12)\n",
        "ax.legend(loc='best')\n",
        "\n",
        "xtickslocs = ax.get_xticks()\n",
        "print(xtickslocs)\n",
        "\n",
        "addlabels_centered(xtickslocs-width/2, initial_correct_counts, 9)\n",
        "addlabels_centered(xtickslocs+width/2, post_correct_counts, 9)\n",
        "#addlabels_pred(x, all_counts, 10)\n",
        "#addlabels_truemarks(x, true_correct_counts, 9)\n",
        "\n",
        "ax.axvline(x = 0.5, color = 'k', linestyle = '--')\n",
        "ax.axvline(x = 1.5, color = 'k', linestyle = '--')\n",
        "\n",
        "fig.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "mkvGj5gXBJ4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Write colony output to file\n",
        "Only works if colony annotations exist"
      ],
      "metadata": {
        "id": "T8HZKouAEgbr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Code to print a pdf of the croppings\n",
        "# 1. Sort data in table based on plate name, colony number and other elements.\n",
        "# 2. Iterate through each row of the sorted table to get colony imformation\n",
        "# 3. Add inforation to pdf document.\n",
        "# 4. Repear for each colony and plate.\n",
        "# 5. Output pdf.\n",
        "\n",
        "# Do the same as above, but group based on the number of sectors detected\n",
        "\n",
        "\n",
        "\n",
        "for this_plate in all_plate_names:\n",
        "\n",
        "    # this_plate is the key to the correspnding subfolder in each annotation class\n",
        "    # Initialize PDF writer\n",
        "    pdf = FPDF()\n",
        "    pdf = FPDF(unit = \"pt\", format = [850,1100])\n",
        "    pdf.set_font('Arial', 'B', 16)\n",
        "    target_height = float(40)\n",
        "    left_margin = 10\n",
        "    right_margin = 840\n",
        "    bottom_margin = 1050\n",
        "    number_spacing = 7\n",
        "    uniform_spacing = 640\n",
        "\n",
        "\n",
        "    row_number = 1 # initial row index\n",
        "    col_position = 10 # initial column position\n",
        "    col_margin = 40\n",
        "    this_plate_stem = os.path.splitext(this_plate)[0]\n",
        "\n",
        "    # all_cropped_images = sorted(glob.glob(output_crops_folder + '/Colony Cuts/' + this_plate_stem + '_' + '*.jpg'))\n",
        "    # all_cropped_circles = sorted(glob.glob(output_crops_folder + '/Colony Circles/' + this_plate_stem + '_' + '*.jpg'))\n",
        "    # all_cropped_masks = sorted(glob.glob(output_crops_folder + '/Colony Segs/' + this_plate_stem + '_' + '*.png'))\n",
        "\n",
        "    # all_cropped_initial_regions = sorted(glob.glob(output_crops_folder + '/Colony Initial Regions/' + this_plate_stem + '_' + '*.png'))\n",
        "    # all_cropped_initial_boundaries = sorted(glob.glob(output_crops_folder + '/Colony Initial Boundary/' + this_plate_stem + '_' + '*.png'))\n",
        "    # all_cropped_initial_bad_regions = sorted(glob.glob(output_crops_folder + '/Colony Initial Bad Regions/' + this_plate_stem + '_' + '*.png'))\n",
        "    # all_cropped_initial_sector_bounds = sorted(glob.glob(output_crops_folder + '/Colony Initial Sector Bounds/' + this_plate_stem + '_' + '*.png'))\n",
        "\n",
        "    # all_cropped_corrected_masks = sorted(glob.glob(output_crops_folder + '/Colony Corrected Segs/' + this_plate_stem + '_' + '*.png'))\n",
        "    # all_cropped_corrected_regions = sorted(glob.glob(output_crops_folder + '/Colony Corrected Regions/' + this_plate_stem + '_' + '*.png'))\n",
        "    # all_cropped_corrected_boundaries = sorted(glob.glob(output_crops_folder + '/Colony Corrected Boundary/' + this_plate_stem + '_' + '*.png'))\n",
        "    # all_cropped_corrected_bad_regions = sorted(glob.glob(output_crops_folder + '/Colony Corrected Bad Regions/' + this_plate_stem + '_' + '*.png'))\n",
        "    # all_cropped_corrected_sector_bounds = sorted(glob.glob(output_crops_folder + '/Colony Corrected Sector Bounds/' + this_plate_stem + '_' + '*.png'))\n",
        "\n",
        "    # all_cropped_sectors = sorted(glob.glob(output_crops_folder + '/Colony Sectors/' + this_plate_stem + '_' + '*.png'))\n",
        "    # all_cropped_sector_comps = sorted(glob.glob(output_crops_folder + '/Colony Sector Comps/' + this_plate_stem + '_' + '*.png'))\n",
        "\n",
        "    #print(all_cropped_images)\n",
        "    #print(all_cropped_circles)\n",
        "    #print(all_cropped_masks)\n",
        "    #print(all_cropped_sectors)\n",
        "    this_plate_data = colony_data[colony_data['Plate Name'] == this_plate]\n",
        "    #this_plate_data.set_index('Colony Number', inplace=True)\n",
        "    max_num_sectors_in_plate = int(max(this_plate_data['Pred # Sectors']))\n",
        "    pdf.add_page()\n",
        "\n",
        "    pdf.text(col_position, target_height*row_number, 'Colonies detected in Plate ' + str(this_plate) + '.  ' + str(len(this_plate_data)) + ' colonies were detected.')\n",
        "    pdf.text(col_position, target_height*row_number + 20, 'Group 1: Raw image data')\n",
        "    pdf.text(col_position, target_height*row_number + 40, 'Group 2: Raw segmentation of whole colony and boundary')\n",
        "    pdf.text(col_position, target_height*row_number + 60, 'Group 3: Regional breakdown and analysis before boundary corrections were made')\n",
        "    pdf.text(col_position, target_height*row_number + 80, 'Group 4: Segmentation with corrected boundary')\n",
        "    pdf.text(col_position, target_height*row_number + 100, 'Group 5: Regional breakdown and analysis after boundary corrections were made')\n",
        "    pdf.text(col_position, target_height*row_number + 120, 'Group 6: Breakdown of red sectored regions and pixels after correction')\n",
        "\n",
        "    row_number = row_number + 2\n",
        "\n",
        "    # Start by collecting all of the [PSI+] predictions\n",
        "    for this_num_sectors in range(0,1):\n",
        "        row_number = row_number + 1\n",
        "        col_position = 10\n",
        "        if (target_height*(row_number+1)) > bottom_margin: # If there is not enough room for rows, move the remaining images to a new page.\n",
        "            pdf.add_page()\n",
        "            row_number = 1 # initial row index\n",
        "        #print(this_plate_data)\n",
        "        this_plate_sector_data = this_plate_data[this_plate_data['Label After'] == '[PSI+]']\n",
        "        #print(this_plate_sector_data)\n",
        "        this_plate_sector_data.reset_index()\n",
        "        #print(this_plate_sector_data)\n",
        "        pdf.text(col_position, target_height*row_number + (target_height/2), 'Colonies labeled [PSI+]: ' + str(len(this_plate_sector_data)))\n",
        "        row_number = row_number + 1\n",
        "\n",
        "        # Sort this subtable by sector scores in descending order\n",
        "        sorted_plate_sector_data = this_plate_sector_data.sort_values(by=['(AC) Weighted Full Average Score', 'Colony Number'], ascending=[False, True])\n",
        "        sorted_plate_sector_data.reset_index()\n",
        "\n",
        "        for index, row in sorted_plate_sector_data.iterrows():\n",
        "\n",
        "            #print('Colony ' + str(int(row['Colony Number'])))\n",
        "            \n",
        "            cured_status = 'Cured' if ((row['Red Area (Seg)'] / row['Colony Area (Seg)']) >= 0.95) else ''\n",
        "\n",
        "            cover_image_name = output_crops_folder + '/raw/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.jpg'\n",
        "            cover_circle_name = output_crops_folder + '/circles/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.jpg'\n",
        "            cover_mask_name = output_crops_folder + '/segs/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_initial_region_name = output_crops_folder + '/init_regions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_initial_boundary_name = output_crops_folder + '/init_bounds/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_initial_bad_region_name = output_crops_folder + '/init_bad/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_initial_sector_bounds_name = output_crops_folder + '/init_partitions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_corrected_mask_name = output_crops_folder + '/cor_segs/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_region_name = output_crops_folder + '/cor_regions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_boundary_name = output_crops_folder + '/cor_bounds/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_bad_region_name = output_crops_folder + '/cor_bad/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_sector_bounds_name = output_crops_folder + '/cor_partitions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_sector_name = output_crops_folder + '/sectors/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_sector_comp_name = output_crops_folder + '/sector_comps/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            if use_expert_counts == True:\n",
        "                cover_counts_name = output_crops_folder + '/counted/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            # cover_region_name = output_crops_folder + '/Colony Regions/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_bad_region_name = output_crops_folder + '/Colony Bad Regions/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_sector_name = output_crops_folder + '/Colony Sectors/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_sector_comp_name = output_crops_folder + '/Colony Sector Comps/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_sector_bounds_name = output_crops_folder + '/Colony Sector Bounds/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_image = PIL.Image.open(cover_image_name, mode='r')\n",
        "            cover_circle = PIL.Image.open(cover_circle_name, mode='r')\n",
        "            cover_mask = PIL.Image.open(cover_mask_name, mode='r')\n",
        "\n",
        "            cover_initial_region = PIL.Image.open(cover_initial_region_name, mode='r')\n",
        "            cover_initial_boundary = PIL.Image.open(cover_initial_boundary_name, mode='r')\n",
        "            cover_initial_bad_region = PIL.Image.open(cover_initial_bad_region_name, mode='r')\n",
        "            cover_initial_sector_bounds = PIL.Image.open(cover_initial_sector_bounds_name, mode='r')\n",
        "\n",
        "            cover_corrected_region = PIL.Image.open(cover_corrected_region_name, mode='r')\n",
        "            cover_corrected_boundary = PIL.Image.open(cover_corrected_boundary_name, mode='r')\n",
        "            cover_corrected_bad_region = PIL.Image.open(cover_corrected_bad_region_name, mode='r')\n",
        "            cover_corrected_sector_bounds = PIL.Image.open(cover_corrected_sector_bounds_name, mode='r')\n",
        "\n",
        "            cover_sector = PIL.Image.open(cover_sector_name, mode='r')\n",
        "            cover_sector_comp = PIL.Image.open(cover_sector_comp_name, mode='r')\n",
        "\n",
        "            if use_expert_counts == True:\n",
        "                cover_counts = PIL.Image.open(cover_counts_name, mode='r')\n",
        "\n",
        "            # cover_region = PIL.Image.open(cover_region_name, mode='r')\n",
        "            # cover_bad_region = PIL.Image.open(cover_bad_region_name, mode='r')\n",
        "            # cover_sector = PIL.Image.open(cover_sector_name, mode='r')\n",
        "            # cover_sector_comp = PIL.Image.open(cover_sector_comp_name, mode='r')\n",
        "            # cover_sector_bounds = PIL.Image.open(cover_sector_bounds_name, mode='r')\n",
        "            #print('This Image: ')\n",
        "            #print(pathlib.Path(all_cropped_images[index]).stem)\n",
        "            #print(pathlib.Path(all_cropped_masks[index]).stem)\n",
        "            #print(pathlib.Path(all_cropped_sectors[index]).stem)\n",
        "            w_im,h_im = cover_image.size\n",
        "            w_ma,h_ma = cover_mask.size\n",
        "            w_annot,h_annot = cover_initial_sector_bounds.size\n",
        "            scaling_factor_im = target_height / float(h_im)\n",
        "            scaling_factor_ma = target_height / float(h_ma)\n",
        "            scaling_factor_annot = target_height / float(h_annot)\n",
        "            scaled_width_im = scaling_factor_im*w_im\n",
        "            scaled_width_ma = scaling_factor_ma*w_ma\n",
        "            scaled_width_annot = scaling_factor_annot*w_annot\n",
        "            scaled_height_im = scaling_factor_im*h_im\n",
        "            scaled_height_ma = scaling_factor_ma*h_ma\n",
        "            scaled_height_annot = scaling_factor_annot*h_annot\n",
        "            #image = all_cropped_images[this_colony]\n",
        "            #mask = all_cropped_masks[this_colony]\n",
        "\n",
        "            # Check that the image, mask, and number will fit inside the margins on the give row, and if not, move them to the next row\n",
        "            if col_position + (3*scaled_width_im) + (10*scaled_width_ma) + (2*scaled_width_annot) + number_spacing > right_margin:\n",
        "                row_number = row_number + 1\n",
        "                col_position = 10\n",
        "                current_col_position = copy.deepcopy(col_position)\n",
        "                if (target_height*(row_number+1)) > bottom_margin: # If there is not enough room for rows, move the remaining images to a new page.\n",
        "                    pdf.add_page()\n",
        "                    row_number = 1 # initial row index\n",
        "            else:\n",
        "                current_col_position = copy.deepcopy(col_position)\n",
        "            #print(all_cropped_images[index])\n",
        "            # Add images and masks to the defined position\n",
        "\n",
        "            # Cropping of colony\n",
        "            pdf.image(cover_image_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony\n",
        "            current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "            # Cropping of colony from Wes's annotations\n",
        "            if use_expert_counts == True:\n",
        "                pdf.image(cover_counts_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony\n",
        "                current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "            # Cropping of colony with circle\n",
        "            pdf.image(cover_circle_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony with overlayed circle\n",
        "            current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # Raw semgentation\n",
        "            pdf.image(cover_mask_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert colony segmentation within the circle\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # The boundary of the raw segmentation\n",
        "            pdf.image(cover_initial_boundary_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert colony segmentation within the circle\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # The regional breakdown of the raw segmentation\n",
        "            pdf.image(cover_initial_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # Annotations of where the red regions are found in the regional breakdown\n",
        "            pdf.image(cover_initial_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "            current_col_position = current_col_position + scaled_width_annot\n",
        "\n",
        "            # The inconsistent regions located\n",
        "            pdf.image(cover_initial_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # The segmentation such that boundary pixels inconsistent with their assigned region were changed\n",
        "            pdf.image(cover_corrected_mask_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # The boundary of the corrected segmentation\n",
        "            pdf.image(cover_corrected_boundary_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # The regional breakdown of the corrected segmentation\n",
        "            pdf.image(cover_corrected_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # Annotations on the corrected segmentations indicating where the red regions are (these should be the sectors)\n",
        "            pdf.image(cover_corrected_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "            current_col_position = current_col_position + scaled_width_annot\n",
        "\n",
        "            # Any inconsistent regions detected in the corrected segmentation (in theory, these should always be completely black)\n",
        "            pdf.image(cover_corrected_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # Partitioning of the red regions found in the corrected segmentation (each shaed of gray is a different sector)\n",
        "            pdf.image(cover_sector_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert predicted sector regions\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "            \n",
        "            # A subset of the previous image with only the red pixels preserved.\n",
        "            pdf.image(cover_sector_comp_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert red pixel segmentations within the predicted secto regions.\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # pdf.image(cover_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # pdf.image(cover_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # current_col_position = current_col_position + 10 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # pdf.image(cover_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "            # current_col_position = current_col_position + scaled_width_annot\n",
        "            \n",
        "            # pdf.image(cover_sector_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert predicted sector regions\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "            \n",
        "            # pdf.image(cover_sector_comp_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert red pixel segmentations within the predicted secto regions.\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "            #col_position = col_position + scaled_width_ma\n",
        "            #pdf.text(current_col_position + number_spacing, target_height*row_number + 16, str('# Sec: ' + str(int(row['Pred # Sectors']))))\n",
        "            pdf.text(current_col_position + number_spacing, target_height*row_number + 16, str('Col #: ' + str(row['Colony Number'])))\n",
        "            pdf.text(current_col_position + number_spacing, target_height*row_number + 36, str('Avg Sc: ' + str(round(row['(AC) Weighted Full Average Score'], 2))))\n",
        "            #pdf.text(current_col_position + number_spacing, target_height*row_number + 76, cured_status)\n",
        "\n",
        "            # make space for the next set of images\n",
        "\n",
        "            col_position = current_col_position + number_spacing + col_margin\n",
        "\n",
        "\n",
        "    # Next, do the same thing for [psi-] predictions\n",
        "    for this_num_sectors in range(0,1):\n",
        "        row_number = row_number + 1\n",
        "        col_position = 10\n",
        "        if (target_height*(row_number+1)) > bottom_margin: # If there is not enough room for rows, move the remaining images to a new page.\n",
        "            pdf.add_page()\n",
        "            row_number = 1 # initial row index\n",
        "        #print(this_plate_data)\n",
        "        this_plate_sector_data = this_plate_data[this_plate_data['Label After'] == '[psi-]']\n",
        "        #print(this_plate_sector_data)\n",
        "        this_plate_sector_data.reset_index()\n",
        "        #print(this_plate_sector_data)\n",
        "        pdf.text(col_position, target_height*row_number + (target_height/2), 'Colonies labeled [psi-]: ' + str(len(this_plate_sector_data)))\n",
        "        row_number = row_number + 1\n",
        "\n",
        "        # Sort this subtable by sector scores in descending order\n",
        "        sorted_plate_sector_data = this_plate_sector_data.sort_values(by=['(AC) Weighted Full Average Score', 'Colony Number'], ascending=[False, True])\n",
        "        sorted_plate_sector_data.reset_index()\n",
        "\n",
        "        for index, row in sorted_plate_sector_data.iterrows():\n",
        "\n",
        "            #print('Colony ' + str(int(row['Colony Number'])))\n",
        "            \n",
        "            cured_status = 'Cured' if ((row['Red Area (Seg)'] / row['Colony Area (Seg)']) >= 0.95) else ''\n",
        "\n",
        "            cover_image_name = output_crops_folder + '/raw/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.jpg'\n",
        "            cover_circle_name = output_crops_folder + '/circles/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.jpg'\n",
        "            cover_mask_name = output_crops_folder + '/segs/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_initial_region_name = output_crops_folder + '/init_regions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_initial_boundary_name = output_crops_folder + '/init_bounds/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_initial_bad_region_name = output_crops_folder + '/init_bad/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_initial_sector_bounds_name = output_crops_folder + '/init_partitions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_corrected_mask_name = output_crops_folder + '/cor_segs/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_region_name = output_crops_folder + '/cor_regions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_boundary_name = output_crops_folder + '/cor_bounds/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_bad_region_name = output_crops_folder + '/cor_bad/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_sector_bounds_name = output_crops_folder + '/cor_partitions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_sector_name = output_crops_folder + '/sectors/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_sector_comp_name = output_crops_folder + '/sector_comps/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            if use_expert_counts == True:\n",
        "                cover_counts_name = output_crops_folder + '/counted/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            # cover_region_name = output_crops_folder + '/Colony Regions/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_bad_region_name = output_crops_folder + '/Colony Bad Regions/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_sector_name = output_crops_folder + '/Colony Sectors/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_sector_comp_name = output_crops_folder + '/Colony Sector Comps/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_sector_bounds_name = output_crops_folder + '/Colony Sector Bounds/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_image = PIL.Image.open(cover_image_name, mode='r')\n",
        "            cover_circle = PIL.Image.open(cover_circle_name, mode='r')\n",
        "            cover_mask = PIL.Image.open(cover_mask_name, mode='r')\n",
        "\n",
        "            cover_initial_region = PIL.Image.open(cover_initial_region_name, mode='r')\n",
        "            cover_initial_boundary = PIL.Image.open(cover_initial_boundary_name, mode='r')\n",
        "            cover_initial_bad_region = PIL.Image.open(cover_initial_bad_region_name, mode='r')\n",
        "            cover_initial_sector_bounds = PIL.Image.open(cover_initial_sector_bounds_name, mode='r')\n",
        "\n",
        "            cover_corrected_region = PIL.Image.open(cover_corrected_region_name, mode='r')\n",
        "            cover_corrected_boundary = PIL.Image.open(cover_corrected_boundary_name, mode='r')\n",
        "            cover_corrected_bad_region = PIL.Image.open(cover_corrected_bad_region_name, mode='r')\n",
        "            cover_corrected_sector_bounds = PIL.Image.open(cover_corrected_sector_bounds_name, mode='r')\n",
        "\n",
        "            cover_sector = PIL.Image.open(cover_sector_name, mode='r')\n",
        "            cover_sector_comp = PIL.Image.open(cover_sector_comp_name, mode='r')\n",
        "\n",
        "            if use_expert_counts == True:\n",
        "                cover_counts = PIL.Image.open(cover_counts_name, mode='r')\n",
        "\n",
        "            # cover_region = PIL.Image.open(cover_region_name, mode='r')\n",
        "            # cover_bad_region = PIL.Image.open(cover_bad_region_name, mode='r')\n",
        "            # cover_sector = PIL.Image.open(cover_sector_name, mode='r')\n",
        "            # cover_sector_comp = PIL.Image.open(cover_sector_comp_name, mode='r')\n",
        "            # cover_sector_bounds = PIL.Image.open(cover_sector_bounds_name, mode='r')\n",
        "            #print('This Image: ')\n",
        "            #print(pathlib.Path(all_cropped_images[index]).stem)\n",
        "            #print(pathlib.Path(all_cropped_masks[index]).stem)\n",
        "            #print(pathlib.Path(all_cropped_sectors[index]).stem)\n",
        "            w_im,h_im = cover_image.size\n",
        "            w_ma,h_ma = cover_mask.size\n",
        "            w_annot,h_annot = cover_initial_sector_bounds.size\n",
        "            scaling_factor_im = target_height / float(h_im)\n",
        "            scaling_factor_ma = target_height / float(h_ma)\n",
        "            scaling_factor_annot = target_height / float(h_annot)\n",
        "            scaled_width_im = scaling_factor_im*w_im\n",
        "            scaled_width_ma = scaling_factor_ma*w_ma\n",
        "            scaled_width_annot = scaling_factor_annot*w_annot\n",
        "            scaled_height_im = scaling_factor_im*h_im\n",
        "            scaled_height_ma = scaling_factor_ma*h_ma\n",
        "            scaled_height_annot = scaling_factor_annot*h_annot\n",
        "            #image = all_cropped_images[this_colony]\n",
        "            #mask = all_cropped_masks[this_colony]\n",
        "\n",
        "            # Check that the image, mask, and number will fit inside the margins on the give row, and if not, move them to the next row\n",
        "            if col_position + (3*scaled_width_im) + (10*scaled_width_ma) + (2*scaled_width_annot) + number_spacing > right_margin:\n",
        "                row_number = row_number + 1\n",
        "                col_position = 10\n",
        "                current_col_position = copy.deepcopy(col_position)\n",
        "                if (target_height*(row_number+1)) > bottom_margin: # If there is not enough room for rows, move the remaining images to a new page.\n",
        "                    pdf.add_page()\n",
        "                    row_number = 1 # initial row index\n",
        "            else:\n",
        "                current_col_position = copy.deepcopy(col_position)\n",
        "            #print(all_cropped_images[index])\n",
        "            # Add images and masks to the defined position\n",
        "\n",
        "            # Cropping of colony\n",
        "            pdf.image(cover_image_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony\n",
        "            current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "            # Cropping of colony from Wes's annotations\n",
        "            if use_expert_counts == True:\n",
        "                pdf.image(cover_counts_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony\n",
        "                current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "            # Cropping of colony with circle\n",
        "            pdf.image(cover_circle_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony with overlayed circle\n",
        "            current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # Raw semgentation\n",
        "            pdf.image(cover_mask_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert colony segmentation within the circle\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # The boundary of the raw segmentation\n",
        "            pdf.image(cover_initial_boundary_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert colony segmentation within the circle\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # The regional breakdown of the raw segmentation\n",
        "            pdf.image(cover_initial_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # Annotations of where the red regions are found in the regional breakdown\n",
        "            pdf.image(cover_initial_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "            current_col_position = current_col_position + scaled_width_annot\n",
        "\n",
        "            # The inconsistent regions located\n",
        "            pdf.image(cover_initial_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # The segmentation such that boundary pixels inconsistent with their assigned region were changed\n",
        "            pdf.image(cover_corrected_mask_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # The boundary of the corrected segmentation\n",
        "            pdf.image(cover_corrected_boundary_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # The regional breakdown of the corrected segmentation\n",
        "            pdf.image(cover_corrected_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # Annotations on the corrected segmentations indicating where the red regions are (these should be the sectors)\n",
        "            pdf.image(cover_corrected_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "            current_col_position = current_col_position + scaled_width_annot\n",
        "\n",
        "            # Any inconsistent regions detected in the corrected segmentation (in theory, these should always be completely black)\n",
        "            pdf.image(cover_corrected_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # Partitioning of the red regions found in the corrected segmentation (each shaed of gray is a different sector)\n",
        "            pdf.image(cover_sector_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert predicted sector regions\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "            \n",
        "            # A subset of the previous image with only the red pixels preserved.\n",
        "            pdf.image(cover_sector_comp_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert red pixel segmentations within the predicted secto regions.\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # pdf.image(cover_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # pdf.image(cover_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # current_col_position = current_col_position + 10 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # pdf.image(cover_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "            # current_col_position = current_col_position + scaled_width_annot\n",
        "            \n",
        "            # pdf.image(cover_sector_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert predicted sector regions\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "            \n",
        "            # pdf.image(cover_sector_comp_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert red pixel segmentations within the predicted secto regions.\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "            #col_position = col_position + scaled_width_ma\n",
        "            #pdf.text(current_col_position + number_spacing, target_height*row_number + 16, str('# Sec: ' + str(int(row['Pred # Sectors']))))\n",
        "            pdf.text(current_col_position + number_spacing, target_height*row_number + 16, str('Col #: ' + str(row['Colony Number'])))\n",
        "            pdf.text(current_col_position + number_spacing, target_height*row_number + 36, str('Avg Sc: ' + str(round(row['(AC) Weighted Full Average Score'], 2))))\n",
        "            #pdf.text(current_col_position + number_spacing, target_height*row_number + 76, cured_status)\n",
        "\n",
        "            # make space for the next set of images\n",
        "\n",
        "            col_position = current_col_position + number_spacing + col_margin\n",
        "\n",
        "    # Now, do this for sectored colonies with any number of sectors\n",
        "    for this_num_sectors in range(1, max_num_sectors_in_plate + 1):\n",
        "        row_number = row_number + 1\n",
        "        col_position = 10\n",
        "        if (target_height*(row_number+1)) > bottom_margin: # If there is not enough room for rows, move the remaining images to a new page.\n",
        "            pdf.add_page()\n",
        "            row_number = 1 # initial row index\n",
        "        #print(this_plate_data)\n",
        "        this_plate_sector_data = this_plate_data[this_plate_data['Label After'] == 'S'+str(this_num_sectors)]\n",
        "        #print(this_plate_sector_data)\n",
        "        this_plate_sector_data.reset_index()\n",
        "        #print(this_plate_sector_data)\n",
        "        if this_num_sectors == 1:\n",
        "            pdf.text(col_position, target_height*row_number + (target_height/2), 'Colonies with ' + str(num2words(this_num_sectors)) + ' sector: ' +  str(len(this_plate_sector_data)))\n",
        "        else:\n",
        "            pdf.text(col_position, target_height*row_number + (target_height/2), 'Colonies with ' + str(num2words(this_num_sectors)) + ' sectors: ' +  str(len(this_plate_sector_data)))\n",
        "        row_number = row_number + 1\n",
        "\n",
        "        # Sort this subtable by sector scores in descending order\n",
        "        sorted_plate_sector_data = this_plate_sector_data.sort_values(by=['(AC) Weighted Full Average Score', 'Colony Number'], ascending=[False, True])\n",
        "        sorted_plate_sector_data.reset_index()\n",
        "\n",
        "        for index, row in sorted_plate_sector_data.iterrows():\n",
        "\n",
        "            #print('Colony ' + str(int(row['Colony Number'])))\n",
        "            \n",
        "            cured_status = 'Cured' if ((row['Red Area (Seg)'] / row['Colony Area (Seg)']) >= 0.95) else ''\n",
        "\n",
        "            cover_image_name = output_crops_folder + '/raw/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.jpg'\n",
        "            cover_circle_name = output_crops_folder + '/circles/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.jpg'\n",
        "            cover_mask_name = output_crops_folder + '/segs/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_initial_region_name = output_crops_folder + '/init_regions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_initial_boundary_name = output_crops_folder + '/init_bounds/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_initial_bad_region_name = output_crops_folder + '/init_bad/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_initial_sector_bounds_name = output_crops_folder + '/init_partitions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_corrected_mask_name = output_crops_folder + '/cor_segs/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_region_name = output_crops_folder + '/cor_regions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_boundary_name = output_crops_folder + '/cor_bounds/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_bad_region_name = output_crops_folder + '/cor_bad/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_sector_bounds_name = output_crops_folder + '/cor_partitions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_sector_name = output_crops_folder + '/sectors/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_sector_comp_name = output_crops_folder + '/sector_comps/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            if use_expert_counts == True:\n",
        "                cover_counts_name = output_crops_folder + '/counted/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            # cover_region_name = output_crops_folder + '/Colony Regions/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_bad_region_name = output_crops_folder + '/Colony Bad Regions/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_sector_name = output_crops_folder + '/Colony Sectors/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_sector_comp_name = output_crops_folder + '/Colony Sector Comps/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_sector_bounds_name = output_crops_folder + '/Colony Sector Bounds/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_image = PIL.Image.open(cover_image_name, mode='r')\n",
        "            cover_circle = PIL.Image.open(cover_circle_name, mode='r')\n",
        "            cover_mask = PIL.Image.open(cover_mask_name, mode='r')\n",
        "\n",
        "            cover_initial_region = PIL.Image.open(cover_initial_region_name, mode='r')\n",
        "            cover_initial_boundary = PIL.Image.open(cover_initial_boundary_name, mode='r')\n",
        "            cover_initial_bad_region = PIL.Image.open(cover_initial_bad_region_name, mode='r')\n",
        "            cover_initial_sector_bounds = PIL.Image.open(cover_initial_sector_bounds_name, mode='r')\n",
        "\n",
        "            cover_corrected_region = PIL.Image.open(cover_corrected_region_name, mode='r')\n",
        "            cover_corrected_boundary = PIL.Image.open(cover_corrected_boundary_name, mode='r')\n",
        "            cover_corrected_bad_region = PIL.Image.open(cover_corrected_bad_region_name, mode='r')\n",
        "            cover_corrected_sector_bounds = PIL.Image.open(cover_corrected_sector_bounds_name, mode='r')\n",
        "\n",
        "            cover_sector = PIL.Image.open(cover_sector_name, mode='r')\n",
        "            cover_sector_comp = PIL.Image.open(cover_sector_comp_name, mode='r')\n",
        "\n",
        "            if use_expert_counts == True:\n",
        "                cover_counts = PIL.Image.open(cover_counts_name, mode='r')\n",
        "\n",
        "            # cover_region = PIL.Image.open(cover_region_name, mode='r')\n",
        "            # cover_bad_region = PIL.Image.open(cover_bad_region_name, mode='r')\n",
        "            # cover_sector = PIL.Image.open(cover_sector_name, mode='r')\n",
        "            # cover_sector_comp = PIL.Image.open(cover_sector_comp_name, mode='r')\n",
        "            # cover_sector_bounds = PIL.Image.open(cover_sector_bounds_name, mode='r')\n",
        "            #print('This Image: ')\n",
        "            #print(pathlib.Path(all_cropped_images[index]).stem)\n",
        "            #print(pathlib.Path(all_cropped_masks[index]).stem)\n",
        "            #print(pathlib.Path(all_cropped_sectors[index]).stem)\n",
        "            w_im,h_im = cover_image.size\n",
        "            w_ma,h_ma = cover_mask.size\n",
        "            w_annot,h_annot = cover_initial_sector_bounds.size\n",
        "            scaling_factor_im = target_height / float(h_im)\n",
        "            scaling_factor_ma = target_height / float(h_ma)\n",
        "            scaling_factor_annot = target_height / float(h_annot)\n",
        "            scaled_width_im = scaling_factor_im*w_im\n",
        "            scaled_width_ma = scaling_factor_ma*w_ma\n",
        "            scaled_width_annot = scaling_factor_annot*w_annot\n",
        "            scaled_height_im = scaling_factor_im*h_im\n",
        "            scaled_height_ma = scaling_factor_ma*h_ma\n",
        "            scaled_height_annot = scaling_factor_annot*h_annot\n",
        "            #image = all_cropped_images[this_colony]\n",
        "            #mask = all_cropped_masks[this_colony]\n",
        "\n",
        "            # Check that the image, mask, and number will fit inside the margins on the give row, and if not, move them to the next row\n",
        "            if col_position + (3*scaled_width_im) + (10*scaled_width_ma) + (2*scaled_width_annot) + number_spacing > right_margin:\n",
        "                row_number = row_number + 1\n",
        "                col_position = 10\n",
        "                current_col_position = copy.deepcopy(col_position)\n",
        "                if (target_height*(row_number+1)) > bottom_margin: # If there is not enough room for rows, move the remaining images to a new page.\n",
        "                    pdf.add_page()\n",
        "                    row_number = 1 # initial row index\n",
        "            else:\n",
        "                current_col_position = copy.deepcopy(col_position)\n",
        "            #print(all_cropped_images[index])\n",
        "            # Add images and masks to the defined position\n",
        "\n",
        "            # Cropping of colony\n",
        "            pdf.image(cover_image_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony\n",
        "            current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "            # Cropping of colony from Wes's annotations\n",
        "            if use_expert_counts == True:\n",
        "                pdf.image(cover_counts_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony\n",
        "                current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "            # Cropping of colony with circle\n",
        "            pdf.image(cover_circle_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony with overlayed circle\n",
        "            current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # Raw semgentation\n",
        "            pdf.image(cover_mask_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert colony segmentation within the circle\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # The boundary of the raw segmentation\n",
        "            pdf.image(cover_initial_boundary_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert colony segmentation within the circle\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # The regional breakdown of the raw segmentation\n",
        "            pdf.image(cover_initial_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # Annotations of where the red regions are found in the regional breakdown\n",
        "            pdf.image(cover_initial_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "            current_col_position = current_col_position + scaled_width_annot\n",
        "\n",
        "            # The inconsistent regions located\n",
        "            pdf.image(cover_initial_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # The segmentation such that boundary pixels inconsistent with their assigned region were changed\n",
        "            pdf.image(cover_corrected_mask_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # The boundary of the corrected segmentation\n",
        "            pdf.image(cover_corrected_boundary_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # The regional breakdown of the corrected segmentation\n",
        "            pdf.image(cover_corrected_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # Annotations on the corrected segmentations indicating where the red regions are (these should be the sectors)\n",
        "            pdf.image(cover_corrected_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "            current_col_position = current_col_position + scaled_width_annot\n",
        "\n",
        "            # Any inconsistent regions detected in the corrected segmentation (in theory, these should always be completely black)\n",
        "            pdf.image(cover_corrected_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # Partitioning of the red regions found in the corrected segmentation (each shaed of gray is a different sector)\n",
        "            pdf.image(cover_sector_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert predicted sector regions\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "            \n",
        "            # A subset of the previous image with only the red pixels preserved.\n",
        "            pdf.image(cover_sector_comp_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert red pixel segmentations within the predicted secto regions.\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # pdf.image(cover_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # pdf.image(cover_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # current_col_position = current_col_position + 10 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # pdf.image(cover_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "            # current_col_position = current_col_position + scaled_width_annot\n",
        "            \n",
        "            # pdf.image(cover_sector_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert predicted sector regions\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "            \n",
        "            # pdf.image(cover_sector_comp_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert red pixel segmentations within the predicted secto regions.\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "            #col_position = col_position + scaled_width_ma\n",
        "            #pdf.text(current_col_position + number_spacing, target_height*row_number + 16, str('# Sec: ' + str(int(row['Pred # Sectors']))))\n",
        "            pdf.text(current_col_position + number_spacing, target_height*row_number + 16, str('Col #: ' + str(row['Colony Number'])))\n",
        "            pdf.text(current_col_position + number_spacing, target_height*row_number + 36, str('Avg Sc: ' + str(round(row['(AC) Weighted Full Average Score'], 2))))\n",
        "            #pdf.text(current_col_position + number_spacing, target_height*row_number + 76, cured_status)\n",
        "\n",
        "            # make space for the next set of images\n",
        "\n",
        "            col_position = current_col_position + number_spacing + col_margin\n",
        "\n",
        "\n",
        "\n",
        "    # for this_num_sectors in range(0,max_num_sectors_in_plate + 1):\n",
        "    #     row_number = row_number + 1\n",
        "    #     col_position = 10\n",
        "    #     if (target_height*(row_number+1)) > bottom_margin: # If there is not enough room for rows, move the remaining images to a new page.\n",
        "    #         pdf.add_page()\n",
        "    #         row_number = 1 # initial row index\n",
        "    #     #print(this_plate_data)\n",
        "    #     this_plate_sector_data = this_plate_data[this_plate_data['Pred # Sectors'] == this_num_sectors]\n",
        "    #     #print(this_plate_sector_data)\n",
        "    #     this_plate_sector_data.reset_index()\n",
        "    #     #print(this_plate_sector_data)\n",
        "    #     if this_num_sectors == 1:\n",
        "    #         pdf.text(col_position, target_height*row_number + (target_height/2), 'Colonies with ' + str(num2words(this_num_sectors)) + ' sector: ' +  str(len(this_plate_sector_data)))\n",
        "    #     else:\n",
        "    #         pdf.text(col_position, target_height*row_number + (target_height/2), 'Colonies with ' + str(num2words(this_num_sectors)) + ' sectors: ' +  str(len(this_plate_sector_data)))\n",
        "    #     row_number = row_number + 1\n",
        "\n",
        "    #     # Sort this subtable by sector scores in descending order\n",
        "    #     sorted_plate_sector_data = this_plate_sector_data.sort_values(by=['Avg Sector Score', 'Colony Number'], ascending=[False, True])\n",
        "    #     sorted_plate_sector_data.reset_index()\n",
        "\n",
        "    #     for index, row in sorted_plate_sector_data.iterrows():\n",
        "\n",
        "    #         #print('Colony ' + str(int(row['Colony Number'])))\n",
        "            \n",
        "    #         cured_status = 'Cured' if ((row['Red Area (Seg)'] / row['Colony Area (Seg)']) >= 0.95) else ''\n",
        "\n",
        "    #         cover_image_name = output_crops_folder + '/raw/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.jpg'\n",
        "    #         cover_circle_name = output_crops_folder + '/circles/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.jpg'\n",
        "    #         cover_mask_name = output_crops_folder + '/segs/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "    #         cover_initial_region_name = output_crops_folder + '/init_regions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "    #         cover_initial_boundary_name = output_crops_folder + '/init_bounds/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "    #         cover_initial_bad_region_name = output_crops_folder + '/init_bad/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "    #         cover_initial_sector_bounds_name = output_crops_folder + '/init_partitions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "    #         cover_corrected_mask_name = output_crops_folder + '/cor_segs/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "    #         cover_corrected_region_name = output_crops_folder + '/cor_regions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "    #         cover_corrected_boundary_name = output_crops_folder + '/cor_bounds/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "    #         cover_corrected_bad_region_name = output_crops_folder + '/cor_bad/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "    #         cover_corrected_sector_bounds_name = output_crops_folder + '/cor_partitions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "    #         cover_sector_name = output_crops_folder + '/sectors/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "    #         cover_sector_comp_name = output_crops_folder + '/sector_comps/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "    #         if use_expert_counts == True:\n",
        "    #             cover_counts_name = output_crops_folder + '/counted/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "    #         # cover_region_name = output_crops_folder + '/Colony Regions/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "    #         # cover_bad_region_name = output_crops_folder + '/Colony Bad Regions/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "    #         # cover_sector_name = output_crops_folder + '/Colony Sectors/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "    #         # cover_sector_comp_name = output_crops_folder + '/Colony Sector Comps/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "    #         # cover_sector_bounds_name = output_crops_folder + '/Colony Sector Bounds/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "    #         cover_image = PIL.Image.open(cover_image_name, mode='r')\n",
        "    #         cover_circle = PIL.Image.open(cover_circle_name, mode='r')\n",
        "    #         cover_mask = PIL.Image.open(cover_mask_name, mode='r')\n",
        "\n",
        "    #         cover_initial_region = PIL.Image.open(cover_initial_region_name, mode='r')\n",
        "    #         cover_initial_boundary = PIL.Image.open(cover_initial_boundary_name, mode='r')\n",
        "    #         cover_initial_bad_region = PIL.Image.open(cover_initial_bad_region_name, mode='r')\n",
        "    #         cover_initial_sector_bounds = PIL.Image.open(cover_initial_sector_bounds_name, mode='r')\n",
        "\n",
        "    #         cover_corrected_region = PIL.Image.open(cover_corrected_region_name, mode='r')\n",
        "    #         cover_corrected_boundary = PIL.Image.open(cover_corrected_boundary_name, mode='r')\n",
        "    #         cover_corrected_bad_region = PIL.Image.open(cover_corrected_bad_region_name, mode='r')\n",
        "    #         cover_corrected_sector_bounds = PIL.Image.open(cover_corrected_sector_bounds_name, mode='r')\n",
        "\n",
        "    #         cover_sector = PIL.Image.open(cover_sector_name, mode='r')\n",
        "    #         cover_sector_comp = PIL.Image.open(cover_sector_comp_name, mode='r')\n",
        "\n",
        "    #         if use_expert_counts == True:\n",
        "    #             cover_counts = PIL.Image.open(cover_counts_name, mode='r')\n",
        "\n",
        "    #         # cover_region = PIL.Image.open(cover_region_name, mode='r')\n",
        "    #         # cover_bad_region = PIL.Image.open(cover_bad_region_name, mode='r')\n",
        "    #         # cover_sector = PIL.Image.open(cover_sector_name, mode='r')\n",
        "    #         # cover_sector_comp = PIL.Image.open(cover_sector_comp_name, mode='r')\n",
        "    #         # cover_sector_bounds = PIL.Image.open(cover_sector_bounds_name, mode='r')\n",
        "    #         #print('This Image: ')\n",
        "    #         #print(pathlib.Path(all_cropped_images[index]).stem)\n",
        "    #         #print(pathlib.Path(all_cropped_masks[index]).stem)\n",
        "    #         #print(pathlib.Path(all_cropped_sectors[index]).stem)\n",
        "    #         w_im,h_im = cover_image.size\n",
        "    #         w_ma,h_ma = cover_mask.size\n",
        "    #         w_annot,h_annot = cover_initial_sector_bounds.size\n",
        "    #         scaling_factor_im = target_height / float(h_im)\n",
        "    #         scaling_factor_ma = target_height / float(h_ma)\n",
        "    #         scaling_factor_annot = target_height / float(h_annot)\n",
        "    #         scaled_width_im = scaling_factor_im*w_im\n",
        "    #         scaled_width_ma = scaling_factor_ma*w_ma\n",
        "    #         scaled_width_annot = scaling_factor_annot*w_annot\n",
        "    #         scaled_height_im = scaling_factor_im*h_im\n",
        "    #         scaled_height_ma = scaling_factor_ma*h_ma\n",
        "    #         scaled_height_annot = scaling_factor_annot*h_annot\n",
        "    #         #image = all_cropped_images[this_colony]\n",
        "    #         #mask = all_cropped_masks[this_colony]\n",
        "\n",
        "    #         # Check that the image, mask, and number will fit inside the margins on the give row, and if not, move them to the next row\n",
        "    #         if col_position + (3*scaled_width_im) + (10*scaled_width_ma) + (2*scaled_width_annot) + number_spacing > right_margin:\n",
        "    #             row_number = row_number + 1\n",
        "    #             col_position = 10\n",
        "    #             current_col_position = copy.deepcopy(col_position)\n",
        "    #             if (target_height*(row_number+1)) > bottom_margin: # If there is not enough room for rows, move the remaining images to a new page.\n",
        "    #                 pdf.add_page()\n",
        "    #                 row_number = 1 # initial row index\n",
        "    #         else:\n",
        "    #             current_col_position = copy.deepcopy(col_position)\n",
        "    #         #print(all_cropped_images[index])\n",
        "    #         # Add images and masks to the defined position\n",
        "\n",
        "    #         # Cropping of colony\n",
        "    #         pdf.image(cover_image_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony\n",
        "    #         current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "    #         # Cropping of colony from Wes's annotations\n",
        "    #         if use_expert_counts == True:\n",
        "    #             pdf.image(cover_counts_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony\n",
        "    #             current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "    #         # Cropping of colony with circle\n",
        "    #         pdf.image(cover_circle_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony with overlayed circle\n",
        "    #         current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "    #         current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "    #         # Raw semgentation\n",
        "    #         pdf.image(cover_mask_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert colony segmentation within the circle\n",
        "    #         current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "    #         # The boundary of the raw segmentation\n",
        "    #         pdf.image(cover_initial_boundary_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert colony segmentation within the circle\n",
        "    #         current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "    #         current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "    #         # The regional breakdown of the raw segmentation\n",
        "    #         pdf.image(cover_initial_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "    #         current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "    #         # Annotations of where the red regions are found in the regional breakdown\n",
        "    #         pdf.image(cover_initial_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "    #         current_col_position = current_col_position + scaled_width_annot\n",
        "\n",
        "    #         # The inconsistent regions located\n",
        "    #         pdf.image(cover_initial_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "    #         current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "    #         current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "    #         # The segmentation such that boundary pixels inconsistent with their assigned region were changed\n",
        "    #         pdf.image(cover_corrected_mask_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "    #         current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "    #         # The boundary of the corrected segmentation\n",
        "    #         pdf.image(cover_corrected_boundary_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "    #         current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "    #         current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "    #         # The regional breakdown of the corrected segmentation\n",
        "    #         pdf.image(cover_corrected_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "    #         current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "    #         # Annotations on the corrected segmentations indicating where the red regions are (these should be the sectors)\n",
        "    #         pdf.image(cover_corrected_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "    #         current_col_position = current_col_position + scaled_width_annot\n",
        "\n",
        "    #         # Any inconsistent regions detected in the corrected segmentation (in theory, these should always be completely black)\n",
        "    #         pdf.image(cover_corrected_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "    #         current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "    #         current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "    #         # Partitioning of the red regions found in the corrected segmentation (each shaed of gray is a different sector)\n",
        "    #         pdf.image(cover_sector_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert predicted sector regions\n",
        "    #         current_col_position = current_col_position + scaled_width_ma\n",
        "            \n",
        "    #         # A subset of the previous image with only the red pixels preserved.\n",
        "    #         pdf.image(cover_sector_comp_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert red pixel segmentations within the predicted secto regions.\n",
        "    #         current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "    #         # pdf.image(cover_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "    #         # current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "    #         # pdf.image(cover_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "    #         # current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "    #         # current_col_position = current_col_position + 10 # A margin to separate subsets of visualizations\n",
        "\n",
        "    #         # pdf.image(cover_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "    #         # current_col_position = current_col_position + scaled_width_annot\n",
        "            \n",
        "    #         # pdf.image(cover_sector_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert predicted sector regions\n",
        "    #         # current_col_position = current_col_position + scaled_width_ma\n",
        "            \n",
        "    #         # pdf.image(cover_sector_comp_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert red pixel segmentations within the predicted secto regions.\n",
        "    #         # current_col_position = current_col_position + scaled_width_ma\n",
        "    #         #col_position = col_position + scaled_width_ma\n",
        "    #         #pdf.text(current_col_position + number_spacing, target_height*row_number + 16, str('# Sec: ' + str(int(row['Pred # Sectors']))))\n",
        "    #         pdf.text(current_col_position + number_spacing, target_height*row_number + 16, str('Col #: ' + str(row['Colony Number'])))\n",
        "    #         pdf.text(current_col_position + number_spacing, target_height*row_number + 36, str('Avg Sc: ' + str(round(row['Avg Sector Score'], 2))))\n",
        "    #         #pdf.text(current_col_position + number_spacing, target_height*row_number + 76, cured_status)\n",
        "\n",
        "    #         # make space for the next set of images\n",
        "\n",
        "    #         col_position = current_col_position + number_spacing + col_margin\n",
        "\n",
        "    # Write pdf file with output of colony data generated for this plate.\n",
        "    pdf.output(output_details_folder + '/' + this_plate_stem + '.pdf', \"F\")\n",
        "    print('Colonies from ' + this_plate_stem + ' printed.')\n",
        "\n"
      ],
      "metadata": {
        "id": "1Qkh6tTkEnB-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Merge all pdf files printed.  This will concatenate data from all plates.\n",
        "all_files = sorted(glob.glob(output_details_folder + '/' + '*.pdf'))\n",
        "merger = PdfMerger()\n",
        "for this_file in all_files:\n",
        "    merger.append(PdfReader(open(this_file, 'rb')))\n",
        "\n",
        "merger.write(main_folder + '/' + colony_chart_doc + '.pdf')"
      ],
      "metadata": {
        "id": "Ded_cipyEogq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5HZo325XlB6"
      },
      "source": [
        "# Write files containing only samples from each plate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pGgs4_VQXkTU"
      },
      "outputs": [],
      "source": [
        "# Create folder for sampling\n",
        "output_samples_folder = test_output_folder + '/PDF Samples'\n",
        "if os.path.exists(output_samples_folder) == False:\n",
        "    os.makedirs(output_samples_folder)\n",
        "\n",
        "num_samples_per_plate = 40\n",
        "\n",
        "# Set random number seed to sample from the colonies detected\n",
        "np.random.seed(seed=2)\n",
        "# seed 1: done on 80 samples per plate (1/12/2023)\n",
        "# seed 2: done on 40 samples per plate (1/17/2023)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zdqITCaMYFiM"
      },
      "outputs": [],
      "source": [
        "# Code to print a pdf of the croppings\n",
        "# 1. Sort data in table based on plate name, colony number and other elements.\n",
        "# 2. Iterate through each row of the sorted table to get colony imformation\n",
        "# 3. Add inforation to pdf document.\n",
        "# 4. Repear for each colony and plate.\n",
        "# 5. Output pdf.\n",
        "\n",
        "# Do the same as above, but group based on the number of sectors detected\n",
        "\n",
        "\n",
        "\n",
        "for this_plate in all_plate_names:\n",
        "\n",
        "    # this_plate is the key to the correspnding subfolder in each annotation class\n",
        "    # Initialize PDF writer\n",
        "    pdf = FPDF()\n",
        "    pdf = FPDF(unit = \"pt\", format = [850,1100])\n",
        "    pdf.set_font('Arial', 'B', 16)\n",
        "    target_height = float(40)\n",
        "    left_margin = 10\n",
        "    right_margin = 840\n",
        "    bottom_margin = 1050\n",
        "    number_spacing = 7\n",
        "    uniform_spacing = 640\n",
        "\n",
        "\n",
        "    row_number = 1 # initial row index\n",
        "    col_position = 10 # initial column position\n",
        "    col_margin = 40\n",
        "    this_plate_stem = os.path.splitext(this_plate)[0]\n",
        "    this_plate_data = colony_data[colony_data['Plate Name'] == this_plate]\n",
        "\n",
        "    print('Now looking at: ' + str(this_plate))\n",
        "\n",
        "    # Sample rows from the table\n",
        "    num_rows_in_data = len(this_plate_data)\n",
        "    colony_ids = sorted(np.random.choice(num_rows_in_data, num_samples_per_plate, replace=False))\n",
        "    print('Sampled ' + str(len(colony_ids)) + ' colonies.')\n",
        "    print(colony_ids)\n",
        "    this_sampled_plate_data = this_plate_data.iloc[colony_ids]\n",
        "\n",
        "    #this_plate_data.set_index('Colony Number', inplace=True)\n",
        "    max_num_sectors_in_plate = int(max(this_sampled_plate_data['Pred # Sectors']))\n",
        "    pdf.add_page()\n",
        "\n",
        "    #pdf.text(col_position, target_height*row_number, 'Colonies detected in Plate ' + str(this_plate) + '.  ' + str(len(this_plate_data)) + ' colonies were detected.')\n",
        "    pdf.text(col_position, target_height*row_number, str(len(this_sampled_plate_data)) + 'detected colonies sampled from Plate ' + str(this_plate) + '.')\n",
        "    pdf.text(col_position, target_height*row_number + 20, 'Group 1: Raw image data')\n",
        "    pdf.text(col_position, target_height*row_number + 40, 'Group 2: Raw segmentation of whole colony and boundary')\n",
        "    pdf.text(col_position, target_height*row_number + 60, 'Group 3: Regional breakdown and analysis before boundary corrections were made')\n",
        "    pdf.text(col_position, target_height*row_number + 80, 'Group 4: Segmentation with corrected boundary')\n",
        "    pdf.text(col_position, target_height*row_number + 100, 'Group 5: Regional breakdown and analysis after boundary corrections were made')\n",
        "    pdf.text(col_position, target_height*row_number + 120, 'Group 6: Breakdown of red sectored regions and pixels after correction')\n",
        "\n",
        "    row_number = row_number + 2\n",
        "\n",
        "    for this_num_sectors in range(0,max_num_sectors_in_plate + 1):\n",
        "        row_number = row_number + 1\n",
        "        col_position = 10\n",
        "        if (target_height*(row_number+1)) > bottom_margin: # If there is not enough room for rows, move the remaining images to a new page.\n",
        "            pdf.add_page()\n",
        "            row_number = 1 # initial row index\n",
        "        #print(this_plate_data)\n",
        "        this_plate_sector_data = this_sampled_plate_data[this_sampled_plate_data['Pred # Sectors'] == this_num_sectors]\n",
        "        #print(this_plate_sector_data)\n",
        "        this_plate_sector_data.reset_index()\n",
        "        #print(this_plate_sector_data)\n",
        "        if this_num_sectors == 1:\n",
        "            pdf.text(col_position, target_height*row_number + (target_height/2), 'Colonies with ' + str(num2words(this_num_sectors)) + ' sector: ' +  str(len(this_plate_sector_data)))\n",
        "        else:\n",
        "            pdf.text(col_position, target_height*row_number + (target_height/2), 'Colonies with ' + str(num2words(this_num_sectors)) + ' sectors: ' +  str(len(this_plate_sector_data)))\n",
        "        row_number = row_number + 1\n",
        "\n",
        "        # Sort this subtable by sector scores in descending order\n",
        "        sorted_plate_sector_data = this_plate_sector_data.sort_values(by=['Avg Sector Score', 'Colony Number'], ascending=[False, True])\n",
        "        sorted_plate_sector_data.reset_index()\n",
        "\n",
        "        for index, row in sorted_plate_sector_data.iterrows():\n",
        "\n",
        "            #print('Colony ' + str(int(row['Colony Number'])))\n",
        "            \n",
        "            cured_status = 'Cured' if ((row['Red Area (Seg)'] / row['Colony Area (Seg)']) >= 0.95) else ''\n",
        "\n",
        "            cover_image_name = output_crops_folder + '/raw/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.jpg'\n",
        "            cover_circle_name = output_crops_folder + '/circles/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.jpg'\n",
        "            cover_mask_name = output_crops_folder + '/segs/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_initial_region_name = output_crops_folder + '/init_regions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_initial_boundary_name = output_crops_folder + '/init_bounds/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_initial_bad_region_name = output_crops_folder + '/init_bad/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_initial_sector_bounds_name = output_crops_folder + '/init_partitions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_corrected_mask_name = output_crops_folder + '/cor_segs/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_region_name = output_crops_folder + '/cor_regions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_boundary_name = output_crops_folder + '/cor_bounds/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_bad_region_name = output_crops_folder + '/cor_bad/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_corrected_sector_bounds_name = output_crops_folder + '/cor_partitions/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_sector_name = output_crops_folder + '/sectors/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "            cover_sector_comp_name = output_crops_folder + '/sector_comps/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            if use_expert_counts == True:\n",
        "                cover_counts_name = output_crops_folder + '/counted/' + file_dict[this_plate] + '/' + this_plate_stem + '_c_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            # cover_region_name = output_crops_folder + '/Colony Regions/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_bad_region_name = output_crops_folder + '/Colony Bad Regions/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_sector_name = output_crops_folder + '/Colony Sectors/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_sector_comp_name = output_crops_folder + '/Colony Sector Comps/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "            # cover_sector_bounds_name = output_crops_folder + '/Colony Sector Bounds/' + this_plate_stem + '_Colony_' + str(int(row['Colony Number'])) + '.png'\n",
        "\n",
        "            cover_image = PIL.Image.open(cover_image_name, mode='r')\n",
        "            cover_circle = PIL.Image.open(cover_circle_name, mode='r')\n",
        "            cover_mask = PIL.Image.open(cover_mask_name, mode='r')\n",
        "\n",
        "            cover_initial_region = PIL.Image.open(cover_initial_region_name, mode='r')\n",
        "            cover_initial_boundary = PIL.Image.open(cover_initial_boundary_name, mode='r')\n",
        "            cover_initial_bad_region = PIL.Image.open(cover_initial_bad_region_name, mode='r')\n",
        "            cover_initial_sector_bounds = PIL.Image.open(cover_initial_sector_bounds_name, mode='r')\n",
        "\n",
        "            cover_corrected_region = PIL.Image.open(cover_corrected_region_name, mode='r')\n",
        "            cover_corrected_boundary = PIL.Image.open(cover_corrected_boundary_name, mode='r')\n",
        "            cover_corrected_bad_region = PIL.Image.open(cover_corrected_bad_region_name, mode='r')\n",
        "            cover_corrected_sector_bounds = PIL.Image.open(cover_corrected_sector_bounds_name, mode='r')\n",
        "\n",
        "            cover_sector = PIL.Image.open(cover_sector_name, mode='r')\n",
        "            cover_sector_comp = PIL.Image.open(cover_sector_comp_name, mode='r')\n",
        "\n",
        "            if use_expert_counts == True:\n",
        "                cover_counts = PIL.Image.open(cover_counts_name, mode='r')\n",
        "\n",
        "            # cover_region = PIL.Image.open(cover_region_name, mode='r')\n",
        "            # cover_bad_region = PIL.Image.open(cover_bad_region_name, mode='r')\n",
        "            # cover_sector = PIL.Image.open(cover_sector_name, mode='r')\n",
        "            # cover_sector_comp = PIL.Image.open(cover_sector_comp_name, mode='r')\n",
        "            # cover_sector_bounds = PIL.Image.open(cover_sector_bounds_name, mode='r')\n",
        "            #print('This Image: ')\n",
        "            #print(pathlib.Path(all_cropped_images[index]).stem)\n",
        "            #print(pathlib.Path(all_cropped_masks[index]).stem)\n",
        "            #print(pathlib.Path(all_cropped_sectors[index]).stem)\n",
        "            w_im,h_im = cover_image.size\n",
        "            w_ma,h_ma = cover_mask.size\n",
        "            w_annot,h_annot = cover_initial_sector_bounds.size\n",
        "            scaling_factor_im = target_height / float(h_im)\n",
        "            scaling_factor_ma = target_height / float(h_ma)\n",
        "            scaling_factor_annot = target_height / float(h_annot)\n",
        "            scaled_width_im = scaling_factor_im*w_im\n",
        "            scaled_width_ma = scaling_factor_ma*w_ma\n",
        "            scaled_width_annot = scaling_factor_annot*w_annot\n",
        "            scaled_height_im = scaling_factor_im*h_im\n",
        "            scaled_height_ma = scaling_factor_ma*h_ma\n",
        "            scaled_height_annot = scaling_factor_annot*h_annot\n",
        "            #image = all_cropped_images[this_colony]\n",
        "            #mask = all_cropped_masks[this_colony]\n",
        "\n",
        "            # Check that the image, mask, and number will fit inside the margins on the give row, and if not, move them to the next row\n",
        "            if col_position + (3*scaled_width_im) + (10*scaled_width_ma) + (2*scaled_width_annot) + number_spacing > right_margin:\n",
        "                row_number = row_number + 1\n",
        "                col_position = 10\n",
        "                current_col_position = copy.deepcopy(col_position)\n",
        "                if (target_height*(row_number+1)) > bottom_margin: # If there is not enough room for rows, move the remaining images to a new page.\n",
        "                    pdf.add_page()\n",
        "                    row_number = 1 # initial row index\n",
        "            else:\n",
        "                current_col_position = copy.deepcopy(col_position)\n",
        "            #print(all_cropped_images[index])\n",
        "            # Add images and masks to the defined position\n",
        "\n",
        "            # Cropping of colony\n",
        "            pdf.image(cover_image_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony\n",
        "            current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "            # Cropping of colony from Wes's annotations\n",
        "            if use_expert_counts == True:\n",
        "                pdf.image(cover_counts_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony\n",
        "                current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "            # Cropping of colony with circle\n",
        "            pdf.image(cover_circle_name, current_col_position, target_height*row_number, scaled_width_im, scaled_height_im) # Insert cropping of colony with overlayed circle\n",
        "            current_col_position = current_col_position + scaled_width_im\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # Raw semgentation\n",
        "            pdf.image(cover_mask_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert colony segmentation within the circle\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # The boundary of the raw segmentation\n",
        "            pdf.image(cover_initial_boundary_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert colony segmentation within the circle\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # The regional breakdown of the raw segmentation\n",
        "            pdf.image(cover_initial_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # Annotations of where the red regions are found in the regional breakdown\n",
        "            pdf.image(cover_initial_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "            current_col_position = current_col_position + scaled_width_annot\n",
        "\n",
        "            # The inconsistent regions located\n",
        "            pdf.image(cover_initial_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # The segmentation such that boundary pixels inconsistent with their assigned region were changed\n",
        "            pdf.image(cover_corrected_mask_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # The boundary of the corrected segmentation\n",
        "            pdf.image(cover_corrected_boundary_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # The regional breakdown of the corrected segmentation\n",
        "            pdf.image(cover_corrected_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # Annotations on the corrected segmentations indicating where the red regions are (these should be the sectors)\n",
        "            pdf.image(cover_corrected_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "            current_col_position = current_col_position + scaled_width_annot\n",
        "\n",
        "            # Any inconsistent regions detected in the corrected segmentation (in theory, these should always be completely black)\n",
        "            pdf.image(cover_corrected_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            current_col_position = current_col_position + 5 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # Partitioning of the red regions found in the corrected segmentation (each shaed of gray is a different sector)\n",
        "            pdf.image(cover_sector_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert predicted sector regions\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "            \n",
        "            # A subset of the previous image with only the red pixels preserved.\n",
        "            pdf.image(cover_sector_comp_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert red pixel segmentations within the predicted secto regions.\n",
        "            current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # pdf.image(cover_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation showing the different regions of the colony\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # pdf.image(cover_bad_region_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert segmentation that shows the regions that failed the consistency check\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "\n",
        "            # current_col_position = current_col_position + 10 # A margin to separate subsets of visualizations\n",
        "\n",
        "            # pdf.image(cover_sector_bounds_name, current_col_position, target_height*row_number, scaled_width_annot, scaled_height_annot) # Insert segmentaiton with boundaries of sectors annotated\n",
        "            # current_col_position = current_col_position + scaled_width_annot\n",
        "            \n",
        "            # pdf.image(cover_sector_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert predicted sector regions\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "            \n",
        "            # pdf.image(cover_sector_comp_name, current_col_position, target_height*row_number, scaled_width_ma, scaled_height_ma) # Insert red pixel segmentations within the predicted secto regions.\n",
        "            # current_col_position = current_col_position + scaled_width_ma\n",
        "            #col_position = col_position + scaled_width_ma\n",
        "            #pdf.text(current_col_position + number_spacing, target_height*row_number + 16, str('# Sec: ' + str(int(row['Pred # Sectors']))))\n",
        "            pdf.text(current_col_position + number_spacing, target_height*row_number + 16, str('Col #: ' + str(row['Colony Number'])))\n",
        "            pdf.text(current_col_position + number_spacing, target_height*row_number + 36, str('Avg Sc: ' + str(round(row['Avg Sector Score'], 2))))\n",
        "            #pdf.text(current_col_position + number_spacing, target_height*row_number + 76, cured_status)\n",
        "\n",
        "            # make space for the next set of images\n",
        "\n",
        "            col_position = current_col_position + number_spacing + col_margin\n",
        "\n",
        "    # Write pdf file with output of colony data generated for this plate.\n",
        "    pdf.output(output_samples_folder + '/' + this_plate_stem + '.pdf', \"F\")\n",
        "    print('Colonies from ' + this_plate_stem + ' printed.')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wMsG9g4heVmu"
      },
      "outputs": [],
      "source": [
        "# Merge all pdf files printed.  This will concatenate data from all plates.\n",
        "all_files = sorted(glob.glob(output_samples_folder + '/*.pdf'))\n",
        "merger = PdfMerger()\n",
        "for this_file in all_files:\n",
        "    merger.append(PdfReader(open(this_file, 'rb')))\n",
        "\n",
        "merger.write(main_folder + '/' + colony_chart_doc + '.pdf')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "_AnuYIc4-SNH",
        "HoDT8jsK3Jf1",
        "kEt6DCxTSntw",
        "6puKXvrPWxuu",
        "vv8knHnRStQk",
        "5RmkuLhQ-XrF",
        "KBCMydc3-djw",
        "8_bYZFAk-0ib",
        "gVsFlEMA-3V1",
        "U12rQGjZiPaZ",
        "lOxLMcYr-_la",
        "C0ym5zrdgmKK",
        "ROCdty_DS9jl",
        "QlHqp2qG_ObI",
        "lis9Al-N_xbz",
        "Msa8JJN6sp0b",
        "Ai1eixofc6IZ",
        "UjkI5i8MsEGS",
        "mVrxpuFvfDYd",
        "GjGz7R9qsEGV",
        "-WWazVlOh54B",
        "8Wuh9xAOkK3q",
        "75EugnbipD9h",
        "9kjS3mwwp9TV",
        "J7F7EcLcvcSY",
        "9Ysr_hassEH5",
        "xctSQ_9O6QLE",
        "-wIjKbapsEH7",
        "tp8nxwlFsEH8",
        "aks8Z4iaqNSf",
        "vsE4URThqlhJ",
        "mXKL7Y2Pqoeo",
        "c3c33gd9q9b7",
        "Qh74WEI_sEGd",
        "a0EAAIKfsEHn",
        "7tNuwGg2sEHr",
        "932e4Gjmwdgi",
        "15VkgOZfsCKH",
        "T2G-caGfsIHc",
        "3ai8FHWFsEHu",
        "27TndfjkmX_M",
        "IW6BvXpaA7Ox",
        "bhPRlMtpBA2i",
        "E6bBPF7QBDms",
        "ajNSt08EBHig",
        "T8HZKouAEgbr",
        "U5HZo325XlB6"
      ],
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}