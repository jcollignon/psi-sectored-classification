{"cells":[{"cell_type":"markdown","metadata":{"id":"I_oVyoe1SjrG"},"source":["# Install Packages and Modules"]},{"cell_type":"markdown","metadata":{"id":"WdcJkrwWTDWw"},"source":["## Import Google Colab Packages and Mount Drive"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_kla61eGTHFU"},"outputs":[],"source":["from google.colab.patches import cv2_imshow\n","from google.colab import drive\n","drive.mount('/content/gdrive/', force_remount=True)"]},{"cell_type":"markdown","metadata":{"id":"rVjosxWzSovb"},"source":["## Install packages on system"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"l2FdZFBOSbTN"},"outputs":[],"source":["# System installs\n","!apt-get update\n","!apt install msttcorefonts -qq\n","!apt install octave # makes it possible to run matlab scripts\n","!apt install liboctave-dev\n","gpu_info = !nvidia-smi\n","\n","\n","# Pip installs\n","!pip3 install fpdf\n","!pip3 install num2words\n","!pip3 install oct2py #--no-deps\n","!pip3 install PyPDF2"]},{"cell_type":"markdown","metadata":{"id":"VnzEx3uuTgyc"},"source":["## Import python packages and modules"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W-mHbCaCTkhx"},"outputs":[],"source":["# Import all necessary packages for code to run\n","import copy\n","import glob\n","import math\n","import os\n","import pathlib\n","import pickle\n","import random\n","from random import randint\n","import time # measure how long training takes\n","import warnings\n","import cv2\n","from fpdf import FPDF\n","\n","import matplotlib\n","from matplotlib.patches import Circle\n","import matplotlib.pyplot as plt\n","from num2words import num2words\n","import numpy as np\n","import oct2py\n","from oct2py import octave\n","import pandas as pd\n","\n","import PIL\n","from psutil import virtual_memory\n","from PyPDF2 import PdfMerger, PdfReader\n","\n","import seaborn as sns\n","import skimage\n","from skimage import draw\n","from skimage.measure import label, find_contours\n","from skimage.metrics import hausdorff_distance #, hausdorff_pair\n","from skimage.morphology import skeletonize, convex_hull_image\n","import sklearn\n","from sklearn.model_selection import train_test_split\n","from scipy import ndimage\n","from scipy.spatial import procrustes\n","import tensorflow as tf\n","from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation\n","from tensorflow.keras.layers import MaxPool2D, UpSampling2D, Concatenate, GaussianNoise\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n","from tensorflow.python.client import device_lib\n","from tqdm import tqdm\n","\n","%load_ext oct2py.ipython "]},{"cell_type":"markdown","metadata":{"id":"-Aj5pFCzT23C"},"source":["## Check if you are using a GPU or High-RAM runtime"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"oLrZvAdtT6Zg"},"outputs":[],"source":["tf.config.list_physical_devices('GPU')\n","device_lib.list_local_devices()\n","\n","#gpu_info = !nvidia-smi\n","#gpu_info = '\\n'.join(gpu_info)\n","#if gpu_info.find('failed') >= 0:\n","#    print('Not connected to a GPU')\n","#else:\n","#    print(gpu_info)\n","\n","# Check if you are using a high-ram runtime (comes from one of Google's tutorials)\n","\n","ram_gb = virtual_memory().total / 1e9\n","print('Your runtime has {:.1f} gigabytes of available RAM\\n'.format(ram_gb))\n","\n","if ram_gb < 20:\n","    print('Not using a high-RAM runtime')\n","else:\n","    print('You are using a high-RAM runtime!')"]},{"cell_type":"markdown","metadata":{"id":"lS_pVjz3VmY8"},"source":["## Start Octave and add extensions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v06fR20PVozq"},"outputs":[],"source":["%%octave # Start Octave\n","#pwd\n","#dir(\"/content/gdrive/MyDrive\")\n","#addpath(\"/content/gdrive/My Drive/Colab\\ Notebooks/sector-counting-pipeline/Pipeline\")\n","#addpath(\"/content/gdrive/Colab Notebooks/sector-counting-pipeline/Pipeline\")\n","#pkg install qt_toolkit\n","#pkg install fltk\n","\n","# image package version 2.12.0 is required.\n","# The current version of image (2.14.0) produces very different results.\n","\n","# dataframe package version 1.2.0 is required.\n","\n","#pkg install \"/content/gdrive/My Drive/Colab\\ Notebooks/psi-sectored-classification/image-2.12.0.tar.gz\"\n","pkg install \"https://downloads.sourceforge.net/project/octave/Octave%20Forge%20Packages/Individual%20Package%20Releases/image-2.12.0.tar.gz\"\n","#pkg install -forge image\n","pkg load image\n","\n","#pkg install \"/content/gdrive/My Drive/Colab\\ Notebooks/psi-sectored-classification/dataframe-1.2.0.tar.gz\"\n","pkg install \"https://downloads.sourceforge.net/project/octave/Octave%20Forge%20Packages/Individual%20Package%20Releases/dataframe-1.2.0.tar.gz\"\n","#pkg install -forge dataframe\n","pkg load dataframe"]},{"cell_type":"markdown","metadata":{"id":"6eoDt6C4xW53"},"source":["# Define GLOBALS used for notebook flow"]},{"cell_type":"markdown","metadata":{"id":"UES7HxsLPqQU"},"source":["## GLOBAL Variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VZmgj2v2xd39"},"outputs":[],"source":["#-----------------------\n","# EXPECTED IMAGE INPUT\n","#-----------------------\n","\n","# Input and output of U-Net\n","# Image input and output\n","HEIGHT = 1024\n","WIDTH = 1024\n","SHAPE = (HEIGHT, WIDTH, 3) # The size of the input image (assumes 3 channels i.e. RGB)\n","NUM_CLASSES = 3 # How many classes of pixels should the segmentation have?\n","# 2: Colony pixels versus background pixels\n","# 3: Red colony pixels, white colony pixels and background pixels\n","# (this is what we will be using from now on)\n","\n","# Indicates whether red and white labels should be swapped\n","# This is used for color consistency.\n","SWAP_CLASS_LABELS = True\n","\n","#---------------------\n","# TRAINING PARAMETERS\n","#---------------------\n","\n","# Training settings Enable training and/or classification\n","TRAIN_MODEL = False # set to True if you wish to train a new model\n","USE_TEST_NETWORK = False # set to True if you want to use a small model to\n","# test with instead of the implemented model\n","\n","# Model settings\n","LR = 1e-4 # learning rate (initial)\n","MIN_LR = 1e-6 # lowest learning rate if using a scheduler or a reduce on plateau (default is 1e-6)\n","BATCH_SIZE = 1 # how many images are fed in at one pass?\n","EPOCHS = 100 # the maximum number of passes through the images\n","\n","# Output segmentations of plates during training\n","PRINT_TEST_SEGS = False\n","\n","# Output segmentations of plates after training\n","GET_TRAINING_SEGS = True # save segmentations for the training images\n","GET_TESTING_SEGS = True # save segmentations for the testing images\n","\n","\n","#---------------------\n","# CLASSIFICATION PARAMETERS\n","#---------------------\n","\n","# Should classification happen?\n","CLASSIFY_TRAINING_COLONIES = True\n","CLASSIFY_TESTING_COLONIES = True\n","\n","# Save all colony images and annotations of colonies from testing images\n","SAVE_ALL_ANNOTATIONS = True\n","\n","# Padding for images being saved (zooming out a bit, not adding blank pixels)\n","IMAGE_PADDING = 5\n","\n","# Including OTHERS' annotations of the images\n","USE_EXPERT_COUNTS = False # quantifiable colonies from images (dots on the images)\n","USE_QUANTIFIABLE_COUNTS_FROM_TABLE = False # quantifiable colonies tabulated\n","# (assumes you have the tabulated data)\n","USE_TRUE_CURED_COLONIES_FROM_TABLE = False # cured colonies tabulated\n","# (assumes you have the tabulated data)\n","USE_TRUE_SECTOR_COUNTS = False # sector frequencies tabulated\n","#(assumes you have the tabulated data)\n","\n","#---------------------\n","# SET RANDOM NUMBER GENERATOR\n","#---------------------\n","\n","# Set random number generator\n","SEED = 42\n","np.random.seed(SEED) # for numpy operations\n","tf.random.set_seed(SEED) # for tensorflow operations"]},{"cell_type":"markdown","metadata":{"id":"HRJJC1OyPsjk"},"source":["## Repo Directories and Necessary File Names"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"wyJw3dWNPuS6"},"outputs":[],"source":["#---------------------------------------\n","# THINGS TO CHANGE BEFORE RUNNING\n","#---------------------------------------\n","\n","# 1. GET THE REPO DIRECTORY\n","\n","# Change the lines below to correspond to the loction of the repo in your Google Drive\n","\n","# Parent directory of repo folder\n","REPO_PARENT_FOLDER = '/content/gdrive/My Drive/Colab Notebooks'\n","\n","REPO_BODY_FOLDER = REPO_PARENT_FOLDER + \\\n","    '/-PSI--CIC'  # Repo folder itself\n","# include this in Octave's path when reading functions.\n","octave.addpath(REPO_BODY_FOLDER)\n","\n","# This is the subfolder of the repo containing the segmnetation-classification pipeline.\n","# This is also the directory of which this iPython script is found.\n","# The location of the code for running [PSI]-CIC\n","MAIN_FOLDER = REPO_BODY_FOLDER + '/Pipeline'\n","\n","\n","# 2. GET THE FILE NAMES FOR THE WEIGHTS AND THE COLONY OUTPUT DOCUMENT\n","\n","# Name of the file containing the trainied weights\n","# Such file should be stored in the \"Trained Models\" subfolder of \"Pipeline\"\n","# Do not include the '.h5' file type at the end\n","# File names:\n","# 2021_07_01 (too big to add on Github)\n","# test_model_3 (included in Github)\n","WEIGHTS_FILE = '2021_07_01'\n","\n","# NOTE: If you want to use the weights file used in the paper, please contact\n","# me as Github's file size limits prevent me from including it in the repo.\n","\n","# Name of the output file containing all the colony crops from the classification step\n","# This will be the name of the PDF file with colony crops in the \"_Pipeline_test\" folder.\n","COLONY_CHART_DOC = '2023_05_02'\n","\n","\n","# 3. GET DIRECTORIES OF TRAINING AND TESTING IMAGES\n","\n","# Training and validation image locations\n","TRAINING_IMAGE_SET = REPO_BODY_FOLDER + '/Image Generation/Synthetic_Images/train/images'\n","VALIDATION_IMAGE_SET = REPO_BODY_FOLDER + '/Image Generation/Synthetic_Images/val/images'\n","\n","# Directories of the testing images\n","THIS_IMAGE_SET = 'Main Images/Set 2'\n","# Note: The main folder where these images are found is \"Real Images\",\n","# which is the PARENT directory of this script.  This will be the same\n","# structure used when looking at output for the specific image sets.\n","\n","# If you would like to use one image to test how well a segmentation during\n","# training is, write the name of the image you want to test in here.\n","# This must be in the set of testing images.\n","if PRINT_TEST_SEGS is True:\n","    IMAGE_TO_TEST_WITH = 'Plate_2.jpg'\n"]},{"cell_type":"markdown","metadata":{"id":"MwYNwSpL3vr3"},"source":["## Required Directories\n","Refer to this cell if a directory related error is thrown"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iJeeEIi13mpA"},"outputs":[],"source":["# Check that the directories for synthetic images and the weights exist.\n","# AN ERROR IS THROWN IF ONE OF THEM CANNOT BE FOUND.\n","\n","# Directory where all TRAINING images and masks are found\n","IMAGE_FOLDER = REPO_BODY_FOLDER + '/Image Generation/Synthetic_Images'\n","if not os.path.exists(IMAGE_FOLDER):\n","    raise NameError('Directory ' + IMAGE_FOLDER + ' does not exist.')\n","\n","# Directory where model weights are stored or found\n","WEIGHTS_FOLDER = MAIN_FOLDER + '/Trained Models'\n","if not os.path.exists(WEIGHTS_FOLDER):\n","    raise NameError('Directory ' + WEIGHTS_FOLDER + ' does not exist.')\n","\n","# Subdirectory containing all the test plates\n","ALL_REAL_IMAGES_FOLDER = REPO_BODY_FOLDER + '/' + 'Real_Images'\n","if not os.path.exists(ALL_REAL_IMAGES_FOLDER):\n","    raise NameError('Directory ' + ALL_REAL_IMAGES_FOLDER + ' does not exist.')\n","\n","# Subdirectory of the \"Real Images\" folder which contains the\n","# specific image set you are using\n","REAL_IMAGE_FOLDER = ALL_REAL_IMAGES_FOLDER + \\\n","    '/' + THIS_IMAGE_SET  # leave this line alone\n","if not os.path.exists(REAL_IMAGE_FOLDER):\n","    raise NameError('Directory ' + REAL_IMAGE_FOLDER + ' does not exist.')\n","\n","# If you are using images containing the manual annotations, indicate where\n","# this data is found\n","if USE_EXPERT_COUNTS is True:\n","    ADDITIONAL_DATA_FOLDER = MAIN_FOLDER + '/additional_data/' + THIS_IMAGE_SET\n","    if not os.path.exists(ADDITIONAL_DATA_FOLDER):\n","        raise NameError(\n","            'Directory ' + ADDITIONAL_DATA_FOLDER + ' does not exist.')\n","\n","# If you are using an image to intermediately test U-Net during training,\n","# make sure the image you are using can be found\n","if PRINT_TEST_SEGS is True:\n","    if not os.path.exists(REAL_IMAGE_FOLDER + '/' + IMAGE_TO_TEST_WITH):\n","        raise NameError(\n","            'The image you want to test with cannot be found in this folder.')"]},{"cell_type":"markdown","metadata":{"id":"G-KHZeOY39Tb"},"source":["## Create GLOBAL Directories based on GLOBAL variables"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"zeXMsuvp4DDD"},"outputs":[],"source":["# Training output directories\n","\n","# If folders do not exist, they will be created for you.\n","\n","# Primary directory where all output from TRAINING data will be stores\n","TRAIN_OUTPUT_FOLDER = MAIN_FOLDER + '/output_train/' + str(WEIGHTS_FILE)\n","if not os.path.exists(TRAIN_OUTPUT_FOLDER):\n","    os.makedirs(TRAIN_OUTPUT_FOLDER)\n","\n","# Subdirectory where TRAINING image segmentations will be stored\n","TRAIN_SEG_FOLDER = TRAIN_OUTPUT_FOLDER + '/segs'\n","if not os.path.exists(TRAIN_SEG_FOLDER):\n","    os.mkdir(TRAIN_SEG_FOLDER)\n","\n","# Subdirectory where circle detections for the corresponding TRAINING\n","# image segmentation will be found\n","TRAIN_CIRCLE_FOLDER = TRAIN_OUTPUT_FOLDER + '/CHT Circles'\n","if not os.path.exists(TRAIN_CIRCLE_FOLDER):\n","    os.makedirs(TRAIN_CIRCLE_FOLDER)\n","\n","# Subdirectory where data for each circle detection in TRAINING\n","# images will be found (including position and radius)\n","TRAIN_CIRCLE_DATA_FOLDER = TRAIN_OUTPUT_FOLDER + '/CHT Data'\n","if not os.path.exists(TRAIN_CIRCLE_DATA_FOLDER):\n","    os.makedirs(TRAIN_CIRCLE_DATA_FOLDER)\n","\n","# Subdirectory where classification data for each detection in TRAINING\n","# images will be found (including position and radius)\n","# These are .pkl files of tables, one per plate, containing\n","# data on each colony.\n","TRAIN_OUTPUT_TABLE_FOLDER = TRAIN_OUTPUT_FOLDER + '/Colony Tables'\n","if not os.path.exists(TRAIN_OUTPUT_TABLE_FOLDER):\n","    os.makedirs(TRAIN_OUTPUT_TABLE_FOLDER)\n","\n","\n","#---------------------------------------------------\n","# Testing output directories\n","\n","# If folders do not exist, they will be created for you.\n","\n","# If you would like to see output of the plate segmentation during the\n","# training process, this is the subdirectory of the Pipeline folder where\n","# such output will be stored\n","if PRINT_TEST_SEGS is True:\n","    TEST_PER_EPOCH_FOLDER = MAIN_FOLDER + '/segs_per_epoch/' + \\\n","        str(WEIGHTS_FILE) + '/' + THIS_IMAGE_SET\n","    if not os.path.exists(TEST_PER_EPOCH_FOLDER):\n","        os.makedirs(TEST_PER_EPOCH_FOLDER)\n","\n","# Primary directory where all output from TESTING data will be stored\n","# This is model specific, so the weights file name will be an additional\n","# subdirectory for all image sets tested withn thouse weights.\n","TEST_OUTPUT_FOLDER = MAIN_FOLDER + '/output_test/' + \\\n","    str(WEIGHTS_FILE) + '/' + THIS_IMAGE_SET\n","if not os.path.exists(TEST_OUTPUT_FOLDER):\n","    os.makedirs(TEST_OUTPUT_FOLDER)\n","\n","# Subdirectory where TESTING image segmentations will be stored\n","TEST_SEG_FOLDER = TEST_OUTPUT_FOLDER + '/segs'\n","if not os.path.exists(TEST_SEG_FOLDER):\n","    os.makedirs(TEST_SEG_FOLDER)\n","\n","# Subdirectory where circle detections for the corresponding TESTING\n","# image segmentations will be found\n","TEST_CIRCLE_FOLDER = TEST_OUTPUT_FOLDER + '/CHT Circles'\n","if not os.path.exists(TEST_CIRCLE_FOLDER):\n","    os.makedirs(TEST_CIRCLE_FOLDER)\n","\n","# Subdirectory where data for each circle detection in TESTING\n","# images will be found (including position and radius)\n","TEST_CIRCLE_DATA_FOLDER = TEST_OUTPUT_FOLDER + '/CHT Data'\n","if not os.path.exists(TEST_CIRCLE_DATA_FOLDER):\n","    os.makedirs(TEST_CIRCLE_DATA_FOLDER)\n","\n","# Subdirectory where classification data for each detection in TESTING\n","# images will be found (including position and radius)\n","# These are .pkl files of tables, one per plate, containing\n","# data on each colony.\n","TEST_OUTPUT_TABLE_FOLDER = TEST_OUTPUT_FOLDER + '/Colony Tables'\n","if not os.path.exists(TEST_OUTPUT_TABLE_FOLDER):\n","    os.makedirs(TEST_OUTPUT_TABLE_FOLDER)\n","\n","# Subdirectory showing the bounding boxes for each colony detected\n","# in the TESTING images will be found\n","TEST_BOXES_FOLDER = TEST_OUTPUT_FOLDER + '/detections'\n","if not os.path.exists(TEST_BOXES_FOLDER):\n","    os.makedirs(TEST_BOXES_FOLDER)\n","\n","\n","#------------------------------------------------------\n","# FULL OUTPUT: ANNOTATION DETAILS AND PLOTS\n","\n","# Everything still stored in the subdiectory of output_test corresponding to\n","# the segmentaion weights and image set used.\n","\n","# Subdirectory which stores PDF documents per plate showing the\n","# cropped colony, its segmentation, and annotations.\n","OUTPUT_DETAILS_FOLDER = TEST_OUTPUT_FOLDER + '/PDF Details'\n","if not os.path.exists(OUTPUT_DETAILS_FOLDER):\n","    os.makedirs(OUTPUT_DETAILS_FOLDER)\n","\n","# Subdirectory which stores plots visualizing data obgtained from each plate\n","OUTPUT_PLOTS_FOLDER = TEST_OUTPUT_FOLDER + '/Plots'\n","if not os.path.exists(OUTPUT_PLOTS_FOLDER):\n","    os.makedirs(OUTPUT_PLOTS_FOLDER)\n","\n","#-------------------------------------------------------\n","# FULL OUTPUT: CROPPING DIRECTORIES\n","\n","# This section is only active when save_all_annotations is True\n","\n","if SAVE_ALL_ANNOTATIONS is True:\n","\n","    OUTPUT_CROPS_FOLDER = TEST_OUTPUT_FOLDER + '/crops'\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/raw'):\n","        # where the original colonies are cropped and stored\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/raw')\n","\n","    # Below used only if data on quantifiable colonies are available\n","\n","    if USE_EXPERT_COUNTS is True:\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/counted'):\n","            # where the original quantifiable colonies are cropped and stored\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/counted')\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/circles'):\n","        # same as before, but a circle is overlayed on the colony\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/circles')\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/segs'):\n","        # the output from the U-Net segmentation such that only nonzero\n","        # pixels in the circle are kept\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/segs')\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/init_regions'):\n","        # A segmentation outlining the possible sector-like regions\n","        # of the colony, both red and white\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/init_regions')\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/init_bounds'):\n","        # The raw segmentation containing only the boundary of the colony\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/init_bounds')\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/init_partitions'):\n","        # same as the raw segmentation, but with lines annotated\n","        # to represent locations of sector borders\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/init_partitions')\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/init_bad'):\n","        # A segmentation outlining the sector-like regions that\n","        # failed the consistency check\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/init_bad')\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_segs'):\n","        # the output from the U-Net segmentation such that only\n","        # nonzero pixels in the circle are kept\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_segs')\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_bounds'):\n","        # The corrected segmentation containing only the\n","        # boundary of the colony\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_bounds')\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_regions'):\n","        # the output from the U-Net segmentation such that only\n","        # nonzero pixels in the circle are kept\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_regions')\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_bounds'):\n","        # same as the raw segmentation, but with lines annotated\n","        # to represent locations of sector borders\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_bounds')\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_bad'):\n","        # A segmentation outlining the sector-like regions that\n","        # failed the consistency check (should usually be blank\n","        # after correction is performed)\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_bad')\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/sectors'):\n","        # the output containing the regions in the segmentation\n","        # where a sector is predicted\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/sectors')\n","\n","    if not os.path.exists(OUTPUT_CROPS_FOLDER + '/sector_comps'):\n","        # same as before, but only red pixels in the segmentation\n","        # are considered\n","        os.makedirs(OUTPUT_CROPS_FOLDER + '/sector_comps')\n"]},{"cell_type":"markdown","metadata":{"id":"7Gs78Ruu45z0"},"source":["# Functions"]},{"cell_type":"markdown","metadata":{"id":"54HKkXOM48wY"},"source":["## Functions for U-net architecture"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jaAluWeC4_87"},"outputs":[],"source":["def conv_block(inputs, channels, pool=True):\n","    \"\"\"Consists of two convolutional layers follwed by an\n","    optional max-pooling layer\"\"\"\n","\n","    x_output = Conv2D(channels, 3, padding=\"same\")(inputs)\n","    x_output = BatchNormalization()(x_output)\n","    x_output = Activation('relu')(x_output)\n","\n","    x_output = Conv2D(channels, 3, padding=\"same\")(x_output)\n","    x_output = BatchNormalization()(x_output)\n","    x_output = Activation('relu')(x_output)\n","\n","    if pool is True:  # Only to be used in the encoder path which has max pooling layers\n","        p_output = MaxPool2D((2, 2))(x_output)\n","        return x_output, p_output\n","\n","    return x_output\n","\n","\n","if USE_TEST_NETWORK is False:\n","    print('Running U-Net.')\n","\n","    def build_unet(shape, num_classes):\n","        \"\"\"This is the implementation of the U-net architecture\"\"\"\n","\n","        inputs = Input(shape)\n","\n","        # Determine whether to add a layer indicating adding noise\n","        # This should be done to the training images only.\n","        #inputs = GaussianNoise(inputs, stddev=0.5) # use this\n","        #inputs = GaussianNoise(inputs, stddev=0.5, training=True)\n","\n","        # Encoder region\n","\n","        x_1, p_1 = conv_block(inputs, 64, pool=True)\n","        x_2, p_2 = conv_block(p_1, 128, pool=True)\n","        x_3, p_3 = conv_block(p_2, 256, pool=True)\n","        x_4, p_4 = conv_block(p_3, 512, pool=True)\n","\n","        # Connecting the Encoder and Decoder regions (the deepest layer)\n","\n","        b_1 = conv_block(p_4, 1024, pool=False)\n","\n","        # Decoder Region\n","\n","        u_1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(b_1)\n","        #print(u1.shape)\n","        #print(x4.shape)\n","        c_1 = Concatenate()([u_1, x_4])\n","        x_5 = conv_block(c_1, 512, pool=False)\n","\n","        u_2 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x_5)\n","        c_2 = Concatenate()([u_2, x_3])\n","        x_6 = conv_block(c_2, 256, pool=False)\n","\n","        u_3 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x_6)\n","        c_3 = Concatenate()([u_3, x_2])\n","        x_7 = conv_block(c_3, 128, pool=False)\n","\n","        u_4 = UpSampling2D((2, 2), interpolation=\"bilinear\")(x_7)\n","        c_4 = Concatenate()([u_4, x_1])\n","        x_8 = conv_block(c_4, 64, pool=False)\n","\n","        # Obtain output layer with number of desired classes\n","\n","        output = Conv2D(num_classes, 1, padding=\"same\",\n","                        activation=\"softmax\")(x_8)\n","\n","        return Model(inputs, output)\n","\n","elif USE_TEST_NETWORK is True:\n","    print('Running the testing network.')\n","\n","    def build_unet(shape, num_classes):\n","        \"\"\"This is a network to test for errors in code\"\"\"\n","\n","        inputs = Input(shape)\n","\n","        # Encoder region\n","\n","        _, p_1 = conv_block(inputs, 8, pool=True)\n","\n","        # Decoder Region\n","\n","        u_1 = UpSampling2D((2, 2), interpolation=\"bilinear\")(p_1)\n","        x_2 = conv_block(u_1, 16, pool=False)\n","\n","        # Obtain output layer with number of desired classes\n","\n","        output = Conv2D(num_classes, 1, padding=\"same\",\n","                        activation=\"softmax\")(x_2)\n","\n","        return Model(inputs, output)\n"]},{"cell_type":"markdown","metadata":{"id":"OUFRCxo55AVI"},"source":["## Functions for preprocessing images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XBHWh9ZG5CVU"},"outputs":[],"source":["# function to crop image\n","\n","\n","def crop(img):\n","    \"\"\"This function is used to crop a colony from an image\"\"\"\n","\n","    i, j = img.nonzero()[:2]\n","    x_min = i.min()\n","    x_max = i.max() + 1\n","    y_min = j.min()\n","    y_max = j.max() + 1\n","    return img[x_min:x_max, y_min:y_max], [x_min, x_max, y_min, y_max]\n","\n","\n","def trim_border(x_image):\n","    \"\"\"This function makes non-square images square by trimming the\n","    longer dimensions equally on both sides. \"\"\"\n","\n","    if x_image.shape[0] > x_image.shape[1]:\n","        pixel_diff = x_image.shape[0] - x_image.shape[1]\n","        if pixel_diff % 2 == 0:\n","            x_cropped = x_image[(pixel_diff // 2)\n","                           :(x_image.shape[0]-(pixel_diff // 2)), :, :]\n","        else:\n","            x_cropped = x_image[math.ceil(\n","                pixel_diff / 2):x_image.shape[0]-(math.floor(pixel_diff / 2)), :, :]\n","\n","    elif x_image.shape[0] < x_image.shape[1]:\n","        pixel_diff = x_image.shape[1] - x_image.shape[0]\n","        if pixel_diff % 2 == 0:\n","            x_cropped = x_image[:, (pixel_diff // 2):x_image.shape[1]-(pixel_diff // 2), :]\n","        else:\n","            x_cropped = x_image[:, math.ceil(\n","                pixel_diff / 2):x_image.shape[1]-(math.floor(pixel_diff / 2)), :]\n","\n","    else:\n","        x_cropped = x_image\n","\n","    return x_cropped\n","\n","\n","def read_image(x_image):\n","    \"\"\"This function reads in a color image and normalizes pixels values\n","    between 0 and 1\"\"\"\n","\n","    x_image = cv2.imread(x_image, cv2.IMREAD_COLOR)\n","    x_image = trim_border(x_image)  # this should be called\n","    x_image = cv2.resize(x_image, (WIDTH, HEIGHT))\n","    x_image = x_image / 255.0  # normalize image\n","    x_image = x_image.astype(np.float32)\n","    return x_image\n","\n","\n","def read_mask(x_mask):\n","    \"\"\"This function reads in a mask.  Only normalizes binary masks\"\"\"\n","\n","    x_mask = cv2.imread(x_mask, cv2.IMREAD_GRAYSCALE)\n","    #print(x.shape)\n","    x_mask = cv2.resize(x_mask, (WIDTH, HEIGHT))\n","    if NUM_CLASSES == 2:\n","        x_mask = x_mask / 255.0\n","        # This is necessary because for some reason binary images\n","        # automatically have 0 and 255 encoded.\n","    x_mask = x_mask.astype(np.int32)\n","    return x_mask\n","\n","\n","def tf_dataset(x_image, y_mask, batch=1):\n","    \"\"\"This function is used to grab images in preparation for training\"\"\"\n","\n","    dataset = tf.data.Dataset.from_tensor_slices((x_image, y_mask))\n","    dataset = dataset.shuffle(buffer_size=500)\n","    dataset = dataset.map(preprocess)\n","    dataset = dataset.batch(batch)\n","    dataset = dataset.repeat()\n","    dataset = dataset.prefetch(2)\n","    return dataset\n","\n","\n","def preprocess(x_image, y_mask):\n","    \"\"\"This function reshapes the images and masks.  Masks are one-hot encoded,\n","    and images and masks are shaped to ensure equal spatial dimensions.\"\"\"\n","\n","    def decode_process(x, y):\n","        \"\"\" This converts the image and mask to numpy arrays\"\"\"\n","\n","        x = x.decode()\n","        y = y.decode()\n","\n","        image = read_image(x)\n","        mask = read_mask(y)\n","\n","        return image, mask\n","\n","    image, mask = tf.numpy_function(decode_process, [x_image, y_mask], [tf.float32, tf.int32])\n","    mask = tf.one_hot(mask, NUM_CLASSES, dtype=tf.int32)\n","    image.set_shape([HEIGHT, WIDTH, 3])  # does not change\n","    mask.set_shape([HEIGHT, WIDTH, NUM_CLASSES])  # change last argument dependeing\n","    # on how many classes you want to do for segmentation\n","\n","    return image, mask\n"]},{"cell_type":"markdown","metadata":{"id":"C6Eh7KVrEENl"},"source":["## Helper Functions"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lqZvLNCqEGBZ"},"outputs":[],"source":["# Helper functions\n","\n","def swap_class_labels(seg, red_val, white_val):\n","    \"\"\"Swaps the values assigned to the red and white colony labels for\n","    each pixel.\n","    If a segmentation requires that white pixels should be labeled as white,\n","    but currently show up as gray, this function should ensure that red pixels\n","    are labeled as gray, while white pixels are labeled as white.\n","    red_val is the value that we want for the red pixels.\n","    white_val is the label that red pixels are currently assigned.\"\"\"\n","\n","    white_array = np.where(seg == red_val, white_val, 0)\n","    red_array = np.where(seg == white_val, red_val, 0)\n","    swapped_array = red_array + white_array\n","    return swapped_array\n","\n","def get_color_codes(indicator):\n","    \"\"\"Gives a color vector associated with each number.\"\"\"\n","    if indicator == 0:  # bad_seg\n","        color_code = (0, 255, 0)\n","    elif indicator == 1:  # pink\n","        color_code = (255, 0, 255)\n","    elif indicator == 2:  # red\n","        color_code = (0, 0, 255)\n","    elif indicator == 3:  # variegating\n","        color_code = (255, 0, 0)\n","    elif indicator == 4:  # white\n","        color_code = (255, 255, 255)\n","    return color_code\n","\n","# function to get unique values\n","# (https://www.geeksforgeeks.org/python-get-unique-values-list/)\n","\n","\n","def unique(list1):\n","    \"\"\"Returns a list of unique elements inside a list object\"\"\"\n","\n","  # intilize a null list\n","    unique_list = []\n","\n","    # traverse for all elements\n","    for x_item in list1:\n","        # check if exists in unique_list or not\n","        if x_item not in unique_list:\n","            unique_list.append(x_item)\n","        # print list\n","    return unique_list\n","\n","# Create triangle starting from center, connecting the two ends of a connected component\n","# To get the boundaries of the triangle, use Bresenham's line algorithm\n","\n","# Definition taken from\n","# http://www.roguebasin.com/index.php?title=Bresenham%27s_Line_Algorithm#Python\n","\n","\n","def get_line(start, end):\n","    \"\"\"Bresenham's Line Algorithm\n","    Produces a list of tuples from start and end\n","\n","    >>> points1 = get_line((0, 0), (3, 4))\n","    >>> points2 = get_line((3, 4), (0, 0))\n","    >>> assert(set(points1) == set(points2))\n","    >>> print points1\n","    [(0, 0), (1, 1), (1, 2), (2, 3), (3, 4)]\n","    >>> print points2\n","    [(3, 4), (2, 3), (1, 2), (1, 1), (0, 0)]\n","    \"\"\"\n","    # Setup initial conditions\n","    x_1, y_1 = start\n","    x_2, y_2 = end\n","    d_x = x_2 - x_1\n","    d_y = y_2 - y_1\n","\n","    # Determine how steep the line is\n","    is_steep = abs(d_y) > abs(d_x)\n","\n","    # Rotate line\n","    if is_steep:\n","        x_1, y_1 = y_1, x_1\n","        x_2, y_2 = y_2, x_2\n","\n","    # Swap start and end points if necessary and store swap state\n","    swapped = False\n","    if x_1 > x_2:\n","        x_1, x_2 = x_2, x_1\n","        y_1, y_2 = y_2, y_1\n","        swapped = True\n","\n","    # Recalculate differentials\n","    d_x = x_2 - x_1\n","    d_y = y_2 - y_1\n","\n","    # Calculate error\n","    error = int(d_x / 2.0)\n","    ystep = 1 if y_1 < y_2 else -1\n","\n","    # Iterate over bounding box generating points between start and end\n","    y_it = y_1\n","    points = []\n","    for x_it in range(x_1, x_2 + 1):\n","        coord = (y_it, x_it) if is_steep else (x_it, y_it)\n","        points.append(coord)\n","        error -= abs(d_y)\n","        if error < 0:\n","            y_it += ystep\n","            error += d_x\n","\n","    # Reverse the list if the coordinates were swapped\n","    if swapped:\n","        points.reverse()\n","    return points\n","\n","# Function to sort bounary pixels by theta value relative to center\n","# of colony image\n","# 'seg' should be the mask of the colony boundary\n","# 'start' is the center of the image, and 'end' is the boundary pixel\n","\n","\n","def sort_thetas(seg):\n","    \"\"\"Get the angular values between the center of a colony and all\n","    pixels along its boundary, and sort them starting from one endpoint\n","    of the boundary to the other.\"\"\"\n","\n","    # get center of the segmentation\n","    seg_shape = seg.shape\n","    seg_center = (np.round(seg_shape[1]/2.0), np.round(seg_shape[0]/2.0))\n","\n","    # get the points on the boundary\n","    points = np.transpose(np.nonzero(seg)).tolist()\n","\n","    # Get the angles from the center to the endpoints\n","    these_thetas = []\n","    for this_point in points:\n","        diff_width = this_point[1] - seg_center[0]\n","        diff_height = this_point[0] - seg_center[1]\n","        these_thetas.append(math.atan2(-diff_height, diff_width))\n","\n","    these_thetas_sorted = np.sort(these_thetas)\n","    these_thetas_sorted_args = np.argsort(these_thetas)\n","    sorted_points = []\n","    for this_arg in these_thetas_sorted_args:\n","        sorted_points.append(points[this_arg])\n","\n","    # Add a copy of the first point to the end to make this periodic\n","    these_thetas_sorted = np.append(\n","        these_thetas_sorted, these_thetas_sorted[0])\n","    sorted_points.append(sorted_points[0])\n","\n","    return these_thetas_sorted, sorted_points\n","\n","# Function to create data for plotting 'intensity' between endpoints of a line\n","\n","\n","def get_intensity_map(seg, sorted_points):\n","    \"\"\"Counts the number of pixels from the center of a colony\n","    to its boundary\"\"\"\n","\n","    intensity_sum = []\n","    full_seg_sum = []\n","    seg_shape = seg.shape\n","    seg_center = (np.round(seg_shape[1]/2.0).astype(np.int32),\n","                  np.round(seg_shape[0]/2.0).astype(np.int32))\n","\n","    # get a line between the center and each endpoint iteratively\n","    for this_point in sorted_points:\n","        line_points = get_line(seg_center, tuple(this_point))\n","        #line_points_sum = len(line_points)\n","\n","        # make mask containing points on the line\n","        seg_line = np.zeros_like(seg)\n","        full_seg = np.zeros_like(seg)\n","        for this_line_point in line_points:\n","\n","            full_seg[this_line_point[0], this_line_point[1]] = True\n","            # check if each pixel on the line is red.\n","            # Keep those that are red only\n","            if seg[this_line_point[0], this_line_point[1]] is True:\n","                seg_line[this_line_point[0], this_line_point[1]] = True\n","\n","        seg_line_sum = np.sum(seg_line)\n","        intensity_sum.append(seg_line_sum)\n","        full_seg_sum.append(np.sum(full_seg))\n","\n","    return intensity_sum, full_seg_sum\n","\n","\n","def create_filled_ellipse_in_array(seg, padding=0):\n","    \"\"\"Draws an ellipse over a colony segmentation corresponding\n","    to a cured colony\"\"\"\n","\n","    ellipse_array = np.zeros_like(seg).astype(bool)\n","    ellipse_height = seg.shape[0]\n","    ellipse_width = seg.shape[1]\n","    rr, cc = draw.ellipse((ellipse_height - 1) / 2.0, (ellipse_width-1) /\n","                          2.0, (ellipse_height) / 2.0 - padding, (ellipse_width) / 2.0 - padding)\n","    ellipse_array[rr, cc] = 1\n","    return ellipse_array\n","\n","\n","def create_circle_boundary(seg, radius):\n","    \"\"\"Similar to the above but draws a circle instead.\n","    Requires radius as input.\"\"\"\n","\n","    ellipse_array = np.zeros_like(seg).astype(bool)\n","    ellipse_height = seg.shape[0]\n","    ellipse_width = seg.shape[1]\n","    rr, cc = draw.ellipse((ellipse_height - 1) / 2.0,\n","                          (ellipse_width-1) / 2.0, radius, radius)\n","    ellipse_array[rr, cc] = 1\n","    ellipse_boundary = get_colony_boundary_binary(ellipse_array)\n","    return ellipse_boundary\n","\n","\n","def get_endpoint_locations(endpoints_list, seg, radius):\n","    \"\"\"Creates a list of all endpoints of a connected component in a\n","    colony boundary segmentation.  The segmenation and its connected\n","    component must be given as input.\"\"\"\n","\n","    # Function finds the angle between the center and endpoints of\n","    # the component, and extends the endpoint to the radius of\n","    # the circle predicted.\n","    #ellipse_array = np.zeros_like(seg).astype(bool)\n","    ellipse_height = seg.shape[0]\n","    ellipse_width = seg.shape[1]\n","    mid_height = (ellipse_height - 1) / 2.0\n","    mid_width = (ellipse_width - 1) / 2.0\n","    endpoints_x = []\n","    endpoints_y = []\n","    endpoints_x.append(mid_width)\n","    endpoints_y.append(mid_height)\n","    center_seg = list([mid_height, mid_width])\n","    angle_list = []\n","    for this_endpoint in endpoints_list:\n","        angle = math.atan2(\n","            (this_endpoint[0] - endpoints_y[0]), (this_endpoint[1] - endpoints_x[0]))\n","        angle_list.append(angle)\n","    endpoint_locations = []\n","    for this_angle in angle_list:\n","        endpoint_x = center_seg[1] + radius*math.cos(this_angle)\n","        endpoint_y = center_seg[0] + radius*math.sin(this_angle)\n","        endpoint_locations.append(list([endpoint_x, endpoint_y]))\n","        endpoints_x.append(endpoint_x)\n","        endpoints_y.append(endpoint_y)\n","    return angle_list, endpoint_locations, endpoints_x, endpoints_y\n","\n","\n","def switch_red_white(seg):\n","    \"\"\"Swaps the labled of the red and white pixels in segmentation.\n","    Needed for consistency.\"\"\"\n","\n","    temp_seg = copy.deepcopy(seg)\n","    # find pixels given 255, place a temporary number\n","    # (these should be red pixels)\n","    temp_seg = np.where(temp_seg == 255, 111, temp_seg)\n","    # find pixels given 255, and assign them 255\n","    # (these are the white pixels you want to label properly)\n","    temp_seg = np.where(temp_seg == 127, 255, temp_seg)\n","    # find pixels given the temporary label, and assign them 127\n","    # (these are the red pixels you want to label properly)\n","    temp_seg = np.where(temp_seg == 111, 127, temp_seg)\n","    return temp_seg\n"]},{"cell_type":"markdown","metadata":{"id":"_8FYFdm_FsCt"},"source":["## Classification Code"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6AdgQgELFtm2"},"outputs":[],"source":["# Function to find colony boundary\n","\n","\n","def get_colony_boundary(colony_mask):\n","    \"\"\"Takes a colony segmentation and outputs a binary mask indicating where\n","    the boundary of the colony is found.\n","    This outputs a skeletion of the boundary.\"\"\"\n","    padded_colony = np.pad(\n","        colony_mask[:, :, 0] != 0, 1, 'constant', constant_values=0)\n","    check_boundary_array = np.zeros_like(padded_colony) + 4\n","    image_shape = check_boundary_array.shape\n","\n","    for i in range(1, image_shape[0]-1):\n","        for j in range(1, image_shape[1]-1):\n","            # pixel above is 1\n","            check_boundary_array[i, j] = check_boundary_array[i,\n","                                                              j] - padded_colony[i-1, j]\n","            # pixel below is 1\n","            check_boundary_array[i, j] = check_boundary_array[i,\n","                                                              j] - padded_colony[i+1, j]\n","            # pixel to the left is 1\n","            check_boundary_array[i, j] = check_boundary_array[i,\n","                                                              j] - padded_colony[i, j-1]\n","            # pixel to the right is 1\n","            check_boundary_array[i, j] = check_boundary_array[i,\n","                                                              j] - padded_colony[i, j+1]\n","\n","    background_mask = check_boundary_array > 0\n","    edge_mask = np.multiply(background_mask, padded_colony)  # sanity check so\n","    # that boundary is in the padded colony\n","    edge_mask_unpadded = edge_mask[1:-1, 1:-1]  # remove the padding\n","\n","    # Skeletonize red boundary pixels\n","    # (https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html)\n","    # This will turn any represenation of a cohesive red colony\n","    # region on the boundary as a set of lines in pixels space, meant to\n","    # correct for areas that have weird boundaries.\n","    edge_mask_unpadded = skeletonize(edge_mask_unpadded)\n","    return edge_mask_unpadded\n","\n","# binary version of above code\n","\n","\n","def get_colony_boundary_binary(colony_mask):\n","    \"\"\"Does the same as above, but colony_mask is also binary\"\"\"\n","\n","    padded_colony = np.pad(colony_mask != 0, 1, 'constant', constant_values=0)\n","    check_boundary_array = np.zeros_like(padded_colony) + 4\n","    image_shape = check_boundary_array.shape\n","\n","    for i in range(1, image_shape[0]-1):\n","        for j in range(1, image_shape[1]-1):\n","            # pixel above is 1\n","            check_boundary_array[i, j] = check_boundary_array[i,\n","                                                              j] - padded_colony[i-1, j]\n","            # pixel below is 1\n","            check_boundary_array[i, j] = check_boundary_array[i,\n","                                                              j] - padded_colony[i+1, j]\n","            # pixel to the left is 1\n","            check_boundary_array[i, j] = check_boundary_array[i,\n","                                                              j] - padded_colony[i, j-1]\n","            # pixel to the right is 1\n","            check_boundary_array[i, j] = check_boundary_array[i,\n","                                                              j] - padded_colony[i, j+1]\n","\n","    background_mask = check_boundary_array > 0\n","    edge_mask = np.multiply(background_mask, padded_colony)  # sanity check so\n","    # that boundary is in the padded colony\n","    edge_mask_unpadded = edge_mask[1:-1, 1:-1]  # remove the padding\n","\n","    # Skeletonize red boundary pixels\n","    # (https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html)\n","    # This will turn any represenation of a cohesive red colony region\n","    # on the boundary as a set of lines in pixels space, meant to correct\n","    # for areas that have weird boundaries.\n","    edge_mask_unpadded = skeletonize(edge_mask_unpadded)\n","    return edge_mask_unpadded\n","\n","\n","# Function to find both the red and white partitions of colony boundary\n","\n","def get_boundary_partitions(red_colony_mask, white_colony_mask, boundary):\n","    \"\"\"Partitions a colony segmentation into its red/white interior pixels\n","    and its red/white boundary pixels\"\"\"\n","\n","    red_boundary_mask = np.multiply(red_colony_mask, boundary)\n","    white_boundary_mask = np.multiply(white_colony_mask, boundary)\n","    boundary_mask_h, boundary_mask_w = boundary.shape\n","\n","    #red_boundary_skeleton = skeletonize(red_boundary_mask)\n","    #white_boundary_skeleton = skeletonize(white_boundary_mask)\n","    return red_boundary_mask, white_boundary_mask, boundary_mask_h, boundary_mask_w\n","\n","\n","# Function to find endpoints of red connected component\n","\n","def get_boundary_component_endpoints(colony_image, red_component):\n","    \"\"\"locates the endpoints of a connected component along the boundary.\n","    This requires the colony segmentation and the corresponding boundary\n","    region as input.  Endpoints are found using `cv2.goodFeaturedToTrack`,\n","    an implemntnation of the hit-miss algorithm, and a brute force method\n","    for locating more obvious endpoints which the hit-miss algorithm\n","    doesn't find.\"\"\"\n","\n","    red_component_padded = np.pad(\n","        red_component, 1, 'constant', constant_values=0).astype(np.int32)\n","\n","    # This function uses the results of 2 methods to find endpoints\n","    # of a curve in order to deal with each other's deficiencies.\n","\n","    # Method 1:\n","    # Hit-miss algortihm using cv2 function goodFeaturesToTrack\n","    # (https://docs.opencv.org/3.4/dd/d1a/group__imgproc__feature.html#ga1d6bb77486c8f92d79c8793ad995d541)\n","    red_endpoints = cv2.goodFeaturesToTrack(red_component.astype(\n","        np.uint8), maxCorners=2, qualityLevel=0.01, minDistance=0.1)\n","    if type(red_endpoints == None):\n","        red_endpoints_list = []\n","        # print(red_endpoints_list)\n","    else:\n","        red_endpoints = red_endpoints.astype(np.int32)\n","        red_endpoints_list = (red_endpoints[0].astype(np.int32)).tolist()\n","\n","    # Method 2:\n","    # Look for the obvious endpoints that 'corner'\n","    endpoints_check = np.zeros_like(colony_image) + 8\n","    endpoints_check_padded = np.pad(\n","        endpoints_check, 1, 'constant', constant_values=0)\n","    endpoint_padded_shape = endpoints_check_padded.shape\n","\n","    for i in range(1, endpoint_padded_shape[0]-1):\n","        for j in range(1, endpoint_padded_shape[1]-1):\n","            # pixel above is 1\n","            endpoints_check_padded[i, j] = endpoints_check_padded[i,\n","                                                                  j] - red_component_padded[i-1, j]\n","            # pixel below is 1\n","            endpoints_check_padded[i, j] = endpoints_check_padded[i,\n","                                                                  j] - red_component_padded[i+1, j]\n","            # pixel to the left is 1\n","            endpoints_check_padded[i, j] = endpoints_check_padded[i,\n","                                                                  j] - red_component_padded[i, j-1]\n","            # pixel to the right is 1\n","            endpoints_check_padded[i, j] = endpoints_check_padded[i,\n","                                                                  j] - red_component_padded[i, j+1]\n","            # pixel on top-left is 1\n","            endpoints_check_padded[i, j] = endpoints_check_padded[i,\n","                                                                  j] - red_component_padded[i-1, j-1]\n","            # pixel on top-right is 1\n","            endpoints_check_padded[i, j] = endpoints_check_padded[i,\n","                                                                  j] - red_component_padded[i-1, j+1]\n","            # pixel on bottom-left is 1\n","            endpoints_check_padded[i, j] = endpoints_check_padded[i,\n","                                                                  j] - red_component_padded[i+1, j-1]\n","            # pixel on bottom-right is 1\n","            endpoints_check_padded[i, j] = endpoints_check_padded[i,\n","                                                                  j] - red_component_padded[i+1, j+1]\n","\n","    # Look for any 'cornering' pixels.  There should be at most 2 if skeletonize works properly.\n","    endpoint_mask = endpoints_check_padded > 6\n","    component_endpoint_mask = np.multiply(endpoint_mask, red_component_padded)\n","    # sanity check to see if endpoints are part of boundary mask\n","    component_endpoint_mask_unpadded = component_endpoint_mask[1:-1, 1:-1]\n","    endpoint_locations = np.nonzero(component_endpoint_mask_unpadded)\n","\n","    # ensure dimensions are consistent\n","    endpoint_locations = np.transpose(\n","        np.flip(np.flip(np.array(endpoint_locations), axis=0), axis=1))\n","    endpoint_locations = endpoint_locations.tolist()\n","\n","    # combine lists and keep the unique elements\n","\n","    full_endpoints_list = endpoint_locations + red_endpoints_list\n","    full_endpoints_list = unique(full_endpoints_list)\n","\n","    if len(full_endpoints_list) == 1:\n","        warnings.warn(\n","            'Algorithm found only 1 endpoint.  It\\'s possible that you have a very small region, but double check the code again anyway.')\n","    elif len(full_endpoints_list) > 2:\n","        warnings.warn(\n","            'Algorithm found more than 2 endpoints.  Possible bad boundary detected.  Will proceed in using the first two elements in the list.')\n","    elif len(full_endpoints_list) == 0:\n","        warnings.warn(\n","            'Algorithm found no endpoints.  It\\'s possible that you have a full cycle, but double check the code again anyway.')\n","\n","    return full_endpoints_list  # This does NOT include the center of the colony\n","\n","\n","# Function that returns the boundary and filled sector\n","\n","def get_sector_masks(red_component, full_endpoints_list):\n","    \"\"\"Outputs the \"idealized\" sector-like regions of a colony segmentation.\n","    Theis output the idealized sector boundaries, interiors and their union.\"\"\"\n","\n","    sector_bounds = np.zeros_like(red_component)\n","    red_h, red_w = sector_bounds.shape\n","\n","    # if there exists an endpoint\n","    if len(full_endpoints_list) > 0:\n","        bound_1 = get_line((np.round(red_h/2.0).astype(np.int32), np.round(red_w/2.0).astype(\n","            np.int32)), (full_endpoints_list[0][1], full_endpoints_list[0][0]))\n","        boundary_line_1 = [list(this_pix) for this_pix in bound_1]\n","        for this_point in boundary_line_1:\n","            sector_bounds[this_point[0], this_point[1]] = 1\n","\n","    # if there exists at least two endpoints (and hopefully there are EXACTLY two...)\n","    if len(full_endpoints_list) > 1:\n","        bound_2 = get_line((np.round(red_h/2.0).astype(np.int32), np.round(red_w/2.0).astype(\n","            np.int32)), (full_endpoints_list[1][1], full_endpoints_list[1][0]))\n","        boundary_line_2 = [list(this_pix) for this_pix in bound_2]\n","        for this_point in boundary_line_2:\n","            sector_bounds[this_point[0], this_point[1]] = 1\n","\n","    sector_boundary = np.logical_or(sector_bounds, red_component)\n","\n","    # Flood fill region inside sector boundary\n","    sector_filled = copy.deepcopy(sector_boundary)\n","    # flood fill region using 'binary_fill_holes'\n","    sector_filled[ndimage.binary_fill_holes(sector_filled)] = 1\n","    sector_filled = sector_filled.astype(np.int32)\n","\n","    sector_interior = np.logical_xor(sector_filled, sector_boundary)\n","    return sector_boundary, sector_interior, sector_filled\n","\n","\n","# Function to check for interior-exterior consistency\n","\n","def check_for_consistency(sector_interior, sector_boundary, red_colony_mask):\n","    \"\"\"Old function, not being used, see check_for_consistency_2\"\"\"\n","\n","  # Check that the interior of the sector is represented in the colony\n","    check_interior = np.logical_and(sector_interior, red_colony_mask)\n","    interior_sum = np.sum(sector_interior)\n","    check_interior_sum = np.sum(check_interior)\n","    # If there is no interior or there are two few pixels, use both the interior and the boundary.\n","    if interior_sum >= 3:\n","        # If first condition is met, check to see how close the sector is actually captured by U-Net\n","        # Compute the number of pixels in the sector detected by U-Net,\n","        # divided by the number of pixels in tbe simplified sector.\n","        prop_interior = check_interior_sum.astype(\n","            np.float64) / interior_sum.astype(np.float64)\n","        if prop_interior < 0.5:\n","            #print('There is one sector that may be misclassified.  Moving on to next sector.')\n","            confirm_check = False\n","            # U-Net did not detect an adequate number of pixels inside the simplified sector\n","            # This could be a misclassified sector\n","            # In this case, change the bad boundary pixels to the opposite color\n","            # Since we are working only with the red boundary pixel, change\n","            # the bad red pixels to white pixels.\n","        else:\n","            #print('This is a sector')\n","            confirm_check = True\n","            # If the second condition is also not met, then you have a sector\n","            # add the sector to the list\n","    else:\n","        #print('There is one sector that is too small to analyze.  Using\n","        # both interior and boundary instead')\n","        full_sector = np.logical_or(sector_interior, sector_boundary)\n","        check_interior_and_boundary = np.logical_and(\n","            full_sector, red_colony_mask)\n","        sector_sum = np.sum(full_sector)\n","        check_full_sum = np.sum(check_interior_and_boundary)\n","        prop_interior = check_full_sum.astype(\n","            np.float64) / sector_sum.astype(np.float64)\n","        if sector_sum >= 5:\n","            # There are enough pixels overall to perform a measurement.\n","\n","            if prop_interior < 0.5:\n","                confirm_check = False\n","            else:\n","                #print('This is a sector')\n","                confirm_check = True\n","\n","        else:\n","            confirm_check = False\n","\n","    return confirm_check, prop_interior\n","\n","# A redo of the above function, but considers the full region regardless\n","# of how many pixels there are (must be greater than 0)\n","\n","\n","def check_for_consistency_2(sector_filled, colony_mask):\n","    \"\"\"Implements the first part of the purity correction step as\n","    described in the paper.  This function indicates whetther the purity\n","    metric for a region is less than 0.5\"\"\"\n","\n","  # Check that the interior of the sector is represented in the colony\n","    check_interior = np.logical_and(sector_filled, colony_mask)\n","    sector_sum = np.sum(sector_filled)\n","    check_sector_sum = np.sum(check_interior)\n","    prop_interior = check_sector_sum.astype(\n","        np.float64) / sector_sum.astype(np.float64)\n","\n","    if prop_interior < 0.5:\n","        confirm_check = False\n","    else:\n","        confirm_check = True\n","\n","    return confirm_check, prop_interior\n","\n","\n","# Function to change pixels from red to white\n","\n","def change_pixel_labels(red_boundary_skeleton, red_component, white_boundary_skeleton):\n","    \"\"\"Implements the second part of the purity correction step.\n","    This returns a temporary masks containg the compoenet to be removed and\n","    the boundary for which the removed component will be added, respectively\"\"\"\n","\n","  # If a potential sector is lacking interior red pixels, and intead has\n","  # sifficinet percentage of white pixels,\n","  # this function will change the exterior pixels of the sector from red to white.\n","    temp_red_boundary_skeleton = np.logical_xor(\n","        red_boundary_skeleton, red_component)  # one is a subset of the other\n","    temp_white_boundary_skeleton = np.logical_or(\n","        white_boundary_skeleton, red_component)  # both are disjoint\n","    return temp_red_boundary_skeleton, temp_white_boundary_skeleton\n","\n","# Function doesn't work yet.  Use the two below this.\n","\n","\n","def pixel_class_swap_on_boundary(boundary_skeleton_to_change, red_boundary_skeleton_bad_components, white_boundary_skeleton_bad_components):\n","    \"\"\"Performs the class swap along the colony boundary for the\n","    entire segemntation\"\"\"\n","\n","    bad_red_boundary_pixels = np.logical_and(\n","        boundary_skeleton_to_change > 0, red_boundary_skeleton_bad_components)\n","    bad_white_boundary_pixels = np.logical_and(\n","        boundary_skeleton_to_change > 0, white_boundary_skeleton_bad_components)\n","\n","    # Change bad red boundaries to white\n","    boundary_skeleton_to_change[bad_red_boundary_pixels] = 1\n","\n","    # Change bad white boundaries to red\n","    boundary_skeleton_to_change[bad_white_boundary_pixels] = 2\n","\n","    return boundary_skeleton_to_change\n","\n","# Functions for swapping boundary labels for components that fail consistency check\n","# Consider writing a function that does both operatons for both classes.\n","\n","\n","def grow_boundary(boundary_skeleton_to_grow, bad_components_to_take):\n","    \"\"\"Adds the boundaries corresponding to regions that do not satisfy\n","    the purity condition.\"\"\"\n","    # using logical or allows to add to the existing structure\n","    # For example, add the bad white boundaries to the red boundaries\n","    grown_boundary = np.logical_or(\n","        boundary_skeleton_to_grow, bad_components_to_take)\n","    return grown_boundary\n","\n","\n","def shrink_boundary(boundary_skeleton_to_shrink, bad_components_to_remove):\n","    \"\"\"Removes the boundaries corresponding to regions that do not satisfy\n","    the purity condition.\"\"\"\n","    # Since red and white boundaries are both disjoint subsets of the\n","    # full boundary, using xor will subtract the subset from the whole\n","    # without adding new information.  For example, remove the bad white\n","    # boundaries, and give them to the red boundaries.\n","    shrunk_boundary = np.logical_xor(\n","        boundary_skeleton_to_shrink, bad_components_to_remove)\n","    return shrunk_boundary\n"]},{"cell_type":"markdown","metadata":{"id":"xwiHKpE6K558"},"source":["## Functions for Shape Properties"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"EiNjxyPOK8Zi"},"outputs":[],"source":["# Condition 1: Check that the colony segmentation is one connected component\n","\n","\n","def check_components_of_colony(seg):\n","    \"\"\"Checks if the colony segmentation is one connected component\"\"\"\n","\n","    # First, check if the colony is one connected component\n","    binary_seg = seg > 0\n","    seg_labels = label(binary_seg)\n","    num_labels = np.unique(seg_labels)[1:]\n","    #print('Number of labels: ' + str(num_labels))\n","\n","    if len(num_labels) == 1:\n","        # The colony is one connected component\n","        # This satisfies the condition\n","        condition_1_strong = True\n","        condition_1_weak = True\n","    else:\n","        binary_seg_count = np.count_nonzero(binary_seg)\n","        # This colony has two or more connectged components\n","        # Find the biggest one, and set a threshold\n","        # Loop through each non-zero number\n","        max_comp_size = 0\n","        for this_label in num_labels:\n","            this_comp = seg_labels[seg_labels == this_label]\n","            this_comp_size = sum(this_comp)\n","            if this_comp_size > max_comp_size:\n","                max_comp_size = copy.deepcopy(this_comp_size)\n","        big_ratio = max_comp_size / float(binary_seg_count)\n","        if big_ratio > 0.9:\n","            condition_1_strong = False\n","            condition_1_weak = True\n","        else:\n","            condition_1_strong = False\n","            condition_1_weak = False\n","\n","    return condition_1_strong, condition_1_weak\n","\n","\n","# Condition 2: Check that the boundary of the colony sgentmation is one connected cpmponent\n","# The one should be more strict because all parts of the boundary are used\n","# explicitly in the classification step.\n","def check_components_of_boundary(seg_boundary):\n","    \"\"\"Checks if the boundary of the colony segmentation is one\n","    connected component\"\"\"\n","\n","    # First, check if the colony is one connected component\n","    binary_seg = seg_boundary > 0\n","    seg_labels = label(binary_seg)\n","    num_labels = np.unique(seg_labels)[1:]\n","    total_num_labels = len(num_labels)\n","\n","    if total_num_labels == 1:\n","        # The boundary meets condition 2\n","        condition_2 = True\n","    else:\n","        # The boundary has two or more connected compoents\n","        # This fails condition 2\n","        condition_2 = False\n","\n","    return condition_2\n","\n","\n","# Condition 3: Check for holes in the colony segmentation.\n","# Ideas: Get the colony boundary.  Fill it.  If the fill matches the colony segmentation,\n","# then this is easly verified.  If there is more than one connected component,\n","# then this condition will automatically fail.\n","def check_for_holes(seg, seg_boundary):\n","    \"\"\"Checks that the space within the colony boundary is\n","    completely labeled\"\"\"\n","\n","    binary_seg = seg > 0\n","    binary_boundary = seg_boundary > 0\n","\n","    #print(binary_seg.shape)\n","    #print(binary_boundary.shape)\n","\n","    # Take the boundary and fill the space in between\n","    filled_boundary = copy.deepcopy(binary_boundary)\n","    filled_boundary[ndimage.binary_fill_holes(filled_boundary)] = True\n","    #print(filled_boundary.shape)\n","    # print('Filled boundary')\n","    # plt.imshow(filled_boundary)\n","    # plt.show()\n","    # number of pixels inside the boundary, including the boundary itself.\n","    filled_boundary_count = np.count_nonzero(filled_boundary)\n","    # all pixels in the filled boundary that are also in the segmentation\n","    binary_seg_agreement = np.logical_and(binary_seg, filled_boundary)\n","    binary_seg_agreement_count = np.count_nonzero(\n","        binary_seg_agreement)  # how many of those pixels exist?\n","    #binary_seg_count = np.count_nonzero(binary_seg)\n","    #print(binary_seg_agreement_count)\n","    #print(binary_seg_count)\n","    if (float(binary_seg_agreement_count) / float(filled_boundary_count)) > 0.999:\n","        # The boundary and the space within matches that of the space occupied\n","        # by the colony segmenatation\n","        condition_3 = True\n","    else:\n","        condition_3 = False\n","\n","    return condition_3\n","\n","\n","# Condition 4: Check that the colony boundary has only one cycle, and that the\n","# cycle uses every pixel of the boundary.\n","# This is equivalent to saying that the colony boundary has exactly one\n","# Hamiltonian cycle.  Showing that there exists one is far easier than showing\n","# there is only one though.\n","def find_hamilton_cycle(seg_boundary):\n","    \"\"\"Checks that the colony boundary is cyclic, and that all pixels on the\n","    boundary are part of the cycle, and that all pixels are along\n","    the cycle exactly once.\"\"\"\n","\n","    binary_boundary = seg_boundary > 0\n","    # Check that a cycle exists\n","    # If it exists, check that the cycle traverses the same number of pixels\n","    # as the number in the segmentation\n","    # Idea: Find all cycles of an image.  Aim for the ones whose length is the\n","    # same as the number of pixels of the boundary.  This will ensure that all\n","    # the pixels are being used.\n","\n","    # get contours\n","    contours = cv2.findContours(\n","        binary_boundary, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n","    hierarchy = contours[1] if len(contours) == 2 else contours[2]\n","    contours = contours[0] if len(contours) == 2 else contours[1]\n","\n","    # count inner contours\n","    count = 0\n","    for component in zip(contours, hierarchy):\n","        #cntr = component[0]\n","        hier = component[1]\n","        # discard outermost no parent contours and keep innermost no child contours\n","        # hier = indices for next, previous, child, parent\n","        # no parent or no child indicated by negative values\n","        if (hier[3] > -1) & (hier[2] < 0):\n","            count = count + 1\n","\n","    # get the actual inner list of hierarchy descriptions\n","    hierarchy = hierarchy[0]\n","\n","    has_cycle = False\n","    return has_cycle\n","\n","\n","# Condition 5: Check that the convex hull of the segmentation is close to a circle.\n","def compare_convex_hull(seg, seg_boundary):\n","    \"\"\"First computes to convex hull of a colony segmentation, finds its\n","    boundary, and compares that boundary to the original boundary segmentation.\n","    This checks to see if the colony boundary is close to convex.\"\"\"\n","\n","    binary_seg = seg > 0\n","    binary_boundary = seg_boundary > 0\n","    #binary_seg_count = np.count_nonzero(binary_seg)\n","\n","    # Compare the convex hull of the segmentation with the segmentation itself\n","    chull_seg = convex_hull_image(binary_boundary)\n","    chull_seg_count = np.count_nonzero(chull_seg)\n","    # print('Convex Hull')\n","    # plt.imshow(chull_seg)\n","    # plt.show()\n","    #chull_seg_count = np.count_nonzero(chull_seg)\n","    # compare the convex hull to the segmentation\n","    comparison_with_seg = np.logical_and(binary_seg, chull_seg)\n","    # count the number of pixels appearing in both\n","    comparison_with_seg_count = np.count_nonzero(comparison_with_seg)\n","    #print(float(comparison_with_seg_count))\n","    #print(float(chull_seg_count))\n","    if (float(comparison_with_seg_count) / float(chull_seg_count)) > 0.95:\n","        # The colony segmentation appears to be approximately convex\n","        #print('Convex segmentation')\n","        is_approximately_convex = True\n","    else:\n","        #print('Not convex')\n","        is_approximately_convex = False\n","\n","    # Compare the colony semgation to a circle.\n","    filled_circle = create_filled_ellipse_in_array(seg, padding=0)\n","    filled_circle_count = np.count_nonzero(filled_circle)\n","    comparison_with_circle = np.logical_and(binary_seg, filled_circle)\n","    comparison_with_circle_count = np.count_nonzero(comparison_with_circle)\n","    if (float(comparison_with_circle_count) / float(filled_circle_count)) > 0.95:\n","        # The colony segmentation appears to be approximately convex\n","        #print('Circular')\n","        is_approximately_circular = True\n","    else:\n","        #print('Not circular')\n","        is_approximately_circular = False\n","\n","    return is_approximately_convex, is_approximately_circular\n","\n","# Condition 6: Compute the Hausdorff distance between the boundary\n","# segmentation and the enclosing circle.\n","# Ideally, we want the shape of the colony segmengtation to be very\n","# similar to a circle, because real coloies appear round.\n","\n","\n","def get_hausdorff_distance(seg, seg_boundary):\n","    \"\"\"Obtain the Hausdorff distance between the colony boundary and\n","    the circle and convex hull of the colony segmenation respectively.\"\"\"\n","\n","    #binary_seg = seg > 0\n","    binary_boundary = seg_boundary > 0\n","    # get convex hull of the boundary, and fill it.\n","    chull_seg = convex_hull_image(binary_boundary)\n","    chull_boundary = get_colony_boundary_binary(chull_seg)\n","    filled_circle = create_filled_ellipse_in_array(seg, padding=0)\n","    circle_boundary = get_colony_boundary_binary(filled_circle)\n","\n","    # Compute Hausdorff distance between colony boundary and circle\n","    dist_to_circle = hausdorff_distance(binary_boundary, circle_boundary)\n","\n","    # Compute Hausdorff distance between colony boundary and the boundary\n","    # of the segmentation's convex hull\n","    dist_to_chull = hausdorff_distance(binary_boundary, chull_boundary)\n","\n","    return dist_to_chull, dist_to_circle\n"]},{"cell_type":"markdown","metadata":{"id":"9ECOZTFqK9BP"},"source":["## Functions for Plotting"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lEQKkmuONYAK"},"outputs":[],"source":["def find_mode(my_array):\n","    \"\"\"First counts the number of times each unique element appears in a\n","    numpy array, and outputs the most frequent elements along with how\n","    many times those elements appear in the array.\"\"\"\n","\n","    vals, counts = np.unique(my_array, return_counts=True)\n","    index = np.argmax(counts)\n","    return vals[index], counts[index]\n","\n","\n","def get_count_breakdown(my_array):\n","    \"\"\"Counts the number of times each unique element appears in a numpy\n","    array, sorts the elemets from least to greatest, and counts how many\n","    times each elect appears in the array.\"\"\"\n","\n","    if len(my_array) > 0:\n","        vals, counts = np.unique(my_array, return_counts=True)\n","        max_val = np.max(vals)\n","        vals_list = list(vals)\n","        sorted_counts = []\n","        for i in range(0, max_val+1):\n","            this_val = vals_list.index(i)\n","            sorted_counts.append(counts[this_val])\n","        return np.array(sorted_counts)\n","\n","    return np.array([])\n","\n","\n","def extend_array(my_array, length):\n","    \"\"\"Takes an array as input and appends a specified number of zeros to the\n","    end of the array.\"\"\"\n","\n","    if my_array.size < length:\n","        some_zeros = length - my_array.size\n","        my_ext_array = np.append(\n","            my_array, np.zeros((1, some_zeros), dtype=int))\n","        return my_ext_array\n","\n","    return my_array\n","\n","\n","def get_sector_count_breakdown(my_array):\n","    \"\"\"Perfoems the same as `get_count_breakdown`, except this forces the\n","    function to start at 0 instead of the actual minimum value in the array.\n","    This should only be used when the array contains positive integers.\"\"\"\n","\n","    if len(my_array) > 0:\n","        vals, counts = np.unique(my_array, return_counts=True)\n","        max_val = np.max(vals)\n","        min_val = np.min(vals)\n","        if min_val != 0:\n","            no_counts = np.array([0 for i in range(0, min_val)])\n","            counts = np.append(no_counts, counts)\n","            no_vals = np.array(range(0, min_val))\n","            vals = np.append(no_vals, vals)\n","        vals_list = list(vals)\n","        sorted_counts = []\n","        print(counts)\n","        print(vals)\n","        print(vals_list)\n","        for i in range(0, max_val+1):\n","            this_val = vals_list.index(i)\n","            sorted_counts.append(counts[this_val])\n","        return np.array(sorted_counts)\n","\n","    return np.array([])\n","\n","\n","def addlabels_initial(x_coord, y_coord, fontsize):\n","    \"\"\"Adds label above, offset by 0.25 to the left.\"\"\"\n","\n","    for i in range(len(x_coord)):\n","        ax.text(i-(0.25), y_coord[i]+5, y_coord[i], ha='center',\n","                fontfamily=\"serif\", fontsize=fontsize)\n","\n","\n","def addlabels_prediction(x_coord, y_coord, fontsize):\n","    \"\"\"Adds label above.\"\"\"\n","\n","    for i in range(len(x_coord)):\n","        ax.text(i, y_coord[i]+5, y_coord[i], ha='center', fontfamily=\"serif\", fontsize=fontsize)\n","\n","\n","def addlabels_truemarks(x_coord, y_coord, fontsize):\n","    \"\"\"Adds label above offset by 0.25 to the right.\"\"\"\n","\n","    for i in range(len(x_coord)):\n","        ax.text(i+(0.25), y_coord[i]+5, y_coord[i], ha='center',\n","                fontfamily=\"serif\", fontsize=fontsize)\n","\n","\n","def addlabels_centered(x_coord, y_coord, fontsize):\n","    \"\"\"Adds label directly above regardless of x coordinate.\"\"\"\n","\n","    for i in range(len(x_coord)):\n","        ax.text(x_coord[i], y_coord[i]+5, y_coord[i], ha='center',\n","                fontfamily=\"serif\", fontsize=fontsize)\n","\n","\n","def addlabels_initial_ax(x_coord, y_coord, fontsize, this_axis):\n","    \"\"\"addlabels_initial but for a specific axis.\"\"\"\n","\n","    for i in range(len(x_coord)):\n","        ax[this_axis].text(i-(0.25), y_coord[i]+5, y_coord[i], ha='center',\n","                           fontfamily=\"serif\", fontsize=fontsize)\n","\n","\n","def addlabels_prediction_ax(x_coord, y_coord, fontsize, this_axis):\n","    \"\"\"addlabels_prediction but for a specific axis.\"\"\"\n","\n","    for i in range(len(x_coord)):\n","        ax[this_axis].text(i, y_coord[i]+5, y_coord[i], ha='center',\n","                           fontfamily=\"serif\", fontsize=fontsize)\n","\n","\n","def addlabels_truemarks_ax(x_coord, y_coord, fontsize, this_axis):\n","    \"\"\"addlabels_truemarks but for a specific axis.\"\"\"\n","\n","    for i in range(len(x_coord)):\n","        ax[this_axis].text(i+(0.25), y_coord[i]+5, y_coord[i], ha='center',\n","                           fontfamily=\"serif\", fontsize=fontsize)\n","\n","\n","def addlabels_centered_ax(x_coord, y_coord, fontsize, this_axis):\n","    \"\"\"addlabels_centered but for a specific axis.\"\"\"\n","\n","    for i in range(len(x_coord)):\n","        ax[this_axis].text(x_coord[i], y_coord[i]+5, y_coord[i], ha='center',\n","                           fontfamily=\"serif\", fontsize=fontsize)\n","\n","\n","def addlabels_prediction_ax_bytick(x_coord, y_coord, fontsize, this_axis):\n","    \"\"\"addlabels_initial but for a specific axis.\"\"\"\n","\n","    for i in range(len(x_coord)):\n","        ax[this_axis].text(x_coord[i], y_coord[i]+5, y_coord[i], ha='center',\n","                           fontfamily=\"serif\", fontsize=fontsize)\n","\n","\n","def addlabels_truemarks_ax_bytick(x_coord, y_coord, fontsize, this_axis):\n","    \"\"\"addlabels_truemarks but for a specific axis.\"\"\"\n","\n","    for i in range(len(x_coord)):\n","        ax[this_axis].text(x_coord[i]+(0.25), y_coord[i]+5, y_coord[i],\n","                           ha='center', fontfamily=\"serif\", fontsize=fontsize)\n","\n","\n","def addlabels_centered_ax_bytick(x_coord, y_coord, fontsize, this_axis):\n","    \"\"\"addlabels_centered but for a specific axis.\"\"\"\n","\n","    for i in range(len(x_coord)):\n","        ax[this_axis].text(x_coord[i], y_coord[i]+5, y_coord[i], ha='center',\n","                           fontfamily=\"serif\", fontsize=fontsize)\n"]},{"cell_type":"markdown","metadata":{"id":"okqItdw8RzPs"},"source":["# Get training images"]},{"cell_type":"markdown","metadata":{"id":"NYiHKhfbR05-"},"source":["## With sector count masks (Additional GLOBALS for directories)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KyPcLfgVR2ne"},"outputs":[],"source":["# Images for Training and validation\n","\n","# Get paths of training and validation sets\n","\n","TRAIN_PATH = IMAGE_FOLDER + '/train'\n","VAL_PATH = IMAGE_FOLDER + '/val'\n","\n","IMAGE_PATH = TRAIN_PATH + '/images/'\n","MASK_PATH = TRAIN_PATH + '/masks/'\n","SECTOR_COUNT_PATH = TRAIN_PATH + '/masks_sector_counts/'\n","#mask_boundary_path = train_path + '/masks_bw_boundary/'\n","VAL_IMAGE_PATH = VAL_PATH + '/images/'\n","VAL_MASK_PATH = VAL_PATH + '/masks/'\n","VAL_SECTOR_COUNT_PATH = VAL_PATH + '/masks_sector_counts/'\n","#val_mask_boundary_path = val_path + '/masks_bw_boundary/'\n","\n","# Get names of training images and masks\n","\n","my_images = glob.glob(IMAGE_PATH + '*.png')\n","my_masks = glob.glob(MASK_PATH + '*.png')\n","my_sector_counts = glob.glob(SECTOR_COUNT_PATH + '*.png')\n","my_val_images = glob.glob(VAL_IMAGE_PATH + '*.png')\n","my_val_masks = glob.glob(VAL_MASK_PATH + '*.png')\n","my_val_sector_counts = glob.glob(VAL_SECTOR_COUNT_PATH + '*.png')\n","\n","# Check that list length is the same\n","if (len(my_images) != len(my_masks)) | (len(my_images) != len(my_sector_counts)):\n","    raise ValueError(\n","        'The number of images in the train subdirectories are inconsistent.  Check that the numbe of images is the same in all train subdirectories.')\n","\n","if (len(my_val_images) != len(my_val_masks)) | (len(my_val_images) != len(my_val_sector_counts)):\n","    raise ValueError(\n","        'The number of images in the val subdirectories are inconsistent.  Check that the number of images is the same in all val subdirectories.')\n","\n","\n","# Check that all images used have the (image, mask, sector_count) tuple.\n","\n","for file in my_images:\n","    x = os.path.basename(file)\n","    #print(mask_path + x)\n","    if not os.path.exists(MASK_PATH + x):\n","        raise NameError('Training mask not found for image ' + IMAGE_PATH + x)\n","    if not os.path.exists(SECTOR_COUNT_PATH + x):\n","        raise NameError(\n","            'Training sector count mask not found for image ' + IMAGE_PATH + x)\n","\n","for file in my_masks:\n","    x = os.path.basename(file)\n","    #print(mask_path + x)\n","    if not os.path.exists(IMAGE_PATH + x):\n","        raise NameError('Training image not found for mask ' + MASK_PATH + x)\n","    if not os.path.exists(SECTOR_COUNT_PATH + x):\n","        raise NameError(\n","            'Training sector count mask not found for mask ' + MASK_PATH + x)\n","\n","for file in my_sector_counts:\n","    x = os.path.basename(file)\n","    #print(mask_path + x)\n","    if not os.path.exists(IMAGE_PATH + x):\n","        raise NameError(\n","            'Training image not found for sector count mask ' + SECTOR_COUNT_PATH + x)\n","    if not os.path.exists(MASK_PATH + x):\n","        raise NameError(\n","            'Training mask not found for sector count mask ' + SECTOR_COUNT_PATH + x)\n","\n","# Get names of validation images and masks\n","\n","for file in my_val_images:\n","    x = os.path.basename(file)\n","    #print(mask_path + x)\n","    if not os.path.exists(VAL_MASK_PATH + x):\n","        raise NameError(\n","            'Validation mask not found for image ' + VAL_IMAGE_PATH + x)\n","    if not os.path.exists(VAL_SECTOR_COUNT_PATH + x):\n","        raise NameError(\n","            'Validation sector count mask not found for image ' + VAL_IMAGE_PATH + x)\n","\n","for file in my_val_masks:\n","    x = os.path.basename(file)\n","    #print(mask_path + x)\n","    if not os.path.exists(VAL_IMAGE_PATH + x):\n","        raise NameError(\n","            'Validation image not found for mask ' + VAL_MASK_PATH + x)\n","    if not os.path.exists(VAL_SECTOR_COUNT_PATH + x):\n","        raise NameError(\n","            'Validation sector count mask not found for mask ' + VAL_MASK_PATH + x)\n","\n","for file in my_val_sector_counts:\n","    x = os.path.basename(file)\n","    #print(mask_path + x)\n","    if not os.path.exists(VAL_IMAGE_PATH + x):\n","        raise NameError(\n","            'Validation image not found for sector count mask ' + VAL_SECTOR_COUNT_PATH + x)\n","    if not os.path.exists(VAL_MASK_PATH + x):\n","        raise NameError(\n","            'Validation mask not found for sector count mask ' + VAL_SECTOR_COUNT_PATH + x)\n","\n","#file_list = os.listdir(root + '/images/*.png')\n","print('Image locations checked and grouped.')\n","\n","# What the above does is this:\n","# my_images and my_masks are the training images and correspodning training masks respectively.\n","# my_val_images and my_val_masks are the validation images and validation masks respectively.\n","# This checks to see if all the images and masks have corresponding pairs.\n","# If this part results in an error, do not continue until the error is resolved."]},{"cell_type":"markdown","metadata":{"id":"yVbA7O4nR3aJ"},"source":["## Without sector count masks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bWtZ1QVegyKw"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"ppa0h-P2gygj"},"source":["# Build U-net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lb5js6rig0LC"},"outputs":[],"source":["# See summary for a 1024x1024x3 image\n","model = build_unet((1024, 1024, 3), 3)\n","model.summary()\n","\n","# This function is not used in the paper\n","\n","\n","def my_schedule(epoch, learning_rate):\n","    \"\"\"Function to reduce learning rate by a factor of 10 every 10 epochs.\"\"\"\n","\n","    if ((epoch % 10) == 0) and (epoch != 0):\n","        print('Reducing learning rate by factor of 10.  New learning rate is', lr*0.1)\n","        return learning_rate * 0.1\n","\n","    return learning_rate\n","\n","# Class fucntion to call when requesting test segmenetations during training\n","\n","\n","class MyCallback(tf.keras.callbacks.Callback):\n","    \"\"\"Class for functions to run for generating callbacks during training.\"\"\"\n","\n","    def on_epoch_end(self, epoch, logs=None):\n","        \"\"\"Modifying function to print test segmenation at the end\n","        of each eopch.\"\"\"\n","\n","        print('Getting test segmentations.')\n","        # Load test images and predict with model\n","\n","        # Image a (mostly cured + sectored example)\n","        x_image = read_image(REAL_IMAGE_FOLDER + '/' + IMAGE_TO_TEST_WITH)\n","        p_image = model.predict(np.expand_dims(x_image, axis=0))[0]\n","        p_image = np.argmax(p_image, axis=-1)\n","        p_image = np.expand_dims(p_image, axis=-1)\n","        p_image = p_image * (255/(NUM_CLASSES-1))\n","        p_image = p_image.astype(np.uint8)\n","        my_image = PIL.Image.fromarray(np.squeeze(p_image, axis=-1), \"L\")\n","        my_image.save(TEST_PER_EPOCH_FOLDER + '/a_' + str(epoch) + '.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7aa2V62yg40C"},"outputs":[],"source":["# Compile model\n","model = build_unet(SHAPE, NUM_CLASSES)\n","\n","# used in paper\n","# Method uses\n","# Categorcial cross-entropy for the loss function\n","# Adam optimization function\n","# Basic accuracy metric which checks the proportion of pixels laebled as correct.\n","model.compile(loss=\"categorical_crossentropy\",\n","              optimizer=tf.keras.optimizers.Adam(LR), metrics=['accuracy'])\n","\n","# Not used in paper\n","#model.compile(loss=\"categorical_crossentropy\",\n","# optimizer=tf.keras.optimizers.Adam(lr),\n","# metrics=[tf.keras.metrics.CategoricalAccuracy()])\n","\n","# Set up function that gathers the images\n","train_dataset = tf_dataset(my_images, my_masks, batch=BATCH_SIZE)\n","val_dataset = tf_dataset(my_val_images, my_val_masks, batch=BATCH_SIZE)\n","\n","# Estimate how many batches of data are need to complete 1 epoch\n","train_steps = len(my_images)//BATCH_SIZE\n","val_steps = len(my_val_images)//BATCH_SIZE\n","\n","# Set callbacks during the training process\n","if PRINT_TEST_SEGS is True:\n","\n","    # Includes the functions defined in the previous cell for printing a\n","    # segmentation of specific test image at each epoch.\n","    # Save model weights at each epoch, only keeping the best weights\n","    # Learning rate decreases upon reaching a local minimum in validation loss\n","    # Training stops automatically when validation loss does not decrease\n","    # any more than 0.001 after 5 epochs.\n","    # Training will stop automatically after reaching the maximum number\n","    # of epochs.\n","    callbacks = [\n","        ModelCheckpoint(WEIGHTS_FOLDER + '/' + WEIGHTS_FILE + '.h5',\n","                        verbose=1, save_best_model=True, save_weights_only=False),\n","        MyCallback(),\n","        LearningRateScheduler(my_schedule),\n","        ReduceLROnPlateau(monitor=\"val_loss\", patience=3,\n","                          factor=0.1, verbose=1, min_lr=MIN_LR),\n","        EarlyStopping(monitor=\"val_loss\", min_delta=0.001,\n","                      patience=5, verbose=1)\n","    ]\n","else:\n","    # Save model weights at each epoch, only keeping the best weights\n","    # Learning rate decreases upon reaching a local minimum in validation loss\n","    # Training stops automatically when validation loss does not decrease any\n","    # more than 0.001 after 5 epochs.\n","    # Training will stop automatically after reaching the maximum number\n","    # of epochs.\n","    callbacks = [\n","        ModelCheckpoint(WEIGHTS_FOLDER + '/' + WEIGHTS_FILE + '.h5',\n","                        verbose=1, save_best_model=True, save_weights_only=False),\n","        ReduceLROnPlateau(monitor=\"val_loss\", patience=3,\n","                          factor=0.1, verbose=1, min_lr=MIN_LR),\n","        EarlyStopping(monitor=\"val_loss\", min_delta=0.001,\n","                      patience=5, verbose=1)\n","    ]\n","\n","\n","# For training up until the maxmum number of epochs specified\n","# callbacks = [\n","#              ModelCheckpoint(weights_folder + '/' + weights_file + '.h5', verbose=1, save_best_model=True, save_weights_only=False),\n","#              ReduceLROnPlateau(monitor=\"val_loss\", patience=3, factor=0.1, verbose=1, min_lr=1e-8)\n","# ]\n"]},{"cell_type":"markdown","metadata":{"id":"JKSusIvghEHj"},"source":["# Train U-Net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i_eetjS2g-Qm"},"outputs":[],"source":["# This part attempts to defien the Weights in the model\n","# NOTE: If youn are using the full U-Net impletnatinos in this paper,\n","# you must have access to a GPU or the runtime will crash due to high RAM usage.\n","if TRAIN_MODEL is True:\n","    # train the model\n","    history = model.fit(train_dataset,\n","                        steps_per_epoch=train_steps,\n","                        validation_data=val_dataset,\n","                        validation_steps=val_steps,\n","                        epochs=EPOCHS,\n","                        callbacks=callbacks)\n","    print(history.history.keys())\n","\n","    # Plot the results of training\n","    # This code was taken from\n","    # https://machinelearningmastery.com/display-deep-learning-model-training-history-in-keras/\n","\n","    # summarize history for accuracy\n","    plt.plot(history.history['categorical_accuracy'])\n","    plt.plot(history.history['val_categorical_accuracy'])\n","    plt.title('Model Accuracy on Synthetic Images')\n","    plt.ylabel('Accuracy')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Training', 'Validation'], loc='center right')\n","    plt.show()\n","\n","    # summarize history for loss\n","    plt.plot(history.history['loss'])\n","    plt.plot(history.history['val_loss'])\n","    plt.title('Model Loss on Synthetic Images')\n","    plt.ylabel('Loss')\n","    plt.xlabel('Epoch')\n","    plt.legend(['Training', 'Validation'], loc='center right')\n","    plt.show()\n","\n","    with open(WEIGHTS_FOLDER + '/accuracy_loss_' + str(NUM_CLASSES) + '.pkl', 'wb') as file:\n","        #file_handle = open(WEIGHTS_FOLDER + '/accuracy_loss_' +\n","        #                   str(NUM_CLASSES) + '.pkl', 'wb')\n","        pickle.dump([history.history['categorical_accuracy'], history.history['val_categorical_accuracy'],\n","                     history.history['loss'], history.history['val_loss']], file)\n","    #file_handle.close()"]},{"cell_type":"markdown","metadata":{"id":"iSVlxwKRjRty"},"source":["# Load Trained U-Net"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mxe-01oqjUOM"},"outputs":[],"source":["model = tf.keras.models.load_model(WEIGHTS_FOLDER + '/' + WEIGHTS_FILE + '.h5')"]},{"cell_type":"markdown","metadata":{"id":"IpFYnY54NPbJ"},"source":["# Segmentation and Classification of Training Images"]},{"cell_type":"markdown","metadata":{"id":"CbQdR6A_NPbJ"},"source":["## Get names of images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tY9HCTWlNPbJ"},"outputs":[],"source":["# Get paths of training and validation images and sort them.\n","training_images_train = sorted(glob.glob(TRAINING_IMAGE_SET + '/' + '*'))\n","training_images_val = sorted(glob.glob(VALIDATION_IMAGE_SET + '/' + '*'))\n","training_images = sorted(training_images_train + training_images_val)\n","print('Number of images found: ' + str(len(training_images)))"]},{"cell_type":"markdown","metadata":{"id":"fM4j1efJNPbK"},"source":["## Segment Training Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nNSXOXT0NPbK"},"outputs":[],"source":["# Commented out IPython magic to ensure Python compatibility.\n","# Code for image segmentation (involves Python and Octave code (requires oct2py module))\n","# 1. Python - Ready u_net for input.\n","# 2. Python - Feed image to U-Net.\n","# 3. Python - Get output segmentation of image.\n","# 4. Octave - Use isolated colonies to estimate a range of radii to search for circular colonies.\n","# 5. Octave - Obtain centers and radii in image with circle Hough transform.\n","# 6. Octave (or Python maybe pandas) - Save csv files of circle locations\n","# and sizes in each image respectively.\n","# 7. Octave (or Python maybe matplotlib) - Make mask of image showing\n","  #where the circles are found.\n","# 8. Repeat steps 2-7 for each image\n","\n","if GET_TRAINING_SEGS is True:\n","\n","    #     %matplotlib inline\n","\n","    for this_image in training_images:\n","\n","        # Steps 1-3: get output segmentation and save it\n","\n","        this_plate = pathlib.PurePath(this_image)\n","        plate_name = this_plate.name\n","\n","        print('Reading plate: ' + str(plate_name))\n","\n","        x = read_image(this_image)\n","\n","        # Predict the class of each pixel, and partition output the same way\n","        p = model.predict(np.expand_dims(x, axis=0))[0]\n","        p = np.argmax(p, axis=-1)\n","        p = np.expand_dims(p, axis=-1)\n","        p = p * (255/(NUM_CLASSES-1))\n","        print(p.shape)\n","        \n","        #print(np.max(p))\n","        p = p.astype(np.int64)\n","        print(np.unique(p))\n","        #print(np.max(p))\n","\n","        if SWAP_CLASS_LABELS is True:\n","            p = swap_class_labels(p, 127, 255)\n","\n","        p_full = tf.identity(p).numpy()\n","        in_class = tf.math.greater(tf.constant(\n","            p_full), tf.constant([0], dtype=tf.int64)).numpy()\n","\n","        p = p.astype(np.uint8)\n","\n","        # Make sure that white pixels are whiete and red pxels are gray\n","\n","        \n","            \n","        # white pixels (should be 255)\n","        p_1 = tf.math.equal(tf.constant(p_full),\n","                            tf.constant([255], dtype=tf.int64)).numpy().astype(np.uint8) * 255\n","        # red pixels (should be 127)\n","        p_2 = tf.math.equal(tf.constant(p_full),\n","                            tf.constant([127], dtype=tf.int64)).numpy().astype(np.uint8) * 255\n","\n","\n","        p_full = 255 * in_class.astype(np.uint8)\n","        #print(p.shape)\n","\n","        #cv2_imshow(p)\n","\n","        # Show and/or save image\n","        #plt.imshow(p * 255/(num_classes-1))\n","        #cv2.cvtColor(p * 255/(num_classes-1), cv2.COLOR_BGR2RGB)\n","        #plt.imshow(cv2.cvtColor(p * 255/(num_classes-1), cv2.COLOR_BGR2GRAY))\n","        #plt.imshow(p, cmap='binary')\n","        #plt.show()\n","        #print(np.unique(p[20:40, 900:920]))\n","        my_image = PIL.Image.fromarray(np.squeeze(p, axis=-1), \"L\")\n","        #display(my_image.resize((256,256)))\n","        my_image.save(TRAIN_SEG_FOLDER + '/' + this_plate.stem + '.png')\n","\n","        # Steps 4-6: Run Matlab code in Octave to use CHT, and\n","        # store colony location data\n","        octave.feval('get_circular_data.m', this_image, TRAIN_SEG_FOLDER +\n","                     '/' + this_plate.stem + '.png', TRAIN_CIRCLE_DATA_FOLDER)\n","        try:\n","            radii_table = pd.read_csv(\n","                TRAIN_CIRCLE_DATA_FOLDER + '/' + this_plate.stem + '.csv', header=None)\n","            radii_table.columns = ['Colony', 'Center (x)', 'Center (y)', 'Radius',\n","                                   'Top Left (x)', 'Top Left (y)', 'Width',\n","                                   'Height', 'Estimated Center (x)',\n","                                   'Estimated Center (y)']\n","            radii_table.to_csv(TRAIN_CIRCLE_DATA_FOLDER +\n","                               '/' + this_plate.stem + '.csv')\n","\n","            # Step 7: Plot the image with the circles overlayed, and save it\n","            #radii_table = pd.read_csv(TEST_CIRCLE_DATA_FOLDER + '/' + this_plate.stem + '.csv')\n","\n","            fig, ax = plt.subplots()\n","            plt.imshow(cv2.cvtColor(x, cv2.COLOR_BGR2RGB))\n","            fig.set_size_inches(1024/96, 1024/96)\n","            for index, row in radii_table.iterrows():\n","                full_circle = Circle((row['Estimated Center (x)'], row['Estimated Center (y)']),\n","                                     radius=row['Radius'], color='blue',\n","                                     fill=False, linewidth=1, alpha=0.9)\n","                ax.add_patch(full_circle)\n","            plt.axis('off')\n","            plt.savefig(TRAIN_CIRCLE_FOLDER + '/' + pathlib.Path(this_image).stem +\n","                        '.jpg', bbox_inches='tight', pad_inches=0)\n","            plt.close()\n","\n","        except pd.errors.EmptyDataError:\n","            # If an error is about to be thrown due to an empty csv file,\n","            # run these lines instead\n","            print('No colonies were detected.  Skipping this image.')\n","            my_table_columns = ['Colony', 'Center (x)', 'Center (y)', 'Radius', 'Top Left (x)',\n","                                'Top Left (y)', 'Width', 'Height',\n","                                'Estimated Center (x)',\n","                                'Estimated Center (y)']\n","            radii_table = pd.DataFrame(columns=my_table_columns)\n","            radii_table.to_csv(TRAIN_CIRCLE_DATA_FOLDER +\n","                               '/' + this_plate.stem + '.csv')\n","\n","            # Step 7: Plot the image with the circles overlayed, and save it\n","            #radii_table = pd.read_csv(test_circle_data_folder + '/' + this_plate.stem + '.csv')\n","\n","            fig, ax = plt.subplots()\n","            plt.imshow(cv2.cvtColor(x, cv2.COLOR_BGR2RGB))\n","            # set because the screen pixel size is 96 dpi\n","            fig.set_size_inches(1024/96, 1024/96)\n","            plt.axis('off')\n","            plt.savefig(TRAIN_CIRCLE_FOLDER + '/' + pathlib.Path(this_image).stem +\n","                        '.jpg', bbox_inches='tight', pad_inches=0)\n","            plt.close()\n","        #print(radii_table)\n","        #raise FileExistsError('The script finished without errors.')\n","        #octave.run('octave_test.m')\n"]},{"cell_type":"markdown","metadata":{"id":"s3AuozRhNPbK"},"source":["## Create dictionary for reference to images, and make directories to store things per plate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RvqRrXJiNPbK"},"outputs":[],"source":["training_images_train = sorted(glob.glob(TRAINING_IMAGE_SET + '/' + '*'))\n","training_images_val = sorted(glob.glob(VALIDATION_IMAGE_SET + '/' + '*'))\n","training_images = sorted(training_images_train + training_images_val)\n","print('Number of images found: ' + str(len(training_images)))\n","\n","training_CHT_images = sorted(glob.glob(TRAIN_CIRCLE_FOLDER + '/' + '*'))\n","print('Number of images found: ' + str(len(training_CHT_images)))\n","\n","training_image_pairs = tuple(zip(training_images, training_CHT_images))\n","print(training_image_pairs)\n","\n","\n","# Create reference table for plate names, and store it as a csv file in\n","# the main annotation directory\n","file_dict = {}\n","for this_plate_number in range(1, len(training_images)+1):\n","    this_plate = pathlib.PurePath(training_images[this_plate_number - 1])\n","    plate_name = this_plate.name\n","    plate_stem = os.path.splitext(plate_name)[0]\n","    file_dict[plate_name] = 'Plate ' + str(this_plate_number)\n","print(file_dict)\n","file_items = file_dict.items()\n","file_list = list(file_items)\n","file_df = pd.DataFrame(file_items, columns = ['Plate Name', 'Folder Name'])\n","print(file_df)\n","\n","\n","# If you are trying to save the crops and annotations of each colony,\n","# the below will run as well.\n","\n","if SAVE_ALL_ANNOTATIONS is True:\n","\n","    # Save this table as a csv file\n","    file_df.to_csv(OUTPUT_CROPS_FOLDER + '/Plate_References.csv')\n","\n","    for index, row in file_df.iterrows():\n","\n","        # Make subdirectories for each annotation class, organized by plate\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/raw/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/raw/' + row['Folder Name'])\n","            # where the original colonies are cropped and stored\n","\n","        if USE_EXPERT_COUNTS is True:\n","            if not os.path.exists(OUTPUT_CROPS_FOLDER + '/counted/' + row['Folder Name']):\n","                os.makedirs(OUTPUT_CROPS_FOLDER + '/counted/' + row['Folder Name'])\n","                # where the original quantifiable colonies are cropped and stored\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/circles/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/circles/' + row['Folder Name'])\n","            # same as before, but a circle is overlayed on the colony\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/segs/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/segs/' + row['Folder Name'])\n","            # the output from the U-Net segmentation such that only\n","            # nonzero pixels in the circle are kept\n","\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/init_regions/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/init_regions/' + row['Folder Name'])\n","            # A segmentation outlining the possible sector-like regions\n","            # of the colony, both red and white\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/init_bounds/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/init_bounds/' + row['Folder Name'])\n","            # The raw segmentation containing only the boundary of the colony\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/init_partitions/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/init_partitions/' + row['Folder Name'])\n","            # same as the raw segmentation, but with lines annotated\n","            # to represent locations of sector borders\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/init_bad/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/init_bad/' + row['Folder Name'])\n","            # A segmentation outlining the sector-like regions that\n","            # failed the consistency check\n","\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_segs/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_segs/' + row['Folder Name'])\n","            # the output from the U-Net segmentation such that only\n","            # nonzero pixels in the circle are kept\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_bounds/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_bounds/' + row['Folder Name'])\n","            # The corrected segmentation containing only the boundary of the colony\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_regions/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_regions/' + row['Folder Name'])\n","            # the output from the U-Net segmentation such that only\n","            # nonzero pixels in the circle are kept\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_partitions/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_partitions/' + row['Folder Name'])\n","            # same as the raw segmentation, but with lines annotated\n","            # to represent locations of sector borders\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_bad/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_bad/' + row['Folder Name'])\n","            # A segmentation outlining the sector-like regions that failed\n","            # the consistency check\n","\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/sectors/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/sectors/' + row['Folder Name'])\n","            # the output containing the regions in the segmentation where\n","            # a sector is predicted\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/sector_comps/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/sector_comps/' + row['Folder Name'])\n","            # same as before, but only red pxieks in the segmentation are considered\n"]},{"cell_type":"markdown","metadata":{"id":"DqlGDEnpNPbL"},"source":["## Classify Colonies in Training Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WWE9W8V5NPbL"},"outputs":[],"source":["# Code for colony classification (this should be all python code)\n","# 1. Read in image and corresponding segmentation.\n","# 2. Read in csv files containing circle locations.\n","# 3. For each row in the csv file, crop out the circular region, estimate size.\n","# 4. Restrict data collection to pixels within the circle detected, exclusing all other pixels.\n","# 5. Split the components of the image into red, white and background.\n","# 6. Get boundary components of the colony, check for consistency.\n","# 7. Output predicted number of sectors and their sizes after the consistency check.\n","# 8. Save the cropping of the colony in a few ways:\n","#   - the raw colony\n","#   - the raw colony with circle overlayed\n","#   - the segmentation of the colony within the circular region\n","#   - the segmentation of the colony with lines drawn on the image to repreent sector borders\n","#   - the predicted sector like regions, where each sector is a different shade of gray.\n","#   - similar to the previous, but keeping pixels classified only as red pixels.\n","#   - the segmentation that is corrected following the consistency check\n","#     (possibly doing an additional check on the white pixels)\n","# 9. Save data on the colony itself, including the sector information,\n","#    to a row in a table.\n","# 10. Save the table to a csv file.\n","# 11. Repeat all steps above for each image.\n","\n","# Issues to work on:\n","# Verify that the purity metric is properly being utilized\n","# Figure out what to do with the holes inside colony segmentations.\n","#   -- A hole has its own boundary, so could look for the boundary of the hole.\n","#   -- The boundary of the hole MUST be smaller than the boundary of the entire colony\n","#   -- Find all connected compoents of the boundary, then exclude the LARGEST one.\n","#   -- For all other boundary components, these are expected to be the holes.\n","#      You need a procedure to fill them.\n","#   -- The procedure could be as simple as filling the hole with the class\n","#      pertaining to the most common pixel on the boundary.\n","\n","# Implementation already existing:\n","\n","\n","if CLASSIFY_TRAINING_COLONIES is True:\n","\n","    #     %matplotlib inline\n","\n","    starting_image = True\n","\n","    if USE_EXPERT_COUNTS is True:\n","        dot_quant_images = sorted(\n","            glob.glob(ADDITIONAL_DATA_FOLDER + '/Quant/' + '*'))\n","        dot_state_images = sorted(\n","            glob.glob(ADDITIONAL_DATA_FOLDER + '/State/' + '*'))\n","\n","    # Run each plate through the classification pipeline\n","\n","    for (train_image, CHT_image) in training_image_pairs:\n","\n","        # Get plate name\n","        this_plate = pathlib.PurePath(train_image)\n","        plate_name = this_plate.name\n","        plate_stem = os.path.splitext(plate_name)[0]\n","\n","        print('Plate: ' + str(plate_name) + ':')\n","        if SAVE_ALL_ANNOTATIONS is True:\n","            print('Annotations will be saved within subfolders named ' +\n","                  \"\\'\" + file_dict[plate_name] + \"\\'\")\n","\n","        # Read images of the plate\n","        x = read_image(train_image)\n","        x_CHT = read_image(CHT_image)\n","\n","        # initialize lists for storing values\n","        all_cropped_colonies = []\n","\n","        # Sizes of regions in pixels\n","        white_region_sum = []\n","        red_region_sum = []\n","        colony_region_sum = []\n","        sector_region_sum = []\n","\n","        corrected_white_region_sum = []\n","        corrected_red_region_sum = []\n","        corrected_sector_region_sum = []\n","\n","        true_white_region_sum = []\n","        true_red_region_sum = []\n","        true_colony_region_sum = []\n","        true_sector_region_sum = []\n","\n","        # Counting sectors\n","        initial_region_counts = []\n","        all_sector_counts = []\n","        true_sector_counts = []\n","\n","        boundary_region_sum = []\n","        colony_prop_sum = []\n","\n","        # Purity scores for regions and colonies\n","        average_sector_score = []\n","        average_sector_iou = []\n","\n","        weighted_sector_score_before = []\n","        weighted_red_sector_score_before = []\n","        weighted_white_sector_score_before = []\n","\n","        weighted_sector_score_after = []\n","        weighted_red_sector_score_after = []\n","        weighted_white_sector_score_after = []\n","\n","        # Bounding box info for colonies in images\n","        sides_vert_top = []\n","        sides_vert_bottom = []\n","        sides_horz_left = []\n","        sides_horz_right = []\n","\n","        # Test lists\n","        colony_is_connected = []\n","        colony_is_approx_connected = []\n","        boundary_is_connected = []\n","        colony_is_whole = []\n","        boundary_is_hamilton = []\n","        colony_is_approx_convex = []\n","        colony_is_approx_circular = []\n","        hausdorff_dist_convex = []\n","        hausdorff_dist_circle = []\n","\n","        # Lists to store purity scores of each region and the color of the region\n","        region_purity_before = []\n","        region_color_before = []\n","        region_sizes_before = []\n","\n","        weighted_purity_before = []\n","        weighted_purity_red_before = []\n","        weighted_purity_white_before = []\n","\n","        region_purity_after = []\n","        region_color_after = []\n","        region_sizes_after = []\n","\n","        weighted_purity_after = []\n","        weighted_purity_red_after = []\n","        weighted_purity_white_after = []\n","\n","        cured_colony_before = []\n","        cured_colony_after = []\n","\n","        stable_colony_before = []\n","        stable_colony_after = []\n","\n","        # Load images here if using quantifable colony data/annotations\n","        if USE_EXPERT_COUNTS is True:\n","            x_quant = read_image(ADDITIONAL_DATA_FOLDER +\n","                                 '/Quant/' + plate_stem + '.tif')\n","            x_state = read_image(ADDITIONAL_DATA_FOLDER +\n","                                 '/State/' + plate_stem + '.tif')\n","            quantifiable_colony = []\n","            quantifiable_cured = []\n","            quantifiable_stable = []\n","            quantifiable_sectored = []\n","\n","        #------------------------------\n","        # Read in plate and locate colonies\n","        #------------------------------\n","\n","        # Read the segmentation of the plate, and keep track of which class each pixel belongs to\n","        p = read_mask(TRAIN_SEG_FOLDER + '/' + this_plate.stem + '.png')\n","\n","        p_full = tf.identity(p).numpy()\n","        in_class = tf.math.greater(tf.constant(\n","            p_full), tf.constant([0])).numpy()\n","\n","        p = p.astype(np.uint8)\n","        # white pixels\n","        p_1 = tf.math.equal(tf.constant(p_full), tf.constant(\n","            [255])).numpy().astype(np.uint8) * 255\n","        # red pixels\n","        p_2 = tf.math.equal(tf.constant(p_full), tf.constant(\n","            [127])).numpy().astype(np.uint8) * 255\n","        p_full = 255 * in_class.astype(np.uint8)\n","\n","        # Gather the location and radii data from the colonies\n","        # If there are no colonies detected, or there is no table, skip this section at once\n","\n","        colony_locations = pd.read_csv(\n","            TRAIN_CIRCLE_DATA_FOLDER + '/' + pathlib.Path(train_image).stem + '.csv')\n","\n","        # Output information from the imported csv\n","        print(str(len(colony_locations[\"Radius\"])) +\n","              ' colonies found using circle Hough transform')\n","        plate_names = np.repeat(plate_name, len(colony_locations[\"Radius\"]))\n","        colony_numbers = np.array(range(len(colony_locations[\"Radius\"])))\n","\n","        #---------------------------------------------------------------------\n","\n","        # CLASSIFICATION PIPELINE START\n","        # Pre-processing step\n","\n","        # Images to save:\n","        # - Cropping of the colony\n","        # - Cropping of the colony with the overalyed circle\n","        # - Original colony segmentation, such that only the pixels inside\n","        #   the overlayed circle are considered.\n","\n","        for this_index in range(0, len(colony_numbers)):\n","\n","            print('')\n","            print('Colony ' + str(this_index))\n","            # get example image using bounding indices\n","            #this_index = 2\n","\n","            # Copy location data from colony image\n","            top_left_x = colony_locations[\"Top Left (x)\"][this_index]\n","            top_left_y = colony_locations[\"Top Left (y)\"][this_index]\n","            box_width = colony_locations[\"Width\"][this_index]\n","            box_height = colony_locations[\"Height\"][this_index]\n","\n","            # Store the locations in another set of lists\n","            sides_vert_top.append(top_left_y)\n","            sides_vert_bottom.append(top_left_y + box_height - 1)\n","            sides_horz_left.append(top_left_x)\n","            sides_horz_right.append(top_left_x + box_width - 1)\n","\n","            # Grab segmentation of colony using coordinates copied above\n","            # The colony image is NOT a boolean array\n","            colony_image = p[(top_left_y-1):(top_left_y + box_height - 1),\n","                             (top_left_x-1):(top_left_x + box_width - 1)]\n","            ellipse_array = create_filled_ellipse_in_array(colony_image)\n","            # unpadded segmentation with the pixels inside the overlayed circle\n","            colony_image = np.multiply(colony_image, ellipse_array)\n","\n","            if USE_EXPERT_COUNTS is True:\n","                quant_image = x_quant[(top_left_y-1):(top_left_y + box_height - 1),\n","                                      (top_left_x-1):(top_left_x + box_width - 1), :]\n","                state_image = x_state[(top_left_y-1):(top_left_y + box_height - 1),\n","                                      (top_left_x-1):(top_left_x + box_width - 1), :]\n","\n","            # The colony mask IS a boolean array.  Keep all the pixels of each class.\n","            white_colony_mask = p_1[(top_left_y-1):(top_left_y + box_height - 1),\n","                                    (top_left_x-1):(top_left_x + box_width - 1)] > 0\n","            red_colony_mask = p_2[(top_left_y-1):(top_left_y + box_height - 1),\n","                                  (top_left_x-1):(top_left_x + box_width - 1)] > 0\n","            # sanity check to see of this is the same as colony image\n","            colony_mask = np.logical_or(white_colony_mask, red_colony_mask)\n","\n","            # Add segmentation of the pixels inside the circular region of\n","            # detection, and apply the mask.  This ensures we only\n","            # use the pixels inside the circle for analysis.\n","            # Booleans are inputs, and booleans are outputs\n","            # Force a circle in colonies detected in the circle detection step\n","            white_colony_mask = np.multiply(white_colony_mask, ellipse_array)\n","            red_colony_mask = np.multiply(red_colony_mask, ellipse_array)\n","            colony_mask = np.logical_or(white_colony_mask, red_colony_mask)\n","\n","            # Get initial measure of the sizes of the red and white regions\n","            # of the colony\n","            white_region_sum.append(np.sum(white_colony_mask))\n","            red_region_sum.append(np.sum(red_colony_mask))\n","            colony_region_sum.append(np.sum(colony_mask))\n","            sector_region_sum.append(\n","                np.sum(red_colony_mask) / np.sum(colony_mask))\n","\n","            # Find colony boundaries, ensuring that the boundaries are ON\n","            # the colony, not ADJACENT to it.\n","            edge_mask_unpadded = get_colony_boundary_binary(\n","                colony_image)  # The function is above\n","            # Second mask containing only the interior pixels of the segmentation\n","            interior_mask_unpadded = np.logical_xor(\n","                colony_image > 0, edge_mask_unpadded)\n","            interior_colony = np.multiply(\n","                colony_image, interior_mask_unpadded)  # This is NOT a boolean\n","\n","            #---------------------------------------------------------------\n","            # Get quantifiable colony labels (if applicable)\n","            #---------------------------------------------------------------\n","\n","            # If we have locations of quantifiable colonies, use this to gather the colonies.\n","            if USE_EXPERT_COUNTS is True:\n","                #----------------------------------\n","                # Determine where the quantifiable colonies are (they have black dots on them)\n","                # Set color boundaries for the markers in the counted images\n","                black_dot_boundaries = [([0, 0, 0], [5, 5, 5])]\n","\n","                for (lower, upper) in black_dot_boundaries:\n","                    # create NumPy arrays from the boundaries\n","                    lower = np.array(lower, dtype=\"uint8\")\n","                    upper = np.array(upper, dtype=\"uint8\")\n","                    # find the colors within the specified boundaries and apply\n","                    # the mask\n","                    dot_mask = cv2.inRange(\n","                        (quant_image*255).astype(np.uint8), lower, upper)\n","                    #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n","                    # Get connected components of the detected pixels\n","                    black_labels = label(dot_mask)\n","                    num_black_labels = len(np.unique(black_labels))\n","                    if num_black_labels <= 1:\n","                        # No dot was detected.  Thus the colony was considered non-quantifiable.\n","                        colony_is_quantifiable = False\n","                    else:\n","                        # Loop through each component.  Find one component\n","                        # that is not too small and is directly on the colony\n","                        colony_center_y = (quant_image.shape[0] - 1) / 2.0\n","                        colony_center_x = (quant_image.shape[1] - 1) / 2.0\n","                        for this_comp in range(1, num_black_labels):\n","                            this_dot_comp = black_labels == this_comp\n","                            # Get centroid of component\n","                            (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(\n","                                this_dot_comp)\n","                            dot_dist = math.sqrt(\n","                                ((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n","                            if dot_dist < colony_locations[\"Radius\"][this_index]:\n","                                colony_is_quantifiable = True\n","                                break\n","                                # end the loop, as we found a dot on the colony\n","\n","                            if this_comp == (num_black_labels - 1):\n","                                # We looped through all the dots, but none of\n","                                # them were on the colony.  Don't analyze\n","                                # this colony.\n","                                colony_is_quantifiable = False\n","\n","                quantifiable_colony.append(colony_is_quantifiable)\n","\n","                #print('Colony', this_index, ': Quantifiable:', colony_is_quantifiable)\n","\n","                #----------------------------------------\n","                # Determine if colony is cured, stable, or sectored\n","\n","                # RGB version\n","                # cured_dot_boundaries = [([34-5, 177-5, 76-5], [34+5, 177+5, 76+5])]\n","                # stable_dot_boundaries = [([237-5, 28-5, 36-5], [237+5, 28+5, 36+5])]\n","                # sectored_dot_boundaries = [([63-5, 72-5, 204-5], [63+5, 72+5, 204+5])]\n","\n","                # BGR version (cv2 needs this)\n","                # Marker colors were manaully chosen, so info below is based on that.\n","                # Wes annotations\n","                cured_dot_boundaries = [\n","                    ([76-5, 177-5, 34-5], [76+5, 177+5, 34+5])]\n","                stable_dot_boundaries = [\n","                    ([36-5, 28-5, 237-5], [36+5, 28+5, 237+5])]\n","                sectored_dot_boundaries = [\n","                    ([204-5, 72-5, 63-5], [204+5, 72+5, 63+5])]\n","\n","                # Nicole annotations\n","                # cured_dot_boundaries = [([0, 250, 0], [0, 255, 0])]\n","                # stable_dot_boundaries = [([0, 0, 250], [0, 0, 255])]\n","                # sectored_dot_boundaries = [([250, 250, 0], [255, 255, 0])]\n","\n","                # cured_dot_boundaries = [([0, 250, 0], [0, 255, 0])]\n","                # stable_dot_boundaries = [([0, 0, 250], [0, 0, 255])]\n","                # sectored_dot_boundaries = [([250, 0, 0], [255, 0, 0])]\n","\n","                for (lower, upper) in cured_dot_boundaries:\n","                    # create NumPy arrays from the boundaries\n","                    lower = np.array(lower, dtype=\"uint8\")\n","                    upper = np.array(upper, dtype=\"uint8\")\n","                    # find the colors within the specified boundaries and apply\n","                    # the mask\n","                    #print(np.unique((colony_image*255).astype(np.uint8)))\n","                    dot_mask = cv2.inRange(\n","                        (state_image*255).astype(np.uint8), lower, upper)\n","                    #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n","                    # Get connected components of the detected dot pixels\n","                    #print(np.unique(dot_mask))\n","                    cured_labels = label(dot_mask)\n","                    num_cured_labels = len(np.unique(cured_labels))\n","                    if num_cured_labels <= 1:\n","                        # No dot was detected.  Thus the colony was considered\n","                        # non-quantifiable.\n","                        colony_is_cured = False\n","                    else:\n","                        # Loop through each component.  Find one component\n","                        # that is not too small and is directly on the colony\n","                        colony_center_y = (state_image.shape[0] - 1) / 2.0\n","                        colony_center_x = (state_image.shape[1] - 1) / 2.0\n","                        for this_comp in range(1, num_cured_labels):\n","                            this_dot_comp = cured_labels == this_comp\n","                            # Get centroid of component\n","                            (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(\n","                                this_dot_comp)\n","                            dot_dist = math.sqrt(\n","                                ((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n","                            if dot_dist < colony_locations[\"Radius\"][this_index]:\n","                                colony_is_cured = True\n","                                break\n","                                # end the loop, as we found a dot on the colony\n","\n","                            if this_comp == (num_cured_labels - 1):\n","                                # We looped through all the dots, but none\n","                                # of them were on the colony.  Don't analyze\n","                                # this colony.\n","                                colony_is_cured = False\n","\n","                quantifiable_cured.append(colony_is_cured)\n","\n","                #print('Colony', this_index, ': Cured:', colony_is_cured)\n","\n","                for (lower, upper) in stable_dot_boundaries:\n","                    # create NumPy arrays from the boundaries\n","                    lower = np.array(lower, dtype=\"uint8\")\n","                    upper = np.array(upper, dtype=\"uint8\")\n","                    # find the colors within the specified boundaries and apply\n","                    # the mask\n","                    #print(np.unique((colony_image*255).astype(np.uint8)))\n","                    dot_mask = cv2.inRange(\n","                        (state_image*255).astype(np.uint8), lower, upper)\n","                    #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n","                    # Get connected components of the detected pixels\n","                    #print(np.unique(dot_mask))\n","                    stable_labels = label(dot_mask)\n","                    num_stable_labels = len(np.unique(stable_labels))\n","                    if num_stable_labels <= 1:\n","                        # No dot was detected.  Thus the colony was considered\n","                        # non-quantifiable.\n","                        colony_is_stable = False\n","                    else:\n","                        # Loop through each component.  Find one component\n","                        # that is not too small and is directly on the colony\n","                        colony_center_y = (state_image.shape[0] - 1) / 2.0\n","                        colony_center_x = (state_image.shape[1] - 1) / 2.0\n","                        for this_comp in range(1, num_stable_labels):\n","                            this_dot_comp = stable_labels == this_comp\n","                            # Get centroid of component\n","                            (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(\n","                                this_dot_comp)\n","                            dot_dist = math.sqrt(\n","                                ((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n","                            if dot_dist < colony_locations[\"Radius\"][this_index]:\n","                                colony_is_stable = True\n","                                break\n","                                # end the loop, as we found a dot on the colony\n","\n","                            if this_comp == (num_stable_labels - 1):\n","                                # We looped through all the dots, but none of\n","                                # them were on the colony.  Don't analyze\n","                                # this colony.\n","                                colony_is_stable = False\n","\n","                quantifiable_stable.append(colony_is_stable)\n","\n","                #print('Colony', this_index, ': Stable:', colony_is_stable)\n","\n","                for (lower, upper) in sectored_dot_boundaries:\n","                    # create NumPy arrays from the boundaries\n","                    lower = np.array(lower, dtype=\"uint8\")\n","                    upper = np.array(upper, dtype=\"uint8\")\n","                    # find the colors within the specified boundaries and apply\n","                    # the mask\n","                    #print(np.unique((colony_image*255).astype(np.uint8)))\n","                    dot_mask = cv2.inRange(\n","                        (state_image*255).astype(np.uint8), lower, upper)\n","                    #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n","                    # Get connected components of the detected pixels\n","                    #print(np.unique(dot_mask))\n","                    sectored_labels = label(dot_mask)\n","                    num_sectored_labels = len(np.unique(sectored_labels))\n","                    if num_sectored_labels <= 1:\n","                        # No dot was detected.  Thus the colony was considered\n","                        # non-quantifiable.\n","                        colony_is_sectored = False\n","                    else:\n","                        # Loop through each component.  Find one component\n","                        # that is not too small and is directly on the colony\n","                        colony_center_y = (state_image.shape[0] - 1) / 2.0\n","                        colony_center_x = (state_image.shape[1] - 1) / 2.0\n","                        for this_comp in range(1, num_sectored_labels):\n","                            this_dot_comp = sectored_labels == this_comp\n","                            # Get centroid of component\n","                            (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(\n","                                this_dot_comp)\n","                            dot_dist = math.sqrt(\n","                                ((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n","                            if dot_dist < colony_locations[\"Radius\"][this_index]:\n","                                colony_is_sectored = True\n","                                break\n","                                # end the loop, as we found a dot on the colony\n","\n","                            if this_comp == (num_sectored_labels - 1):\n","                                # We looped through all the dots, but\n","                                # none of them were on the colony.  Don't\n","                                # analyze this colony.\n","                                colony_is_sectored = False\n","\n","                quantifiable_sectored.append(colony_is_sectored)\n","\n","                #print('Colony', this_index, ': Sectored:', colony_is_sectored)\n","\n","                #----------------------------------\n","\n","            #-----------------------------------------------------\n","            # Get connectedness properties of the segmentation\n","            #-----------------------------------------------------\n","\n","            # Use this information to test whether the segmentation meets the conditions\n","\n","            # Condition 1 test: is the segmentation one connected component?\n","            condition_1_test_strong, condition_1_test_weak = check_components_of_colony(\n","                colony_mask)\n","            colony_is_connected.append(condition_1_test_strong)\n","            colony_is_approx_connected.append(condition_1_test_weak)\n","\n","            # Condition 2 test: Is the boundary one connected component?\n","            condition_2_test = check_components_of_boundary(edge_mask_unpadded)\n","            boundary_is_connected.append(condition_2_test)\n","\n","            # Condition 3 test: Are there holes in the segmentation?\n","            condition_3_test = check_for_holes(colony_mask, edge_mask_unpadded)\n","            colony_is_whole.append(condition_3_test)\n","\n","            # Condition 4 test: Is the boundary a Hamiltonian cycle?\n","            # (not ready yet)\n","            #condition_4_test = get_hamilton_cycle(colony_mask, edge_mask_unpadded)\n","\n","\n","            # Condition 5: Check circularity and convexity\n","            condition_5_convex, condition_5_circular = compare_convex_hull(\n","                colony_mask, edge_mask_unpadded)\n","            colony_is_approx_convex.append(condition_5_convex)\n","            colony_is_approx_circular.append(condition_5_circular)\n","\n","            # Condition 6: Check hausdorff distance\n","            hausdorff_chull, hausdorff_circle = get_hausdorff_distance(\n","                colony_mask, edge_mask_unpadded)\n","            hausdorff_dist_convex.append(hausdorff_chull)\n","            hausdorff_dist_circle.append(hausdorff_circle)\n","\n","\n","            #----------------------------------------\n","            # Partition the boundaries into red and white components\n","\n","            # Get 'ideal' boundary of the colony\n","            ideal_circle = create_circle_boundary(\n","                edge_mask_unpadded, colony_locations[\"Radius\"][this_index])\n","\n","            # Find connected components of the red and white pixels found on the boundary\n","            red_boundary_skeleton, white_boundary_skeleton, boundary_mask_h, boundary_mask_w = get_boundary_partitions(\n","                red_colony_mask, white_colony_mask, edge_mask_unpadded)\n","\n","            #plt.imshow(red_boundary_skeleton)\n","            #plt.title('Red Boundary Skeleton')\n","\n","            # Save the three images using this data\n","            #   - Oringinal image padded\n","            #   - CHT image padded\n","            #   - Segmentation padded\n","            # Force a circle like previously\n","            padded_x = 255 * x[max((top_left_y-1)-IMAGE_PADDING, 0):min((top_left_y + box_height - 1)+IMAGE_PADDING, HEIGHT-1), max(\n","                (top_left_x-1) - IMAGE_PADDING, 0):min((top_left_x + box_width - 1)+IMAGE_PADDING, WIDTH-1), :]\n","            padded_x_CHT = 255 * x_CHT[max((top_left_y-1)-IMAGE_PADDING, 0):min((top_left_y + box_height - 1)+IMAGE_PADDING, HEIGHT-1), max(\n","                (top_left_x-1) - IMAGE_PADDING, 0):min((top_left_x + box_width - 1)+IMAGE_PADDING, WIDTH-1), :]\n","            padded_mask = p[max((top_left_y-1)-IMAGE_PADDING, 0):min((top_left_y + box_height - 1)+IMAGE_PADDING, HEIGHT-1),\n","                            max((top_left_x-1) - IMAGE_PADDING, 0):min((top_left_x + box_width - 1)+IMAGE_PADDING, WIDTH-1)]\n","            ellipse_array_2 = create_filled_ellipse_in_array(\n","                padded_mask, padding=IMAGE_PADDING)\n","            padded_mask = np.multiply(padded_mask, ellipse_array_2)\n","\n","            # # Save the colony images as previously\n","            # if SAVE_ALL_ANNOTATIONS is True:\n","            #     if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/raw/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.jpg', padded_x):\n","            #         raise IOError('Could not write image.')\n","            #     if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/circles/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.jpg', padded_x_CHT):\n","            #         raise IOError('Could not write image.')\n","            #     if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/segs/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', padded_mask):\n","            #         raise IOError('Could not write image.')\n","\n","            # Save the croppings for individual colonies which were annotated\n","                # if USE_EXPERT_COUNTS is True:\n","                #     padded_x_count = 255 * x_quant[max((top_left_y-1)-IMAGE_PADDING, 0):min((top_left_y + box_height - 1)+IMAGE_PADDING, HEIGHT-1), max(\n","                #         (top_left_x-1) - IMAGE_PADDING, 0):min((top_left_x + box_width - 1)+IMAGE_PADDING, WIDTH-1), :]\n","                #     if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/counted/' + file_dict[plate_name] + '/' + pathlib.Path(train_image).stem + '_c_' + str(this_index) + '.png', padded_x_count):\n","                #         raise IOError('Could not write image.')\n","            #-------------------------------------------------------------\n","\n","            # CLASSIFICATION STEP BEGINS\n","            # GET INITIAL REGIONAL BREAKDOWN AND RED REGION ANNOTATIONS OF THE COLONY\n","\n","            # Should store information about the following:\n","            #   - Idealized red and white regions\n","            #   - The boundaries of each red and white region\n","            #   - The sizes of each region\n","            #   - The purity scores of each region\n","            #   - the states of each colony (cured, stable)\n","\n","            # Images to save in this section\n","            # - Regional segmentation\n","            # - Boundary of the colony\n","            # - Red region boundary annotation\n","            # - Regions that fail consistency check\n","\n","            # Plot padded version of the initial segmentation.\n","            # Annotations will be saved onto the image.\n","            colony_image_padded = np.pad(colony_image, 5)\n","            # fig1, ax1 = plt.subplots()\n","            # ax1.imshow(colony_image_padded, cmap='gray', vmin=0, vmax=255)\n","\n","            # initialized to true so that we can look at how each step\n","            # of the pipeline is performing\n","            recheck_boundaries = True\n","\n","            # Using boundary information, find and extract potential\n","            # red and white regions of the colony\n","\n","            red_labels = label(red_boundary_skeleton)\n","            white_labels = label(white_boundary_skeleton)\n","\n","            # Initialize masks separating potential red and white regions\n","            initial_red_region_mask = np.zeros_like(red_boundary_skeleton)\n","            initial_white_region_mask = np.zeros_like(white_boundary_skeleton)\n","            initial_red_boundary_mask = np.zeros_like(red_boundary_skeleton)\n","            initial_white_boundary_mask = np.zeros_like(\n","                white_boundary_skeleton)\n","\n","            # keep track of regions which fail the consistency check\n","            initial_bad_red_score_mask = np.zeros_like(red_boundary_skeleton)\n","            initial_bad_white_score_mask = np.zeros_like(\n","                white_boundary_skeleton)\n","\n","            # Keep track of boundaries whihc fail the consistency check\n","            boundary_correction = np.zeros_like(red_boundary_skeleton)\n","\n","            # Initialize lists to store characteristics about each region\n","            # This includes endpoints on the sector, the purity of the\n","            # sector, and an indicator for the purity being above the\n","            # 50 percent threshold\n","            red_component_endpoints = []\n","            red_component_scores = []\n","            red_component_checks = []\n","            red_component_sizes = []\n","\n","            white_component_endpoints = []\n","            white_component_scores = []\n","            white_component_checks = []\n","            white_component_sizes = []\n","\n","            # How many boundaries of each color are there?\n","            # number of red boundaries present\n","            num_red_boundaries = len(np.unique(red_labels)[1:])\n","            # number of white boundaries present\n","            num_white_boundaries = len(np.unique(white_labels)[1:])\n","\n","            # Initial count of the number of sectors is the number of red boundaries\n","            initial_region_counts.append(num_red_boundaries)\n","\n","            # States can be initialy predicted using the number of red and white boundaries\n","            #if ((num_red_boundaries == 1) & (num_white_boundaries == 0)):\n","            if num_white_boundaries == 0:\n","                cured_colony_before.append(True)\n","            else:\n","                cured_colony_before.append(False)\n","\n","            #if ((num_red_boundaries == 0) & (num_white_boundaries == 1)):\n","            if num_red_boundaries == 0:\n","                stable_colony_before.append(True)\n","            else:\n","                stable_colony_before.append(False)\n","\n","            # Now, to analyze each of the regions to determine if they are sectored\n","\n","            # Analyze the initial red regions of the colony\n","            for this_label in np.unique(red_labels)[1:]:\n","                red_component = copy.deepcopy(red_labels)\n","                red_component = red_component == this_label\n","                red_component = red_component.astype(np.int32)\n","\n","                # Append the red boundary pixels on this component to the red boundary mask\n","                initial_red_boundary_mask = np.logical_or(\n","                    initial_red_boundary_mask, red_component > 0)\n","\n","                # Function to get endpoints of connected component\n","                full_endpoints_list = get_boundary_component_endpoints(\n","                    colony_image[:, :], red_component)\n","\n","                # If exactly two points are found, then everything's good.\n","\n","                # Get the angle of the endpoints relative to the colony center\n","                [endpoint_angles, endpoint_locations, endpoints_x, endpoints_y] = get_endpoint_locations(\n","                    full_endpoints_list, colony_mask, colony_locations[\"Radius\"][this_index])\n","\n","                # Function to get mask representing sector boundary\n","                sector_boundary, sector_interior, sector_filled = get_sector_masks(\n","                    red_component, full_endpoints_list)\n","\n","                # Append the predicted filled region to the red region mask\n","                initial_red_region_mask = np.logical_or(\n","                    initial_red_region_mask, sector_filled)\n","\n","                # Apply consistency check to score the region\n","                confirm_check, prop_interior = check_for_consistency_2(\n","                    sector_filled, red_colony_mask)\n","\n","                # Update score mask to denote where the consistency check failed\n","                if confirm_check is False:\n","                    recheck_boundaries = True\n","                    initial_bad_red_score_mask = np.logical_or(\n","                        initial_bad_red_score_mask, sector_filled)\n","\n","                # Append scores and info to lists\n","                # endpoints of the connected compponent on the boundary\n","                red_component_endpoints.append(full_endpoints_list)\n","                # purity score of the region\n","                red_component_scores.append(prop_interior)\n","                # whether the purity score was at least 0.5\n","                red_component_checks.append(confirm_check)\n","                # the number of pixels in the region\n","                red_component_sizes.append(np.sum(initial_red_region_mask))\n","\n","                # ---ANNOTATION PROCEDURE---\n","\n","                # Plot the lines of the sector (and the boundary line) onto the colony segmentation\n","                length_points = len(endpoints_x)\n","                #print(length_points)\n","                #print(endpoints_x)\n","                # only plots lines if there are divided regions\n","                if len(np.unique(red_labels)[1:]) > 0:\n","                    plot_bounds_x = []\n","                    plot_bounds_y = []\n","                    plot_bounds_x.append(endpoints_x[0] + IMAGE_PADDING)\n","                    plot_bounds_y.append(endpoints_y[0] + IMAGE_PADDING)\n","                    # Get list of center and endpoints on the boundary\n","                    for this_bound in range(0, length_points-1):\n","                        plot_bounds_x.append(\n","                            endpoints_x[this_bound+1] + IMAGE_PADDING)\n","                        plot_bounds_y.append(\n","                            endpoints_y[this_bound+1] + IMAGE_PADDING)\n","                        #plt.plot(plot_points_y, plot_points_x, color='blue')\n","                        #print(endpoints_x[0:2])\n","                        #print(endpoints_y[0:2])\n","                    plot_bounds_x = np.roll(np.array(plot_bounds_x), 1)\n","                    plot_bounds_y = np.roll(np.array(plot_bounds_y), 1)\n","                    #print(plot_bounds_x)\n","                    #print(plot_bounds_y)\n","                    line_style = ':' if (len(plot_bounds_x) == 2) else '-'\n","                    # ax1.plot(plot_bounds_y, plot_bounds_x, linewidth=5,\n","                    #          linestyle=line_style, alpha=0.85)\n","                    if len(plot_bounds_x) == 1:\n","                        full_circle = Circle(\n","                            (plot_bounds_y, plot_bounds_x),\n","                            radius=colony_locations[\"Radius\"][this_index],\n","                            color='blue', fill=False, linewidth=5, alpha=0.85)\n","                        # ax1.add_patch(full_circle)\n","\n","            # Do the same for the white regions\n","            for this_label in np.unique(white_labels)[1:]:\n","                white_component = copy.deepcopy(white_labels)\n","                white_component = white_component == this_label\n","                white_component = white_component.astype(np.int32)\n","\n","                initial_white_boundary_mask = np.logical_or(\n","                    initial_white_boundary_mask, white_component > 0)\n","\n","                # Function to get endpoints of connected component\n","                full_endpoints_list = get_boundary_component_endpoints(\n","                    colony_image[:, :], white_component)\n","\n","                # If exactly two points are found, then everything's good.\n","\n","                # Function to get mask representing sector boundary\n","                sector_boundary, sector_interior, sector_filled = get_sector_masks(\n","                    white_component, full_endpoints_list)\n","\n","                # Fill initial region mask with the filled sector\n","                initial_white_region_mask = np.logical_or(\n","                    initial_white_region_mask, sector_filled)\n","\n","                # Apply consistency check to score region\n","                confirm_check, prop_interior = check_for_consistency_2(\n","                    sector_filled, white_colony_mask)\n","\n","                # Update score mask to denote where the consistency check failed\n","                if confirm_check is False:\n","                    recheck_boundaries = True\n","                    initial_bad_white_score_mask = np.logical_or(\n","                        initial_bad_white_score_mask, sector_filled)\n","\n","                # Append scores and info to lists\n","                white_component_endpoints.append(full_endpoints_list)\n","                white_component_scores.append(prop_interior)\n","                white_component_checks.append(confirm_check)\n","                white_component_sizes.append(np.sum(initial_white_region_mask))\n","\n","            # At this point, you should have two masks, one for the red\n","            # and white regions respectivey.\n","            # You should also have the endponts of each component, stored\n","            # as a collection of lists, one list per component\n","            # Finally, you should have a score for those components\n","\n","            # -------------------------------------\n","            # Store the purity scores in a sublist, along with a second\n","            # sublist indicating the color of each region\n","            # -------------------------------------\n","\n","            all_component_scores = []\n","            all_region_colors = []\n","            all_region_sizes = []\n","\n","            if not red_component_scores:\n","                all_region_colors = all_region_colors + ['red']\n","                all_component_scores = all_component_scores + [np.nan]\n","                all_region_sizes = all_region_sizes + [np.nan]\n","            else:\n","                all_region_colors = all_region_colors + \\\n","                    (['red'] * len(red_component_scores))\n","                all_component_scores = all_component_scores + red_component_scores\n","                all_region_sizes = all_region_sizes + red_component_sizes\n","\n","            if not white_component_scores:\n","                all_region_colors = all_region_colors + ['white']\n","                all_component_scores = all_component_scores + [np.nan]\n","                all_region_sizes = all_region_sizes + [np.nan]\n","            else:\n","                all_region_colors = all_region_colors + \\\n","                    (['white'] * len(white_component_scores))\n","                all_component_scores = all_component_scores + white_component_scores\n","                all_region_sizes = all_region_sizes + white_component_sizes\n","\n","            region_purity_before.append(all_component_scores)\n","            region_color_before.append(all_region_colors)\n","            region_sizes_before.append(all_region_sizes)\n","\n","            # -------------------------------------\n","            # Do the same for the weighted purity scores across the entire colony\n","            # -------------------------------------\n","\n","            # Compute weighted purity scores over all regions, for white only, and for red only\n","\n","            total_red_sum = np.nansum(red_component_sizes)\n","            total_white_sum = np.nansum(white_component_sizes)\n","\n","            if not red_component_scores:\n","                red_region_weights = np.array([0])\n","                weighted_red_scores = np.array([0])\n","            else:\n","                # this vector should add to 1, as this is a normalization of the weights\n","                red_region_weights = np.divide(\n","                    np.array(red_component_sizes), total_red_sum)\n","                weighted_red_scores = np.multiply(\n","                    np.array(red_component_scores), red_region_weights)\n","\n","            if not white_component_scores:\n","                white_region_weights = np.array([0])\n","                weighted_white_scores = np.array([0])\n","            else:\n","                # this vector should add to 1, as this is a normalization of the weights\n","                white_region_weights = np.divide(\n","                    np.array(white_component_sizes), total_white_sum)\n","                weighted_white_scores = np.multiply(\n","                    np.array(white_component_scores), white_region_weights)\n","\n","            # Get weighted average over both regions together\n","            all_region_sum = np.nansum(all_region_sizes)\n","            all_region_weights = np.divide(\n","                np.array(red_component_sizes + white_component_sizes), all_region_sum)\n","            all_region_weighted_scores = np.multiply(\n","                np.array(red_component_scores + white_component_scores), all_region_weights)\n","\n","            weighted_purity_red_before.append(list(weighted_red_scores))\n","            weighted_purity_white_before.append(list(weighted_white_scores))\n","            weighted_purity_before.append(list(all_region_weighted_scores))\n","            weighted_red_sector_score_before.append(\n","                np.nansum(weighted_red_scores))\n","            weighted_white_sector_score_before.append(\n","                np.nansum(weighted_white_scores))\n","            weighted_sector_score_before.append(\n","                np.nansum(all_region_weighted_scores))\n","\n","            # Now, create the masks containing the initial_regions\n","            initial_region_mask = np.maximum(initial_red_region_mask.astype(\n","                np.uint8), 2*initial_white_region_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","            initial_boundary_mask = np.maximum(initial_red_boundary_mask.astype(\n","                np.uint8), 2*initial_white_boundary_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","            initial_score_mask = np.maximum(initial_bad_red_score_mask.astype(\n","                np.uint8), 2*initial_bad_white_score_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","\n","            # Make sure to pad them in the same way as the output segmentation\n","            initial_region_mask = np.pad(initial_region_mask, IMAGE_PADDING)\n","            initial_boundary_mask = np.pad(\n","                initial_boundary_mask, IMAGE_PADDING)\n","            initial_score_mask = np.pad(initial_score_mask, IMAGE_PADDING)\n","\n","            # Save the initial region and boundary mask.  Also save\n","            # image indicating regions which should be investigted further.\n","            # if SAVE_ALL_ANNOTATIONS is True:\n","            #     if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/init_regions/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', initial_region_mask):\n","            #         raise IOError('Could not write image.')\n","            #     if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/init_bounds/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', initial_boundary_mask):\n","            #         raise IOError('Could not write image.')\n","            #     if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/init_bad/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', initial_score_mask):\n","            #         raise IOError('Could not write image.')\n","            # plt.axis('off')\n","            # if SAVE_ALL_ANNOTATIONS is True:\n","            #     fig1.savefig(OUTPUT_CROPS_FOLDER + '/init_partitions/' + file_dict[plate_name] + '/' + pathlib.Path(\n","            #         test_image).stem + '_c_' + str(this_index) + '.png', bbox_inches='tight', pad_inches=0)\n","            # plt.close(fig1)\n","\n","            #------------------------------------------------------------------\n","\n","            # CLASS SWITCH/MERGING STEP\n","\n","            # This is only applied to regions where the consistency check fails.\n","            # i.e. less than 50% of pixels in the predicted region are of the same class\n","            # as the outer boundary pixels\n","\n","            # The process will repeat until all regions pass the consisency check\n","\n","            # NOTE: This section is only executed if one of either the red or\n","            # white regions estimated above, fails the constency check.\n","            # If all regions predicted are consistent in class, the below will\n","            # not execute, as it will do exactly the same stuff as just done above.\n","\n","            # Therefore, this section is purposely redundant and helps us keep\n","            # track of which regions are being updated.\n","\n","            repetition_counter = 0\n","            performing_correction = False  # initialize at the beginning\n","\n","            while recheck_boundaries is True:\n","\n","                recheck_boundaries = False  # reset.\n","                repetition_counter = repetition_counter + 1\n","\n","                # The above should be switched back to True if there is a\n","                # potentially misclassified boundary\n","\n","                # Find the connected components of the skeleton.\n","                # The number of red connected components gives the initial\n","                # number of sectors.\n","                # The number of white connected components are the regions\n","                # separating the red sectors.\n","                # A score for sectoriness will be applied to both sets of regions.\n","                red_labels = label(red_boundary_skeleton)\n","                white_labels = label(white_boundary_skeleton)\n","\n","                # Initialize masks separating potential red and white regions\n","                red_region_mask = np.zeros_like(red_boundary_skeleton)\n","                white_region_mask = np.zeros_like(white_boundary_skeleton)\n","                red_boundary_mask = np.zeros_like(red_boundary_skeleton)\n","                white_boundary_mask = np.zeros_like(white_boundary_skeleton)\n","                red_score_mask = np.zeros_like(red_boundary_skeleton)\n","                white_score_mask = np.zeros_like(white_boundary_skeleton)\n","\n","                # Intialize array to change boundary.\n","                # This is only updated when there is a potentially misclassified boundary.\n","                boundary_correction_red = np.zeros_like(red_boundary_skeleton)\n","                boundary_correction_white = np.zeros_like(\n","                    white_boundary_skeleton)\n","\n","                # Generate regions directly from segmentation\n","                # Iterate through each component and collect some information\n","                # Collect info about component endpoints and purity scores\n","                red_component_endpoints = []\n","                red_component_scores = []\n","                red_component_checks = []\n","\n","                white_component_endpoints = []\n","                white_component_scores = []\n","                white_component_checks = []\n","\n","               # print('Number of red components: ' + str(max(np.unique(red_labels)[1:])))\n","\n","                # Iterate through the red components\n","                for this_label in np.unique(red_labels)[1:]:\n","                    #print('Running the red check.')\n","                    red_component = copy.deepcopy(red_labels)\n","                    red_component = red_component == this_label\n","                    red_component = red_component.astype(np.int32)\n","\n","                    red_boundary_mask = np.logical_or(\n","                        red_boundary_mask, red_component > 0)\n","\n","                    # Function to get endpoints of connected component\n","                    full_endpoints_list = get_boundary_component_endpoints(\n","                        colony_image[:, :], red_component)\n","\n","                    # If exactly two points are found, then everything's good.\n","\n","                    # Function to get mask representing sector boundary\n","                    sector_boundary, sector_interior, sector_filled = get_sector_masks(\n","                        red_component, full_endpoints_list)\n","\n","                    # Fill initial region mask with the filled sector\n","                    red_region_mask = np.logical_or(\n","                        red_region_mask, sector_filled)\n","\n","                    # Apply consistency check to score region\n","                    confirm_check, prop_interior = check_for_consistency_2(\n","                        sector_filled, red_colony_mask)\n","\n","                    # Update score mask to denote where the consistency\n","                    # check failed\n","                    if confirm_check is False:\n","                        recheck_boundaries = True\n","                        boundary_correction_red = np.logical_or(\n","                            boundary_correction_red, red_component)\n","\n","                    # Append scores and info to lists\n","                    red_component_endpoints.append(full_endpoints_list)\n","                    red_component_scores.append(prop_interior)\n","                    red_component_checks.append(confirm_check)\n","\n","                # Do the same for the white components\n","                for this_label in np.unique(white_labels)[1:]:\n","\n","                    white_component = copy.deepcopy(white_labels)\n","                    white_component = white_component == this_label\n","                    white_component = white_component.astype(np.int32)\n","\n","                    white_boundary_mask = np.logical_or(\n","                        white_boundary_mask, white_component > 0)\n","\n","                    # Function to get endpoints of connected component\n","                    full_endpoints_list = get_boundary_component_endpoints(\n","                        colony_image[:, :], white_component)\n","\n","                    # If exactly two points are found, then everything's good.\n","\n","                    # Function to get mask representing sector boundary\n","                    sector_boundary, sector_interior, sector_filled = get_sector_masks(\n","                        white_component, full_endpoints_list)\n","\n","                    # Fill initial region mask with the filled sector\n","                    white_region_mask = np.logical_or(\n","                        white_region_mask, sector_filled)\n","\n","                    # Apply consistency check to score region\n","                    confirm_check, prop_interior = check_for_consistency_2(\n","                        sector_filled, white_colony_mask)\n","\n","                    # Update score mask to denote where the consistency\n","                    # check failed\n","                    if confirm_check is False:\n","                        recheck_boundaries = True\n","                        boundary_correction_white = np.logical_or(\n","                            boundary_correction_white, white_component)\n","\n","                    # Append scores and info to lists\n","                    white_component_endpoints.append(full_endpoints_list)\n","                    white_component_scores.append(prop_interior)\n","                    white_component_checks.append(confirm_check)\n","\n","                # If there were regions that failed the\n","                # consistency check, swap the classes on the boundary\n","                if recheck_boundaries is True:\n","\n","                    # This signifies that boundary information will\n","                    # be different from the initial breakdown\n","                    performing_correction = True\n","\n","                    # Run the swap functions\n","                    # takes the bad white boundaries and switches them to the red class\n","                    red_boundary_skeleton = grow_boundary(\n","                        red_boundary_skeleton, boundary_correction_white)\n","                    red_boundary_skeleton = shrink_boundary(\n","                        red_boundary_skeleton, boundary_correction_red)\n","                    # removes the bad red boundaries\n","\n","                    # takes the bad red boundaries and switches them\n","                    # to the white class\n","                    white_boundary_skeleton = grow_boundary(\n","                        white_boundary_skeleton, boundary_correction_red)\n","                    white_boundary_skeleton = shrink_boundary(\n","                        white_boundary_skeleton, boundary_correction_white)\n","                    # removes the bad white boundaries\n","\n","                # Only run the block below if this colony cannot be\n","                # analyzed appropriatly with this pipeline\n","                # (may be an awful segmentation)\n","                if repetition_counter > 20:\n","                    warnings.warn(\n","                        'Corrections have been applied too many times.  The colony segmentation used here is likely unsuitable for this pipeline.')\n","                    break\n","\n","                    # Once the swap is done, you will head back to the top\n","                    # of this while loop.\n","\n","            # At this point, you should have two masks, one for the red\n","            # and white regions respectivey.\n","            # You should also have the endponts of each components,\n","            # stored as a collection of lists, one list per component\n","            # Finally, you should have a score for those components\n","\n","            # Now, create the masks containing the regions that pass the consistency check\n","            corrected_region_mask = np.maximum(red_region_mask.astype(\n","                np.uint8), 2*white_region_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","            corrected_boundary_mask = np.maximum(red_boundary_mask.astype(\n","                np.uint8), 2*white_boundary_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","\n","            red_labels = label(red_boundary_skeleton)\n","            white_labels = label(white_boundary_skeleton)\n","\n","            # Use the corrected boundary_mask to piece together the corrected colony segmentation\n","            corrected_colony_image = np.add(\n","                interior_colony, corrected_boundary_mask).astype(np.uint8)\n","            corrected_colony_image_padded = np.pad(\n","                corrected_colony_image, IMAGE_PADDING)\n","\n","            # Re-partition the image following correction\n","            corrected_full = tf.identity(\n","                corrected_colony_image).numpy().astype(np.int32)\n","            corrected_white_colony_mask = tf.math.equal(tf.constant(\n","                corrected_full), tf.constant([255])).numpy().astype(np.uint8)\n","            corrected_red_colony_mask = tf.math.equal(tf.constant(\n","                corrected_full), tf.constant([127])).numpy().astype(np.uint8)\n","            # sanity check to see of this is the same as colony image\n","            corrected_colony_mask = np.logical_or(\n","                corrected_white_colony_mask, corrected_red_colony_mask)\n","\n","            #--------------------------------------------------\n","            # Get corrected segmentations and regions\n","\n","            # Get boundary information from the boundary corrected/merged\n","            # segmentation.\n","            corrected_red_boundary_skeleton, corrected_white_boundary_skeleton, corrected_boundary_mask_h, corrected_boundary_mask_w = get_boundary_partitions(\n","                corrected_red_colony_mask, corrected_white_colony_mask, edge_mask_unpadded)\n","\n","            red_labels = label(corrected_red_boundary_skeleton)\n","            white_labels = label(corrected_white_boundary_skeleton)\n","\n","            corrected_boundary_mask = np.maximum((red_labels > 0).astype(\n","                np.uint8), 2*((white_labels > 0).astype(np.uint8)))*(255/(NUM_CLASSES-1))\n","\n","            # Use the corrected boundary_mask to piece together the corrected colony segmentation\n","            corrected_colony_image = np.add(\n","                interior_colony, corrected_boundary_mask).astype(np.uint8)\n","            corrected_colony_image_padded = np.pad(\n","                corrected_colony_image, IMAGE_PADDING)\n","\n","            corrected_region_mask = np.maximum(red_region_mask.astype(\n","                np.uint8), 2*white_region_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","            corrected_boundary_mask = np.maximum(red_boundary_mask.astype(\n","                np.uint8), 2*white_boundary_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","\n","            # Re-partition the image following correction\n","            corrected_full = tf.identity(\n","                corrected_colony_image).numpy().astype(np.int32)\n","            corrected_white_colony_mask = tf.math.equal(tf.constant(\n","                corrected_full), tf.constant([255])).numpy().astype(np.uint8)\n","            corrected_red_colony_mask = tf.math.equal(tf.constant(\n","                corrected_full), tf.constant([127])).numpy().astype(np.uint8)\n","            # sanity check to see of this is the same as colony image\n","            corrected_colony_mask = np.logical_or(\n","                corrected_white_colony_mask, corrected_red_colony_mask)\n","\n","            #-------------------------------------------------------------------\n","\n","            # PROCESSING THE CORRECTED REGIONS\n","            # If you got to this point, then the boundaries should be\n","            # consistent with the interior of the colony.\n","\n","            # Images to save in this section\n","            # - Regional segmentation with the corrected boundary\n","            # - Red region boundary annotation with the corrected boundary\n","            # - Red regions remaining after correction applied\n","\n","            # initialize masks containing the sector locations\n","            all_sector_bounds = np.zeros_like(colony_mask).astype(np.int32)\n","            all_sector_filled = np.zeros_like(colony_mask).astype(np.int32)\n","            all_sector_filled_labels = np.zeros_like(\n","                colony_mask).astype(np.int32)\n","\n","            # Save the corrected segmentation\n","            # if SAVE_ALL_ANNOTATIONS is True:\n","            #     if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/cor_segs/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', corrected_colony_image_padded):\n","            #         raise IOError('Could not write image.')\n","\n","            # Initialize masks separating potential red and white regions\n","            post_red_region_mask = np.zeros_like(\n","                corrected_red_boundary_skeleton)\n","            post_white_region_mask = np.zeros_like(\n","                corrected_white_boundary_skeleton)\n","            post_red_boundary_mask = np.zeros_like(\n","                corrected_red_boundary_skeleton)\n","            post_white_boundary_mask = np.zeros_like(\n","                corrected_white_boundary_skeleton)\n","            post_red_score_mask = np.zeros_like(\n","                corrected_red_boundary_skeleton)\n","            post_white_score_mask = np.zeros_like(\n","                corrected_white_boundary_skeleton)\n","\n","            # red_labels = label(corrected_red_boundary_skeleton)\n","            # white_labels = label(corrected_white_boundary_skeleton)\n","\n","            # initialize counter for the number of sectors in this colony\n","            total_sectors = 0\n","\n","            # Make copy of colony mask and place sectors on top\n","            #colony_mask_faded = copy.deepcopy(colony_mask).astype(np.uint8)\n","            #colony_mask_faded[colony_mask_faded > 0] = 20\n","\n","            corrected_colony_mask_faded = copy.deepcopy(\n","                corrected_colony_mask).astype(np.uint8)\n","            corrected_colony_mask_faded[corrected_colony_mask_faded > 0] = 20\n","\n","            sector_scores = []\n","            sector_ious = []\n","\n","            # Create figure for annotating the corrected colony segmentations.\n","            # Annotations will be saved onto the image.\n","            # fig2, ax2 = plt.subplots()\n","            # ax2.imshow(corrected_colony_image_padded, cmap='gray', vmin=0, vmax=255)\n","\n","            # Compute the scores of the regions one more time.\n","            # All regions should pass the consistency check by this point.\n","            # If not, then something is wrong.\n","            red_component_endpoints = []\n","            red_component_scores = []\n","            red_component_checks = []\n","            red_component_sizes = []\n","\n","            white_component_endpoints = []\n","            white_component_scores = []\n","            white_component_checks = []\n","            white_component_sizes = []\n","\n","            # number of red boundaries present\n","            num_red_boundaries = len(np.unique(red_labels)[1:])\n","            # number of white boundaries present\n","            num_white_boundaries = len(np.unique(white_labels)[1:])\n","\n","            #if ((num_red_boundaries == 1) & (num_white_boundaries == 0)):\n","            if num_white_boundaries == 0:\n","                cured_colony_after.append(True)\n","            else:\n","                cured_colony_after.append(False)\n","\n","            #if ((num_red_boundaries == 0) & (num_white_boundaries == 1)):\n","            if num_red_boundaries == 0:\n","                stable_colony_after.append(True)\n","            else:\n","                stable_colony_after.append(False)\n","\n","            for this_label in np.unique(red_labels)[1:]:\n","                red_component = copy.deepcopy(red_labels)\n","                red_component = red_component == this_label\n","                red_component = red_component.astype(np.int32)\n","\n","                post_red_boundary_mask = np.logical_or(\n","                    post_red_boundary_mask, red_component > 0)\n","\n","                # Function to get endpoints of connected component\n","                full_endpoints_list = get_boundary_component_endpoints(\n","                    corrected_colony_image[:, :], red_component)\n","\n","                # If exactly two points are found, then everything's good.\n","\n","                # Function to get mask representing sector boundary\n","                sector_boundary, sector_interior, sector_filled = get_sector_masks(\n","                    red_component, full_endpoints_list)\n","\n","                # Fill initial region mask with the filled sector\n","                post_red_region_mask = np.logical_or(\n","                    post_red_region_mask, sector_filled)\n","\n","                # Apply consistency check to score region\n","                confirm_check, prop_interior = check_for_consistency_2(\n","                    sector_filled, corrected_red_colony_mask)\n","\n","                # Update score mask to denote where the consistency check failed\n","                if confirm_check is False:\n","                    print(\n","                        'Double check your code.  The red consistency check failed for this colony with score ' + str(prop_interior))\n","\n","                # Append scores and info to lists\n","                red_component_endpoints.append(full_endpoints_list)\n","                red_component_scores.append(prop_interior)\n","                red_component_checks.append(confirm_check)\n","                red_component_sizes.append(np.sum(post_red_region_mask))\n","\n","                # Code for plotting the annotations\n","\n","                # For the consistent sectors, get the angles of the endpoints\n","                # relative to the center.\n","                # colony mask, or any other array with the same size and shape,\n","                # will work as input as it's only needed for size info\n","                [endpoint_angles, endpoint_locations, endpoints_x, endpoints_y] = get_endpoint_locations(\n","                    full_endpoints_list, corrected_colony_mask, colony_locations[\"Radius\"][this_index])\n","                #print(endpoints_x)\n","\n","                # Add to mask containg sector locations\n","                #sector_filled = np.logical_or(sector_boundary, sector_interior)\n","                all_sector_bounds = np.logical_or(\n","                    all_sector_bounds, sector_boundary)\n","                all_sector_filled = np.logical_or(\n","                    all_sector_filled, sector_filled)\n","                all_sector_filled_labels[sector_filled.astype(\n","                    bool)] = this_label\n","                total_sectors = total_sectors + 1\n","                corrected_colony_mask_faded[sector_filled.astype(\n","                    bool)] = 255 / this_label\n","\n","                # Get a score for sectoriness.  We want to be sure we are\n","                # capturing the entire sector\n","                this_sector_mask = np.logical_and(\n","                    sector_filled, red_colony_mask)\n","                this_union_mask = np.logical_or(sector_filled, red_colony_mask)\n","                this_sector_score = np.sum(\n","                    this_sector_mask) / np.sum(sector_filled)\n","                this_sector_iou = np.sum(\n","                    this_sector_mask) / np.sum(this_union_mask)\n","                sector_scores.append(this_sector_score)\n","                sector_ious.append(this_sector_iou)\n","\n","                # Plot the lines of the sector (and the boundary line) onto the colony segmentation\n","                length_points = len(endpoints_x)\n","                #print(length_points)\n","                #print(endpoints_x)\n","                if len(np.unique(red_labels)[1:]) > 0:\n","                    plot_bounds_x = []\n","                    plot_bounds_y = []\n","                    plot_bounds_x.append(endpoints_x[0] + 5)\n","                    plot_bounds_y.append(endpoints_y[0] + 5)\n","                    # Get list of center and endpoints on the boundary\n","                    for this_bound in range(0, length_points-1):\n","                        plot_bounds_x.append(endpoints_x[this_bound+1] + 5)\n","                        plot_bounds_y.append(endpoints_y[this_bound+1] + 5)\n","                        #plt.plot(plot_points_y, plot_points_x, color='blue')\n","                        #print(endpoints_x[0:2])\n","                        #print(endpoints_y[0:2])\n","                    plot_bounds_x = np.roll(np.array(plot_bounds_x), 1)\n","                    plot_bounds_y = np.roll(np.array(plot_bounds_y), 1)\n","                    #print(plot_bounds_x)\n","                    #print(plot_bounds_y)\n","                    line_style = ':' if (len(plot_bounds_x) == 2) else '-'\n","                    # ax2.plot(plot_bounds_y, plot_bounds_x, linewidth=5,\n","                    #          linestyle=line_style, alpha=0.85)\n","                    if len(plot_bounds_x) == 1:\n","                        full_circle = Circle(\n","                            (plot_bounds_y, plot_bounds_x),\n","                            radius=colony_locations[\"Radius\"][this_index],\n","                            color='blue', fill=False, linewidth=5, alpha=0.85)\n","                        # ax2.add_patch(full_circle)\n","\n","            for this_label in np.unique(white_labels)[1:]:\n","                white_component = copy.deepcopy(white_labels)\n","                white_component = white_component == this_label\n","                white_component = white_component.astype(np.int32)\n","\n","                post_white_boundary_mask = np.logical_or(\n","                    post_white_boundary_mask, white_component > 0)\n","\n","                # Function to get endpoints of connected component\n","                full_endpoints_list = get_boundary_component_endpoints(\n","                    corrected_colony_image[:, :], white_component)\n","\n","                # If exactly two points are found, then everything's good.\n","\n","                # Function to get mask representing sector boundary\n","                sector_boundary, sector_interior, sector_filled = get_sector_masks(\n","                    white_component, full_endpoints_list)\n","\n","                # Fill initial region mask with the filled sector\n","                post_white_region_mask = np.logical_or(\n","                    post_white_region_mask, sector_filled)\n","\n","                # Apply consistency check to score region\n","                confirm_check, prop_interior = check_for_consistency_2(\n","                    sector_filled, corrected_white_colony_mask)\n","\n","                # Update score mask to denote where the consistency check failed\n","                if confirm_check is False:\n","                    print(\n","                        'Double check your code.  The white consistency check failed for this colony with score ' + str(prop_interior))\n","\n","                # Append scores and info to lists\n","                white_component_endpoints.append(full_endpoints_list)\n","                white_component_scores.append(prop_interior)\n","                white_component_checks.append(confirm_check)\n","                white_component_sizes.append(np.sum(post_white_region_mask))\n","\n","            print('Scores for red regions: ' + str(red_component_scores))\n","            print('Scores for white regions: ' + str(white_component_scores))\n","\n","            # Store the purity scores in a sublist, along with a second\n","            # sublist indicating the color of each region\n","\n","            all_component_scores = []\n","            all_region_colors = []\n","            all_region_sizes = []\n","\n","            if not red_component_scores:\n","                all_region_colors = all_region_colors + ['red']\n","                all_component_scores = all_component_scores + [np.nan]\n","                all_region_sizes = all_region_sizes + [np.nan]\n","            else:\n","                all_region_colors = all_region_colors + \\\n","                    (['red'] * len(red_component_scores))\n","                all_component_scores = all_component_scores + red_component_scores\n","                all_region_sizes = all_region_sizes + red_component_sizes\n","\n","            if not white_component_scores:\n","                all_region_colors = all_region_colors + ['white']\n","                all_component_scores = all_component_scores + [np.nan]\n","                all_region_sizes = all_region_sizes + [np.nan]\n","            else:\n","                all_region_colors = all_region_colors + \\\n","                    (['white'] * len(white_component_scores))\n","                all_component_scores = all_component_scores + white_component_scores\n","                all_region_sizes = all_region_sizes + white_component_sizes\n","\n","            region_purity_after.append(all_component_scores)\n","            region_color_after.append(all_region_colors)\n","            region_sizes_after.append(all_region_sizes)\n","\n","            # Compute weighted purity scores over all regions, for white only, and for red only\n","\n","            total_red_sum = np.nansum(red_component_sizes)\n","            total_white_sum = np.nansum(white_component_sizes)\n","\n","            if not red_component_scores:\n","                red_region_weights = np.array([0])\n","                weighted_red_scores = np.array([0])\n","            else:\n","                # this vector should add to 1, as this is a normalization of the weights\n","                red_region_weights = np.divide(\n","                    np.array(red_component_sizes), total_red_sum)\n","                weighted_red_scores = np.multiply(\n","                    np.array(red_component_scores), red_region_weights)\n","\n","            if not white_component_scores:\n","                white_region_weights = np.array([0])\n","                weighted_white_scores = np.array([0])\n","            else:\n","                # this vector should add to 1, as this is a normalization of the weights\n","                white_region_weights = np.divide(\n","                    np.array(white_component_sizes), total_white_sum)\n","                weighted_white_scores = np.multiply(\n","                    np.array(white_component_scores), white_region_weights)\n","\n","            # Get weighted average over both regions together\n","            all_region_sum = np.nansum(all_region_sizes)\n","            all_region_weights = np.divide(\n","                np.array(red_component_sizes + white_component_sizes), all_region_sum)\n","            all_region_weighted_scores = np.multiply(\n","                np.array(red_component_scores + white_component_scores), all_region_weights)\n","\n","            weighted_purity_red_after.append(list(weighted_red_scores))\n","            weighted_purity_white_after.append(list(weighted_white_scores))\n","            weighted_purity_after.append(list(all_region_weighted_scores))\n","            weighted_red_sector_score_after.append(\n","                np.nansum(weighted_red_scores))\n","            weighted_white_sector_score_after.append(\n","                np.nansum(weighted_white_scores))\n","            weighted_sector_score_after.append(\n","                np.nansum(all_region_weighted_scores))\n","\n","            # Now, create the masks containing the initial_regions\n","            post_region_mask = np.maximum(post_red_region_mask.astype(\n","                np.uint8), 2*post_white_region_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","            post_boundary_mask = np.maximum(post_red_boundary_mask.astype(\n","                np.uint8), 2*post_white_boundary_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","            post_score_mask = np.maximum(post_red_score_mask.astype(\n","                np.uint8), 2*post_white_score_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","\n","            post_region_mask = np.pad(post_region_mask, IMAGE_PADDING)\n","            post_boundary_mask = np.pad(post_boundary_mask, IMAGE_PADDING)\n","            post_score_mask = np.pad(post_score_mask, IMAGE_PADDING)\n","\n","            # if SAVE_ALL_ANNOTATIONS is True:\n","            #     if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/cor_bounds/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', post_boundary_mask):\n","            #         raise IOError('Could not write image.')\n","            #     if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/cor_regions/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', post_region_mask):\n","            #         raise IOError('Could not write image.')\n","            #     if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/cor_bad/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', post_score_mask):\n","            #         raise IOError('Could not write image.')\n","            # plt.axis('off')\n","            # if SAVE_ALL_ANNOTATIONS is True:\n","            #     fig2.savefig(OUTPUT_CROPS_FOLDER + '/cor_partitions/' + file_dict[plate_name] + '/' + pathlib.Path(\n","            #         test_image).stem + '_c_' + str(this_index) + '.png', bbox_inches='tight', pad_inches=0)\n","            # plt.close(fig2)\n","\n","            #------------------------------------------------------------------\n","\n","            # PRINTING RESULTS OF COLONY\n","\n","            if not sector_scores:\n","                sector_scores = 0\n","                sector_ious = 0\n","            average_sector_score.append(np.mean(sector_scores))\n","            average_sector_iou.append(np.mean(sector_ious))\n","            #print('Colony ' + str(this_index))\n","            print('Estimated number of sectors: ' + str(total_sectors))\n","            all_sector_counts.append(total_sectors)\n","            print('Average sector score: ' + str(average_sector_score[-1]))\n","            print('Average sector score (IoU): ' + str(average_sector_iou[-1]))\n","\n","            corrected_white_region_sum.append(\n","                np.sum(np.logical_xor(corrected_colony_mask, all_sector_filled)))\n","            corrected_red_region_sum.append(np.sum(all_sector_filled))\n","            corrected_sector_region_sum.append(\n","                np.sum(all_sector_filled) / np.sum(corrected_colony_mask))\n","\n","            true_sector_count = 0\n","            true_sector_counts.append(true_sector_count)\n","            true_sector_region_sum.append(0)\n","            corrected_colony_mask_faded[corrected_colony_mask == 0] = 0\n","\n","            corrected_colony_mask_faded = np.pad(\n","                corrected_colony_mask_faded, IMAGE_PADDING)\n","            corrected_red_colony_mask_padded = np.pad(\n","                corrected_red_colony_mask, IMAGE_PADDING)\n","            corrected_sector_comp_mask = np.multiply(\n","                corrected_red_colony_mask_padded, corrected_colony_mask_faded)\n","\n","            #colony_image_padded = np.pad(colony_image, IMAGE_PADDING)\n","            #cv2_imshow(colony_mask_faded)\n","            # if SAVE_ALL_ANNOTATIONS is True:\n","            #     if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/sectors/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', corrected_colony_mask_faded):\n","            #         raise IOError('Could not write image.')\n","            #     if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/sector_comps/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', corrected_sector_comp_mask):\n","            #         raise IOError('Could not write image.')\n","\n","        # This ends the loop on the isolated colonies\n","\n","        # Ensure that the number of sectors are integers\n","\n","        # Construct a dataframe with the nubmer of sectors and the proportion of red present\n","\n","        all_sector_counts_array = np.array(all_sector_counts).astype(int)\n","        true_sector_counts = np.array(true_sector_counts).astype(int)\n","        #true_sector_counts = np.repeat(1,len(indiv_good))\n","        correct_sector_count = np.abs(\n","            true_sector_counts - all_sector_counts_array) == 0\n","\n","        sides_vert_top_array = np.array(sides_vert_top)\n","        sides_vert_bottom_array = np.array(sides_vert_bottom)\n","        sides_horz_left_array = np.array(sides_horz_left)\n","        sides_horz_right_array = np.array(sides_horz_right)\n","\n","        # Gather all data that that can be created as a numpy array\n","        d = {'Plate Name': plate_names,\n","             'Colony Number': colony_numbers.astype(int),\n","             'True # Sectors': true_sector_counts,\n","             'Initial # Regions': np.array(initial_region_counts).astype(int),\n","             'Pred # Sectors': all_sector_counts_array,\n","             'Correct # Sectors?': correct_sector_count,\n","             'White Area (Seg)': white_region_sum,\n","             'Red Area (Seg)': red_region_sum,\n","             'Colony Area (Seg)': (np.array(white_region_sum) + np.array(red_region_sum)),\n","             'White Area (Corr)': corrected_white_region_sum,\n","             'Red Area (Corr)': corrected_red_region_sum,\n","             'Colony Area (Corr)': (np.array(corrected_white_region_sum) + np.array(corrected_red_region_sum)),\n","             'Avg Sector Score': average_sector_score,\n","             'Avg Sector Score (IoU)': average_sector_iou,\n","             'Side Top': sides_vert_top_array,\n","             'Side Bottom': sides_vert_bottom_array,\n","             'Side Left': sides_horz_left_array,\n","             'Side Right': sides_horz_right_array,\n","             '1 Comp': np.array(colony_is_connected),\n","             '1 Comp (Approx)': np.array(colony_is_approx_connected),\n","             'Bound Comp': np.array(boundary_is_connected),\n","             'No Holes': np.array(colony_is_whole),\n","             'Approx Convex': np.array(colony_is_approx_convex),\n","             'Approx Circle': np.array(colony_is_approx_circular),\n","             'Hausdorff Convex': np.array(hausdorff_dist_convex),\n","             'Hausdorff Circle': np.array(hausdorff_dist_circle)}\n","\n","        # #Gather data based on what else we used as input\n","        # if USE_EXPERT_COUNTS is True:\n","        #     d['Quantifiable'] = np.array(quantifiable_colony)\n","        #     d['Quantifiable Cured'] = np.array(quantifiable_cured)\n","        #     d['Quantifiable Stable'] = np.array(quantifiable_stable)\n","        #     d['Quantifiable Sectored'] = np.array(quantifiable_sectored)\n","\n","        df = pd.DataFrame(data=d)\n","\n","        # Gather data that could NOT be stored as a numpy array, such as nested lists\n","\n","        df['(BC) Regional Color Classes'] = list(region_color_before)\n","        df['(BC) Regional Sizes'] = list(region_sizes_before)\n","        df['(BC) Regional Purity Scores'] = list(region_purity_before)\n","        df['(BC) Red Purity Scores Weighted'] = list(\n","            weighted_purity_red_before)\n","        df['(BC) White Purity Scores Weighted'] = list(\n","            weighted_purity_white_before)\n","        df['(BC) Weighted Red Average Score'] = weighted_red_sector_score_before\n","        df['(BC) Weigted White Average Score'] = weighted_white_sector_score_before\n","        df['(BC) Weighted Full Average Score'] = weighted_sector_score_before\n","        df['(BC) Cured'] = cured_colony_before\n","        df['(BC) Stable'] = stable_colony_before\n","\n","        df['(AC) Regional Color Classes'] = list(region_color_after)\n","        df['(AC) Regional Sizes'] = list(region_sizes_after)\n","        df['(AC) Regional Purity Scores'] = list(region_purity_after)\n","        df['(AC) Red Purity Scores Weighted'] = list(\n","            weighted_purity_red_after)\n","        df['(AC) White Purity Scores Weighted'] = list(\n","            weighted_purity_white_after)\n","        df['(AC) Weighted Red Average Score'] = weighted_red_sector_score_after\n","        df['(AC) Weighted White Average Score'] = weighted_white_sector_score_after\n","        df['(AC) Weighted Full Average Score'] = weighted_sector_score_after\n","        df['(AC) Cured'] = cured_colony_after\n","        df['(AC) Stable'] = stable_colony_after\n","\n","        df.to_pickle(TRAIN_OUTPUT_TABLE_FOLDER + '/' + str(plate_stem) + '.pkl')\n"]},{"cell_type":"markdown","metadata":{"id":"AZ10Uz1BNPbN"},"source":["## Merge tables into one"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P5Jw5Kh2NPbN"},"outputs":[],"source":["# Read in all the files of data\n","sorted_tables = sorted(glob.glob(TRAIN_OUTPUT_TABLE_FOLDER + '/' + '*'))\n","print(sorted_tables)\n","\n","first_table = True\n","\n","for this_table in sorted_tables:\n","    this_table_data = pd.read_pickle(this_table)\n","    if first_table is True:\n","        first_table = False\n","        all_table_data = copy.deepcopy(this_table_data)\n","    else:\n","        all_table_data = pd.concat([all_table_data, this_table_data], axis=0, ignore_index=True)\n","\n","all_table_data.to_pickle(TRAIN_OUTPUT_FOLDER + '/' + str(WEIGHTS_FILE) + '_colony_data.pkl')\n"]},{"cell_type":"markdown","metadata":{"id":"F4uhooNlNPbO"},"source":["## Load data table and append the true data (if any) as additional columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"meDs7eP8NPbO"},"outputs":[],"source":["colony_data = pd.read_pickle(TRAIN_OUTPUT_FOLDER + '/' + str(WEIGHTS_FILE) + '_colony_data.pkl')\n","\n","#print(colony_data)\n","all_plate_names = colony_data['Plate Name'].unique()\n","all_sector_values = list(range(0, int(np.max(colony_data['Pred # Sectors']))+1))\n","\n","# Include true sector counts if available\n","if USE_TRUE_SECTOR_COUNTS is True:\n","\n","    # Read in table with true sector counts\n","    true_sector_counts = pd.read_csv(TRAIN_OUTPUT_FOLDER + '/true_colony_data.csv')\n","    # load file containing true sector counts\n","    colony_data['True # Sectors'] = true_sector_counts['True # Sectors']\n","    # insert the true sector counts in the data\n","    matching_sector_counts = colony_data['True # Sectors'] == colony_data['Pred # Sectors']\n","    # compare the true and predicted sector counts\n","    colony_data['Correct # Sectors?'] = matching_sector_counts\n","    # mark where the counts match and insert this into the data\n","\n","if USE_QUANTIFIABLE_COUNTS_FROM_TABLE is True:\n","    true_quant_colonies = pd.read_csv(TRAIN_OUTPUT_FOLDER + '/true_quantifiable_colonies.csv')\n","    # load file containing whether colony is cured\n","    colony_data['Quantifiable'] = true_quant_colonies['Quantifiable']\n","    # insert this data into the original table\n","\n","if USE_TRUE_CURED_COLONIES_FROM_TABLE is True:\n","    # Read in table with true cured colonies\n","    true_cured_colonies = pd.read_csv(TRAIN_OUTPUT_FOLDER + '/true_cured_colonies.csv')\n","    # load file containing whether colony is cured\n","    colony_data['Is Cured?'] = true_cured_colonies['Is Cured?']\n","    # insert this data into the original table\n","\n","if (USE_TRUE_SECTOR_COUNTS is True) & (USE_QUANTIFIABLE_COUNTS_FROM_TABLE is True) & (USE_TRUE_CURED_COLONIES_FROM_TABLE is True):\n","    colony_data['Quantifiable Cured'] = (colony_data['Quantifiable']) & (colony_data['Is Cured?'])\n","    colony_data['Quantifiable Stable'] = (colony_data['Quantifiable']) & (colony_data['True # Sectors'] == 0)\n","    colony_data['Quantifiable Sectored'] = (colony_data['Quantifiable']) & (colony_data['True # Sectors'] > 0) & (~colony_data['Is Cured?'])\n","\n","colony_data.to_pickle(TRAIN_OUTPUT_FOLDER + '/' + str(WEIGHTS_FILE) + '_colony_data.pkl')\n","\n","colony_data.to_csv(TRAIN_OUTPUT_FOLDER + '/' + str(WEIGHTS_FILE) + '_colony_data.csv')\n","colony_data\n"]},{"cell_type":"markdown","metadata":{"id":"Oc09qA7wNPbO"},"source":["## Add [PSI] labels to classified colonies using data obtained from the classification step"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qOgZGaoiNPbO"},"outputs":[],"source":["colony_states_before = np.array(\n","    ['UNFILLED' for i in range(0, len(colony_data))])\n","colony_states_after = np.array(\n","    ['UNFILLED' for i in range(0, len(colony_data))])\n","colony_states_true = np.array(['UNFILLED' for i in range(0, len(colony_data))])\n","#colony_states_set = set(colony_states)\n","#print(colony_states_set)\n","\n","max_sector_count_before = max(colony_data['Initial # Regions'])\n","max_sector_count_after = max(colony_data['Pred # Sectors'])\n","max_sector_count_true = max(colony_data['True # Sectors'])\n","\n","max_sector_count_all = max(\n","    [max_sector_count_before, max_sector_count_after, max_sector_count_true])\n","\n","# [PSI+]: Get all colonies with no red regions\n","\n","colony_states_before[colony_data['(BC) Stable']] = '[PSI+]'\n","colony_states_after[colony_data['(AC) Stable']] = '[PSI+]'\n","#colony_states_true[colony_data['Is Stable?']] = '[PSI+]'\n","\n","# [psi-]: Get all quantifiable colonies with no white regions\n","\n","colony_states_before[colony_data['(BC) Cured']] = '[psi-]'\n","colony_states_after[colony_data['(AC) Cured']] = '[psi-]'\n","#colony_states_true[colony_data['Is Cured?']] = '[psi-]'\n","\n","# Sx: Get all quantifiable colonies with at least 1 white region and exactly x red regions\n","\n","for num_regions in range(1, max_sector_count_all+1):\n","    colony_states_before[(~colony_data['(BC) Cured']) & (~colony_data['(BC) Stable']) & (\n","        colony_data['Initial # Regions'] == num_regions)] = str('S' + str(num_regions))\n","    colony_states_after[(~colony_data['(AC) Cured']) & (~colony_data['(AC) Stable']) & (\n","        colony_data['Pred # Sectors'] == num_regions)] = str('S' + str(num_regions))\n","    #colony_states_true[(~colony_data['Is Cured?']) & (~colony_data['Is Stable?']) & (\n","    #    colony_data['True # Sectors'] == num_regions).astype(bool)] = str('S' + str(num_regions))\n","\n","#print(np.unique(colony_states_before))\n","#print(np.unique(colony_states_after))\n","#print(np.unique(colony_states_true))\n","\n","unmarked_locations = np.where(colony_states_true == 'UNFILLED')\n","\n","# Make corrections to the table for unfilled locations\n","\n","\n","# Display any colony locations what are marked as UNFILLED\n","\n","colony_row = colony_data.iloc[unmarked_locations]\n","#print(colony_row)\n","#print(colony_row.index)\n","\n","#print(colony_states_before)\n","\n","# If every location has been filled, then add these to the merged table\n","colony_data['Label Before'] = colony_states_before\n","colony_data['Label After'] = colony_states_after\n","#colony_data['Label True'] = colony_states_true\n"]},{"cell_type":"markdown","metadata":{"id":"ZAqM9u9qNPbO"},"source":["## Plots"]},{"cell_type":"markdown","metadata":{"id":"EvBEYSlFNPbP"},"source":["### Predictions Only"]},{"cell_type":"markdown","metadata":{"id":"1k6WXhuUNPbP"},"source":["#### Colony States (no sector counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_A_ggFUcNPbP"},"outputs":[],"source":["max_initial = np.max(colony_data['Initial # Regions'])\n","max_pred = np.max(colony_data['Pred # Sectors'])\n","# max_true = np.max(colony_data['True # Sectors'])\n","max_all = np.max([max_initial, max_pred])\n","# diff_count_before = np.abs(colony_data['Initial # Regions'] - colony_data['True # Sectors'])\n","# diff_count_after = np.abs(colony_data['Pred # Sectors'] - colony_data['True # Sectors'])\n","\n","label_names = ['[PSI+]', '[psi-]', 'Sectored']\n","\n","initial_correct_counts = []\n","post_correct_counts = []\n","#true_correct_counts = []\n","all_counts = []\n","\n","\n","# print(np.unique(colony_data['Label True']))\n","\n","# Gather [PSI+] counts\n","#true_white_labels = colony_data[(colony_data['Label True'] == '[PSI+]')]\n","correct_white_labels_before = colony_data[(\n","    colony_data['Label Before'] == '[PSI+]')]\n","correct_white_labels_after = colony_data[(\n","    colony_data['Label After'] == '[PSI+]')]\n","\n","initial_correct_counts.append(len(correct_white_labels_before))\n","post_correct_counts.append(len(correct_white_labels_after))\n","# true_correct_counts.append(len(true_white_labels))\n","\n","# Gather [psi-] counts\n","#true_red_labels = colony_data[(colony_data['Label True'] == '[psi-]')]\n","correct_red_labels_before = colony_data[(\n","    colony_data['Label Before'] == '[psi-]')]\n","correct_red_labels_after = colony_data[(\n","    colony_data['Label After'] == '[psi-]')]\n","\n","initial_correct_counts.append(len(correct_red_labels_before))\n","post_correct_counts.append(len(correct_red_labels_after))\n","# true_correct_counts.append(len(true_red_labels))\n","\n","\n","# Gather sectored counts\n","correct_sector_labels_before = colony_data[(\n","    colony_data['Label Before'].str.startswith('S'))]\n","correct_sector_labels_after = colony_data[(\n","    colony_data['Label After'].str.startswith('S'))]\n","\n","initial_correct_counts.append(len(correct_sector_labels_before))\n","post_correct_counts.append(len(correct_sector_labels_after))\n","# max_sector_counts = max([np.nanmax(colony_data['Initial # Regions'].astype(int)), np.nanmax(colony_data['Pred # Sectors'].astype(int)), np.nanmax(colony_data['True # Sectors'].astype(int))])\n","# print(max_sector_counts)\n","\n","# for this_num_sectors in range(1, max_sector_counts+1):\n","#     #true_sector_labels = colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors))]\n","#     correct_sector_labels_before = colony_data[(colony_data['Label Before'] == 'S'+str(this_num_sectors))]\n","#     correct_sector_labels_after = colony_data[(colony_data['Label After'] == 'S'+str(this_num_sectors))]\n","\n","#     initial_correct_counts.append(len(correct_sector_labels_before))\n","#     post_correct_counts.append(len(correct_sector_labels_after))\n","#     #true_correct_counts.append(len(true_sector_labels))\n","\n","# print(colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors)) & (colony_data['Label After'] == 'S'+str(this_num_sectors))])\n","#sector_labels = ['S'+str(i) for i in (range(1, max_sector_counts+1))]\n","# print(sector_labels)\n","#label_names = label_names + sector_labels\n","# print(label_names)\n","x = np.arange(len(label_names))\n","# print(len(x))\n","# print(len(initial_correct_counts))\n","\n","\n","width = 0.25  # the width of the bars\n","\n","fig, ax = plt.subplots(figsize=(12, 5), sharey=True)\n","#x - width/2\n","ax.set_ylim(bottom=0, top=max(initial_correct_counts + post_correct_counts)+50)\n","rects1 = ax.bar(x - width/2, initial_correct_counts, width,\n","                label='Original Predictions', color='blue')\n","rects2 = ax.bar(x+width/2, post_correct_counts, width,\n","                label='With Purity Correction', color='red')\n","#rects2 = ax.bar(x + width/2, all_counts, width, label='All Colonies', color='red')\n","#rects3 = ax.bar(x + width, true_correct_counts, width, label='Manual Counts', color='green')\n","\n","# print(true_single_frequency)\n","# print(pred_single_frequency)\n","\n","ax.set_xlabel('Colony States')\n","ax.set_ylabel('Frequency')\n","ax.set_title('Classified Colonies', fontsize=16)\n","ax.xaxis.label.set_fontsize(14)\n","ax.yaxis.label.set_fontsize(14)\n","ax.set_xticks(np.arange(0, 3, step=1))\n","ax.set_xticklabels(label_names)\n","ax.tick_params(axis='both', labelsize=12)\n","ax.legend(loc='best')\n","\n","xtickslocs = ax.get_xticks()\n","print(xtickslocs)\n","\n","addlabels_centered(xtickslocs-width/2, initial_correct_counts, 9)\n","addlabels_centered(xtickslocs+width/2, post_correct_counts, 9)\n","#addlabels_pred(x, all_counts, 10)\n","#addlabels_truemarks(x, true_correct_counts, 9)\n","\n","ax.axvline(x=0.5, color='k', linestyle='--')\n","ax.axvline(x=1.5, color='k', linestyle='--')\n","\n","fig.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"hM7HRJVNNPbP"},"source":["#### Colony States (with sector counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"JvVspExVNPbP"},"outputs":[],"source":["max_initial = np.max(colony_data['Initial # Regions'])\n","max_pred = np.max(colony_data['Pred # Sectors'])\n","# max_true = np.max(colony_data['True # Sectors'])\n","max_all = np.max([max_initial, max_pred])\n","# diff_count_before = np.abs(colony_data['Initial # Regions'] - colony_data['True # Sectors'])\n","# diff_count_after = np.abs(colony_data['Pred # Sectors'] - colony_data['True # Sectors'])\n","\n","initial_correct_counts = []\n","post_correct_counts = []\n","#true_correct_counts = []\n","all_counts = []\n","\n","label_names = ['[PSI+]', '[psi-]']\n","\n","# print(np.unique(colony_data['Label True']))\n","\n","# Gather [PSI+] counts\n","#true_white_labels = colony_data[(colony_data['Label True'] == '[PSI+]')]\n","correct_white_labels_before = colony_data[(\n","    colony_data['Label Before'] == '[PSI+]')]\n","correct_white_labels_after = colony_data[(\n","    colony_data['Label After'] == '[PSI+]')]\n","\n","initial_correct_counts.append(len(correct_white_labels_before))\n","post_correct_counts.append(len(correct_white_labels_after))\n","# true_correct_counts.append(len(true_white_labels))\n","\n","# Gather [psi-] counts\n","#true_red_labels = colony_data[(colony_data['Label True'] == '[psi-]')]\n","correct_red_labels_before = colony_data[(\n","    colony_data['Label Before'] == '[psi-]')]\n","correct_red_labels_after = colony_data[(\n","    colony_data['Label After'] == '[psi-]')]\n","\n","initial_correct_counts.append(len(correct_red_labels_before))\n","post_correct_counts.append(len(correct_red_labels_after))\n","# true_correct_counts.append(len(true_red_labels))\n","\n","\n","# Gather sectored counts\n","max_sector_counts = max([np.nanmax(colony_data['Initial # Regions'].astype(int)), np.nanmax(\n","    colony_data['Pred # Sectors'].astype(int)), np.nanmax(colony_data['True # Sectors'].astype(int))])\n","# print(max_sector_counts)\n","\n","for this_num_sectors in range(1, max_sector_counts+1):\n","    #true_sector_labels = colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors))]\n","    correct_sector_labels_before = colony_data[(\n","        colony_data['Label Before'] == 'S'+str(this_num_sectors))]\n","    correct_sector_labels_after = colony_data[(\n","        colony_data['Label After'] == 'S'+str(this_num_sectors))]\n","\n","    initial_correct_counts.append(len(correct_sector_labels_before))\n","    post_correct_counts.append(len(correct_sector_labels_after))\n","    # true_correct_counts.append(len(true_sector_labels))\n","\n","# print(colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors)) & (colony_data['Label After'] == 'S'+str(this_num_sectors))])\n","sector_labels = ['S'+str(i) for i in (range(1, max_sector_counts+1))]\n","# print(sector_labels)\n","label_names = label_names + sector_labels\n","# print(label_names)\n","x = np.arange(len(label_names))\n","# print(len(x))\n","# print(len(initial_correct_counts))\n","\n","\n","width = 0.25  # the width of the bars\n","\n","fig, ax = plt.subplots(figsize=(12, 5), sharey=True)\n","#x - width/2\n","ax.set_ylim(bottom=0, top=max(initial_correct_counts + post_correct_counts)+50)\n","rects1 = ax.bar(x - width/2, initial_correct_counts, width,\n","                label='Original Predictions', color='blue')\n","rects2 = ax.bar(x+width/2, post_correct_counts, width,\n","                label='With Purity Correction', color='red')\n","#rects2 = ax.bar(x + width/2, all_counts, width, label='All Colonies', color='red')\n","#rects3 = ax.bar(x + width, true_correct_counts, width, label='Manual Counts', color='green')\n","\n","# print(true_single_frequency)\n","# print(pred_single_frequency)\n","\n","ax.set_xlabel('Colony States')\n","ax.set_ylabel('Frequency')\n","ax.set_title('Classified Colonies', fontsize=16)\n","ax.xaxis.label.set_fontsize(14)\n","ax.yaxis.label.set_fontsize(14)\n","ax.set_xticks(np.arange(0, max_sector_counts+2, step=1))\n","ax.set_xticklabels(label_names)\n","ax.tick_params(axis='both', labelsize=12)\n","ax.legend(loc='best')\n","\n","xtickslocs = ax.get_xticks()\n","print(xtickslocs)\n","\n","addlabels_centered(xtickslocs-width/2, initial_correct_counts, 9)\n","addlabels_centered(xtickslocs+width/2, post_correct_counts, 9)\n","#addlabels_pred(x, all_counts, 10)\n","#addlabels_truemarks(x, true_correct_counts, 9)\n","\n","ax.axvline(x=0.5, color='k', linestyle='--')\n","ax.axvline(x=1.5, color='k', linestyle='--')\n","\n","fig.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"3yC2OTfFM2k9"},"source":["# Segmentation and Classification of Testing Images"]},{"cell_type":"markdown","metadata":{"id":"qHs3tflgjUs-"},"source":["## Get names of images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"YDRB_hKBjW8J"},"outputs":[],"source":["test_images = sorted(glob.glob(REAL_IMAGE_FOLDER + '/' + '*'))\n","print('Number of images found: ' + str(len(test_images)))"]},{"cell_type":"markdown","metadata":{"id":"OYfyP1mfjZ-Z"},"source":["## Segment Testing Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fCu53Hydjb3t"},"outputs":[],"source":["# Commented out IPython magic to ensure Python compatibility.\n","# Code for image segmentation (involves Python and Octave code (requires oct2py module))\n","# 1. Python - Ready u_net for input.\n","# 2. Python - Feed image to U-Net.\n","# 3. Python - Get output segmentation of image.\n","# 4. Octave - Use isolated colonies to estimate a range of radii to search for circular colonies.\n","# 5. Octave - Obtain centers and radii in image with circle Hough transform.\n","# 6. Octave (or Python maybe pandas) - Save csv files of circle locations\n","# and sizes in each image respectively.\n","# 7. Octave (or Python maybe matplotlib) - Make mask of image showing\n","  #where the circles are found.\n","# 8. Repeat steps 2-7 for each image\n","\n","if GET_TESTING_SEGS is True:\n","\n","    #     %matplotlib inline\n","\n","    for this_image in test_images:\n","\n","        # Steps 1-3: get output segmentation and save it\n","\n","        this_plate = pathlib.PurePath(this_image)\n","        plate_name = this_plate.name\n","\n","        print('Reading plate: ' + str(plate_name))\n","\n","        x = read_image(this_image)\n","\n","        # Predict the class of each pixel, and partition output the same way\n","        p = model.predict(np.expand_dims(x, axis=0))[0]\n","        p = np.argmax(p, axis=-1)\n","        p = np.expand_dims(p, axis=-1)\n","        p = p * (255/(NUM_CLASSES-1))\n","        print(p.shape)\n","        \n","        #print(np.max(p))\n","        p = p.astype(np.int64)\n","        print(np.unique(p))\n","        #print(np.max(p))\n","\n","        if SWAP_CLASS_LABELS is True:\n","            p = swap_class_labels(p, 127, 255)\n","\n","        p_full = tf.identity(p).numpy()\n","        in_class = tf.math.greater(tf.constant(\n","            p_full), tf.constant([0], dtype=tf.int64)).numpy()\n","\n","        p = p.astype(np.uint8)\n","\n","        # Make sure that white pixels are white and red pxels are gray\n","\n","        \n","            \n","        # white pixels (should be 255)\n","        p_1 = tf.math.equal(tf.constant(p_full),\n","                            tf.constant([255], dtype=tf.int64)).numpy().astype(np.uint8) * 255\n","        # red pixels (should be 127)\n","        p_2 = tf.math.equal(tf.constant(p_full),\n","                            tf.constant([127], dtype=tf.int64)).numpy().astype(np.uint8) * 255\n","\n","\n","        p_full = 255 * in_class.astype(np.uint8)\n","        #print(p.shape)\n","\n","        cv2_imshow(p)\n","\n","        # Show and/or save image\n","        #plt.imshow(p * 255/(num_classes-1))\n","        #cv2.cvtColor(p * 255/(num_classes-1), cv2.COLOR_BGR2RGB)\n","        #plt.imshow(cv2.cvtColor(p * 255/(num_classes-1), cv2.COLOR_BGR2GRAY))\n","        #plt.imshow(p, cmap='binary')\n","        #plt.show()\n","        #print(np.unique(p[20:40, 900:920]))\n","        my_image = PIL.Image.fromarray(np.squeeze(p, axis=-1), \"L\")\n","        #display(my_image.resize((256,256)))\n","        my_image.save(TEST_SEG_FOLDER + '/' + this_plate.stem + '.png')\n","\n","        # Steps 4-6: Run Matlab code in Octave to use CHT, and\n","        # store colony location data\n","        octave.feval('get_circular_data.m', this_image, TEST_SEG_FOLDER +\n","                     '/' + this_plate.stem + '.png', TEST_CIRCLE_DATA_FOLDER)\n","        try:\n","            radii_table = pd.read_csv(\n","                TEST_CIRCLE_DATA_FOLDER + '/' + this_plate.stem + '.csv', header=None)\n","            radii_table.columns = ['Colony', 'Center (x)', 'Center (y)', 'Radius',\n","                                   'Top Left (x)', 'Top Left (y)', 'Width',\n","                                   'Height', 'Estimated Center (x)',\n","                                   'Estimated Center (y)']\n","            radii_table.to_csv(TEST_CIRCLE_DATA_FOLDER +\n","                               '/' + this_plate.stem + '.csv')\n","\n","            # Step 7: Plot the image with the circles overlayed, and save it\n","            #radii_table = pd.read_csv(TEST_CIRCLE_DATA_FOLDER + '/' + this_plate.stem + '.csv')\n","\n","            fig, ax = plt.subplots()\n","            plt.imshow(cv2.cvtColor(x, cv2.COLOR_BGR2RGB))\n","            # 96 old default\n","            # unknown new default as of May 2023\n","            fig.set_size_inches(1024/96, 1024/96)\n","            for index, row in radii_table.iterrows():\n","                full_circle = Circle((row['Estimated Center (x)'], row['Estimated Center (y)']),\n","                                     radius=row['Radius'], color='blue',\n","                                     fill=False, linewidth=1, alpha=0.9)\n","                ax.add_patch(full_circle)\n","            plt.axis('off')\n","            plt.savefig(TEST_CIRCLE_FOLDER + '/' + pathlib.Path(this_image).stem +\n","                        '.jpg', bbox_inches='tight', pad_inches=0)\n","            plt.close()\n","\n","        except pd.errors.EmptyDataError:\n","            # If an error is about to be thrown due to an empty csv file,\n","            # run these lines instead\n","            print('No colonies were detected.  Skipping this image.')\n","            my_table_columns = ['Colony', 'Center (x)', 'Center (y)', 'Radius', 'Top Left (x)',\n","                                'Top Left (y)', 'Width', 'Height',\n","                                'Estimated Center (x)',\n","                                'Estimated Center (y)']\n","            radii_table = pd.DataFrame(columns=my_table_columns)\n","            radii_table.to_csv(TEST_CIRCLE_DATA_FOLDER +\n","                               '/' + this_plate.stem + '.csv')\n","\n","            # Step 7: Plot the image with the circles overlayed, and save it\n","            #radii_table = pd.read_csv(test_circle_data_folder + '/' + this_plate.stem + '.csv')\n","\n","            fig, ax = plt.subplots()\n","            plt.imshow(cv2.cvtColor(x, cv2.COLOR_BGR2RGB))\n","            # set because the screen pixel size is 96 dpi\n","            fig.set_size_inches(1024/96, 1024/96)\n","            plt.axis('off')\n","            plt.savefig(TEST_CIRCLE_FOLDER + '/' + pathlib.Path(this_image).stem +\n","                        '.jpg', bbox_inches='tight', pad_inches=0)\n","            plt.close()\n","        #print(radii_table)\n","        #raise FileExistsError('The script finished without errors.')\n","        #octave.run('octave_test.m')\n"]},{"cell_type":"markdown","metadata":{"id":"ZfgURz4WjF5O"},"source":["## Create dictionary for reference to images, and make directories to store things per plate"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xdO2zEHhjPXr"},"outputs":[],"source":["test_images = sorted(glob.glob(REAL_IMAGE_FOLDER + '/' + '*'))\n","print('Number of images found: ' + str(len(test_images)))\n","\n","test_CHT_images = sorted(glob.glob(TEST_CIRCLE_FOLDER + '/' + '*'))\n","print('Number of images found: ' + str(len(test_CHT_images)))\n","\n","test_image_pairs = tuple(zip(test_images, test_CHT_images))\n","print(test_image_pairs)\n","\n","\n","# Create reference table for plate names, and store it as a csv file in\n","# the main annotation directory\n","file_dict = {}\n","for this_plate_number in range(1, len(test_images)+1):\n","    this_plate = pathlib.PurePath(test_images[this_plate_number - 1])\n","    plate_name = this_plate.name\n","    plate_stem = os.path.splitext(plate_name)[0]\n","    file_dict[plate_name] = 'Plate ' + str(this_plate_number)\n","print(file_dict)\n","file_items = file_dict.items()\n","file_list = list(file_items)\n","file_df = pd.DataFrame(file_items, columns = ['Plate Name', 'Folder Name'])\n","print(file_df)\n","\n","\n","# If you are trying to save the crops and annotations of each colony, the below will run as well.\n","\n","if SAVE_ALL_ANNOTATIONS is True:\n","\n","    # Save this table as a csv file\n","    file_df.to_csv(OUTPUT_CROPS_FOLDER + '/Plate_References.csv')\n","\n","    for index, row in file_df.iterrows():\n","\n","        # Make subdirectories for each annotation class, organized by plate\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/raw/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/raw/' + row['Folder Name'])\n","            # where the original colonies are cropped and stored\n","\n","        if USE_EXPERT_COUNTS is True:\n","            if not os.path.exists(OUTPUT_CROPS_FOLDER + '/counted/' + row['Folder Name']):\n","                os.makedirs(OUTPUT_CROPS_FOLDER + '/counted/' + row['Folder Name'])\n","                # where the original quantifiable colonies are cropped and stored\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/circles/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/circles/' + row['Folder Name'])\n","            # same as before, but a circle is overlayed on the colony\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/segs/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/segs/' + row['Folder Name'])\n","            # the output from the U-Net segmentation such that only\n","            # nonzero pixels in the circle are kept\n","\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/init_regions/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/init_regions/' + row['Folder Name'])\n","            # A segmentation outlining the possible sector-like regions\n","            # of the colony, both red and white\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/init_bounds/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/init_bounds/' + row['Folder Name'])\n","            # The raw segmentation containing only the boundary of the colony\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/init_partitions/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/init_partitions/' + row['Folder Name'])\n","            # same as the raw segmentation, but with lines annotated\n","            # to represent locations of sector borders\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/init_bad/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/init_bad/' + row['Folder Name'])\n","            # A segmentation outlining the sector-like regions that\n","            #failed the consistency check\n","\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_segs/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_segs/' + row['Folder Name'])\n","            # the output from the U-Net segmentation such that only\n","            # nonzero pixels in the circle are kept\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_bounds/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_bounds/' + row['Folder Name'])\n","            # The corrected segmentation containing only the boundary of the colony\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_regions/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_regions/' + row['Folder Name'])\n","            # the output from the U-Net segmentation such that only\n","            # nonzero pixels in the circle are kept\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_partitions/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_partitions/' + row['Folder Name'])\n","            # same as the raw segmentation, but with lines annotated\n","            # to represent locations of sector borders\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/cor_bad/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/cor_bad/' + row['Folder Name'])\n","            # A segmentation outlining the sector-like regions that failed\n","            # the consistency check\n","\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/sectors/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/sectors/' + row['Folder Name'])\n","            # the output containing the regions in the segmentation where\n","            # a sector is predicted\n","\n","        if not os.path.exists(OUTPUT_CROPS_FOLDER + '/sector_comps/' + row['Folder Name']):\n","            os.makedirs(OUTPUT_CROPS_FOLDER + '/sector_comps/' + row['Folder Name'])\n","            # same as before, but only red pxieks in the segmentation are considered\n"]},{"cell_type":"markdown","metadata":{"id":"rsiJC8lrvAsR"},"source":["## Classify Colonies in Testing Images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P49J-mR6vDEy"},"outputs":[],"source":["# Code for colony classification (this should be all python code)\n","# 1. Read in image and corresponding segmentation.\n","# 2. Read in csv files containing circle locations.\n","# 3. For each row in the csv file, crop out the circular region, estimate size.\n","# 4. Restrict data collection to pixels within the circle detected, exclusing all other pixels.\n","# 5. Split the components of the image into red, white and background.\n","# 6. Get boundary components of the colony, check for consistency.\n","# 7. Output predicted number of sectors and their sizes after the consistency check.\n","# 8. Save the cropping of the colony in a few ways:\n","#   - the raw colony\n","#   - the raw colony with circle overlayed\n","#   - the segmentation of the colony within the circular region\n","#   - the segmentation of the colony with lines drawn on the image to repreent sector borders\n","#   - the predicted sector like regions, where each sector is a different shade of gray.\n","#   - similar to the previous, but keeping pixels classified only as red pixels.\n","#   - the segmentation that is corrected following the consistency check\n","#     (possibly doing an additional check on the white pixels)\n","# 9. Save data on the colony itself, including the sector information,\n","#    to a row in a table.\n","# 10. Save the table to a csv file.\n","# 11. Repeat all steps above for each image.\n","\n","# Issues to work on:\n","# Verify that the purity metric is properly being utilized\n","# Figure out what to do with the holes inside colony segmentations.\n","#   -- A hole has its own boundary, so could look for the boundary of the hole.\n","#   -- The boundary of the hole MUST be smaller than the boundary of the entire colony\n","#   -- Find all connected compoents of the boundary, then exclude the LARGEST one.\n","#   -- For all other boundary components, these are expected to be the holes.\n","#      You need a procedure to fill them.\n","#   -- The procedure could be as simple as filling the hole with the class\n","#      pertaining to the most common pixel on the boundary.\n","\n","# Implementation already existing:\n","\n","\n","if CLASSIFY_TESTING_COLONIES is True:\n","\n","    #     %matplotlib inline\n","\n","    starting_image = True\n","\n","    if USE_EXPERT_COUNTS is True:\n","        dot_quant_images = sorted(\n","            glob.glob(ADDITIONAL_DATA_FOLDER + '/Quant/' + '*'))\n","        dot_state_images = sorted(\n","            glob.glob(ADDITIONAL_DATA_FOLDER + '/State/' + '*'))\n","\n","    # Run each plate through the classification pipeline\n","\n","    for (test_image, CHT_image) in test_image_pairs:\n","\n","        # Get plate name\n","        this_plate = pathlib.PurePath(test_image)\n","        plate_name = this_plate.name\n","        plate_stem = os.path.splitext(plate_name)[0]\n","\n","        print('Plate: ' + str(plate_name) + ':')\n","        if SAVE_ALL_ANNOTATIONS is True:\n","            print('Annotations will be saved within subfolders named ' +\n","                  \"\\'\" + file_dict[plate_name] + \"\\'\")\n","\n","        # Read images of the plate\n","        x = read_image(test_image)\n","        x_CHT = read_image(CHT_image)\n","\n","        # initialize lists for storing values\n","        all_cropped_colonies = []\n","\n","        # Sizes of regions in pixels\n","        white_region_sum = []\n","        red_region_sum = []\n","        colony_region_sum = []\n","        sector_region_sum = []\n","\n","        corrected_white_region_sum = []\n","        corrected_red_region_sum = []\n","        corrected_sector_region_sum = []\n","\n","        true_white_region_sum = []\n","        true_red_region_sum = []\n","        true_colony_region_sum = []\n","        true_sector_region_sum = []\n","\n","        # Counting sectors\n","        initial_region_counts = []\n","        all_sector_counts = []\n","        true_sector_counts = []\n","\n","        boundary_region_sum = []\n","        colony_prop_sum = []\n","\n","        # Purity scores for regions and colonies\n","        average_sector_score = []\n","        average_sector_iou = []\n","\n","        weighted_sector_score_before = []\n","        weighted_red_sector_score_before = []\n","        weighted_white_sector_score_before = []\n","\n","        weighted_sector_score_after = []\n","        weighted_red_sector_score_after = []\n","        weighted_white_sector_score_after = []\n","\n","        # Bounding box info for colonies in images\n","        sides_vert_top = []\n","        sides_vert_bottom = []\n","        sides_horz_left = []\n","        sides_horz_right = []\n","\n","        # Test lists\n","        colony_is_connected = []\n","        colony_is_approx_connected = []\n","        boundary_is_connected = []\n","        colony_is_whole = []\n","        boundary_is_hamilton = []\n","        colony_is_approx_convex = []\n","        colony_is_approx_circular = []\n","        hausdorff_dist_convex = []\n","        hausdorff_dist_circle = []\n","\n","        # Lists to store purity scores of each region and the color of the region\n","        region_purity_before = []\n","        region_color_before = []\n","        region_sizes_before = []\n","\n","        weighted_purity_before = []\n","        weighted_purity_red_before = []\n","        weighted_purity_white_before = []\n","\n","        region_purity_after = []\n","        region_color_after = []\n","        region_sizes_after = []\n","\n","        weighted_purity_after = []\n","        weighted_purity_red_after = []\n","        weighted_purity_white_after = []\n","\n","        cured_colony_before = []\n","        cured_colony_after = []\n","\n","        stable_colony_before = []\n","        stable_colony_after = []\n","\n","        # Load images here if using quantifable colony data/annotations\n","        if USE_EXPERT_COUNTS is True:\n","            x_quant = read_image(ADDITIONAL_DATA_FOLDER +\n","                                 '/Quant/' + plate_stem + '.tif')\n","            x_state = read_image(ADDITIONAL_DATA_FOLDER +\n","                                 '/State/' + plate_stem + '.tif')\n","            quantifiable_colony = []\n","            quantifiable_cured = []\n","            quantifiable_stable = []\n","            quantifiable_sectored = []\n","\n","        #------------------------------\n","        # Read in plate and locate colonies\n","        #------------------------------\n","\n","        # Read the segmentation of the plate, and keep track of which class each pixel belongs to\n","        p = read_mask(TEST_SEG_FOLDER + '/' + this_plate.stem + '.png')\n","\n","        p_full = tf.identity(p).numpy()\n","        in_class = tf.math.greater(tf.constant(\n","            p_full), tf.constant([0])).numpy()\n","\n","        p = p.astype(np.uint8)\n","        # white pixels\n","        p_1 = tf.math.equal(tf.constant(p_full), tf.constant(\n","            [255])).numpy().astype(np.uint8) * 255\n","        # red pixels\n","        p_2 = tf.math.equal(tf.constant(p_full), tf.constant(\n","            [127])).numpy().astype(np.uint8) * 255\n","        p_full = 255 * in_class.astype(np.uint8)\n","\n","        # Gather the location and radii data from the colonies\n","        # If there are no colonies detected, or there is no table, skip this section at once\n","\n","        colony_locations = pd.read_csv(\n","            TEST_CIRCLE_DATA_FOLDER + '/' + pathlib.Path(test_image).stem + '.csv')\n","\n","        # Output information from the imported csv\n","        print(str(len(colony_locations[\"Radius\"])) +\n","              ' colonies found using circle Hough transform')\n","        plate_names = np.repeat(plate_name, len(colony_locations[\"Radius\"]))\n","        colony_numbers = np.array(range(len(colony_locations[\"Radius\"])))\n","\n","        #---------------------------------------------------------------------\n","\n","        # CLASSIFICATION PIPELINE START\n","        # Pre-processing step\n","\n","        # Images to save:\n","        # - Cropping of the colony\n","        # - Cropping of the colony with the overalyed circle\n","        # - Original colony segmentation, such that only the pixels inside\n","        #   the overlayed circle are considered.\n","\n","        for this_index in range(0, len(colony_numbers)):\n","\n","            print('')\n","            print('Colony ' + str(this_index))\n","            # get example image using bounding indices\n","            #this_index = 2\n","\n","            # Copy location data from colony image\n","            top_left_x = colony_locations[\"Top Left (x)\"][this_index]\n","            top_left_y = colony_locations[\"Top Left (y)\"][this_index]\n","            box_width = colony_locations[\"Width\"][this_index]\n","            box_height = colony_locations[\"Height\"][this_index]\n","\n","            # Store the locations in another set of lists\n","            sides_vert_top.append(top_left_y)\n","            sides_vert_bottom.append(top_left_y + box_height - 1)\n","            sides_horz_left.append(top_left_x)\n","            sides_horz_right.append(top_left_x + box_width - 1)\n","\n","            # Grab segmentation of colony using coordinates copied above\n","            # The colony image is NOT a boolean array\n","            colony_image = p[(top_left_y-1):(top_left_y + box_height - 1),\n","                             (top_left_x-1):(top_left_x + box_width - 1)]\n","            ellipse_array = create_filled_ellipse_in_array(colony_image)\n","            # unpadded segmentation with the pixels inside the overlayed circle\n","            colony_image = np.multiply(colony_image, ellipse_array)\n","\n","            if USE_EXPERT_COUNTS is True:\n","                quant_image = x_quant[(top_left_y-1):(top_left_y + box_height - 1),\n","                                      (top_left_x-1):(top_left_x + box_width - 1), :]\n","                state_image = x_state[(top_left_y-1):(top_left_y + box_height - 1),\n","                                      (top_left_x-1):(top_left_x + box_width - 1), :]\n","\n","            # The colony mask IS a boolean array.  Keep all the pixels of each class.\n","            white_colony_mask = p_1[(top_left_y-1):(top_left_y + box_height - 1),\n","                                    (top_left_x-1):(top_left_x + box_width - 1)] > 0\n","            red_colony_mask = p_2[(top_left_y-1):(top_left_y + box_height - 1),\n","                                  (top_left_x-1):(top_left_x + box_width - 1)] > 0\n","            # sanity check to see of this is the same as colony image\n","            colony_mask = np.logical_or(white_colony_mask, red_colony_mask)\n","\n","            # Add segmentation of the pixels inside the circular region of\n","            # detection, and apply the mask.  This ensures we only\n","            # use the pixels inside the circle for analysis.\n","            # Booleans are inputs, and booleans are outputs\n","            # Force a circle in colonies detected in the circle detection step\n","            white_colony_mask = np.multiply(white_colony_mask, ellipse_array)\n","            red_colony_mask = np.multiply(red_colony_mask, ellipse_array)\n","            colony_mask = np.logical_or(white_colony_mask, red_colony_mask)\n","\n","            # Get initial measure of the sizes of the red and white regions\n","            # of the colony\n","            white_region_sum.append(np.sum(white_colony_mask))\n","            red_region_sum.append(np.sum(red_colony_mask))\n","            colony_region_sum.append(np.sum(colony_mask))\n","            sector_region_sum.append(\n","                np.sum(red_colony_mask) / np.sum(colony_mask))\n","\n","            # Find colony boundaries, ensuring that the boundaries are ON\n","            # the colony, not ADJACENT to it.\n","            edge_mask_unpadded = get_colony_boundary_binary(\n","                colony_image)  # The function is above\n","            # Second mask containing only the interior pixels of the segmentation\n","            interior_mask_unpadded = np.logical_xor(\n","                colony_image > 0, edge_mask_unpadded)\n","            interior_colony = np.multiply(\n","                colony_image, interior_mask_unpadded)  # This is NOT a boolean\n","\n","            #---------------------------------------------------------------\n","            # Get quantifiable colony labels (if applicable)\n","            #---------------------------------------------------------------\n","\n","            # If we have locations of quantifiable colonies, use this to gather the colonies.\n","            if USE_EXPERT_COUNTS is True:\n","                #----------------------------------\n","                # Determine where the quantifiable colonies are (they have black dots on them)\n","                # Set color boundaries for the markers in the counted images\n","                black_dot_boundaries = [([0, 0, 0], [5, 5, 5])]\n","\n","                for (lower, upper) in black_dot_boundaries:\n","                    # create NumPy arrays from the boundaries\n","                    lower = np.array(lower, dtype=\"uint8\")\n","                    upper = np.array(upper, dtype=\"uint8\")\n","                    # find the colors within the specified boundaries and apply\n","                    # the mask\n","                    dot_mask = cv2.inRange(\n","                        (quant_image*255).astype(np.uint8), lower, upper)\n","                    #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n","                    # Get connected components of the detected pixels\n","                    black_labels = label(dot_mask)\n","                    num_black_labels = len(np.unique(black_labels))\n","                    if num_black_labels <= 1:\n","                        # No dot was detected.  Thus the colony was considered non-quantifiable.\n","                        colony_is_quantifiable = False\n","                    else:\n","                        # Loop through each component.  Find one component\n","                        # that is not too small and is directly on the colony\n","                        colony_center_y = (quant_image.shape[0] - 1) / 2.0\n","                        colony_center_x = (quant_image.shape[1] - 1) / 2.0\n","                        for this_comp in range(1, num_black_labels):\n","                            this_dot_comp = black_labels == this_comp\n","                            # Get centroid of component\n","                            (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(\n","                                this_dot_comp)\n","                            dot_dist = math.sqrt(\n","                                ((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n","                            if dot_dist < colony_locations[\"Radius\"][this_index]:\n","                                colony_is_quantifiable = True\n","                                break\n","                                # end the loop, as we found a dot on the colony\n","\n","                            if this_comp == (num_black_labels - 1):\n","                                # We looped through all the dots, but none of\n","                                # them were on the colony.  Don't analyze\n","                                # this colony.\n","                                colony_is_quantifiable = False\n","\n","                quantifiable_colony.append(colony_is_quantifiable)\n","\n","                #print('Colony', this_index, ': Quantifiable:', colony_is_quantifiable)\n","\n","                #----------------------------------------\n","                # Determine if colony is cured, stable, or sectored\n","\n","                # RGB version\n","                # cured_dot_boundaries = [([34-5, 177-5, 76-5], [34+5, 177+5, 76+5])]\n","                # stable_dot_boundaries = [([237-5, 28-5, 36-5], [237+5, 28+5, 36+5])]\n","                # sectored_dot_boundaries = [([63-5, 72-5, 204-5], [63+5, 72+5, 204+5])]\n","\n","                # BGR version (cv2 needs this)\n","                # Marker colors were manaully chosen, so info below is based on that.\n","                # Wes annotations\n","                cured_dot_boundaries = [\n","                    ([76-5, 177-5, 34-5], [76+5, 177+5, 34+5])]\n","                stable_dot_boundaries = [\n","                    ([36-5, 28-5, 237-5], [36+5, 28+5, 237+5])]\n","                sectored_dot_boundaries = [\n","                    ([204-5, 72-5, 63-5], [204+5, 72+5, 63+5])]\n","\n","                # Nicole annotations\n","                # cured_dot_boundaries = [([0, 250, 0], [0, 255, 0])]\n","                # stable_dot_boundaries = [([0, 0, 250], [0, 0, 255])]\n","                # sectored_dot_boundaries = [([250, 250, 0], [255, 255, 0])]\n","\n","                # cured_dot_boundaries = [([0, 250, 0], [0, 255, 0])]\n","                # stable_dot_boundaries = [([0, 0, 250], [0, 0, 255])]\n","                # sectored_dot_boundaries = [([250, 0, 0], [255, 0, 0])]\n","\n","                for (lower, upper) in cured_dot_boundaries:\n","                    # create NumPy arrays from the boundaries\n","                    lower = np.array(lower, dtype=\"uint8\")\n","                    upper = np.array(upper, dtype=\"uint8\")\n","                    # find the colors within the specified boundaries and apply\n","                    # the mask\n","                    #print(np.unique((colony_image*255).astype(np.uint8)))\n","                    dot_mask = cv2.inRange(\n","                        (state_image*255).astype(np.uint8), lower, upper)\n","                    #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n","                    # Get connected components of the detected dot pixels\n","                    #print(np.unique(dot_mask))\n","                    cured_labels = label(dot_mask)\n","                    num_cured_labels = len(np.unique(cured_labels))\n","                    if num_cured_labels <= 1:\n","                        # No dot was detected.  Thus the colony was considered\n","                        # non-quantifiable.\n","                        colony_is_cured = False\n","                    else:\n","                        # Loop through each component.  Find one component\n","                        # that is not too small and is directly on the colony\n","                        colony_center_y = (state_image.shape[0] - 1) / 2.0\n","                        colony_center_x = (state_image.shape[1] - 1) / 2.0\n","                        for this_comp in range(1, num_cured_labels):\n","                            this_dot_comp = cured_labels == this_comp\n","                            # Get centroid of component\n","                            (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(\n","                                this_dot_comp)\n","                            dot_dist = math.sqrt(\n","                                ((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n","                            if dot_dist < colony_locations[\"Radius\"][this_index]:\n","                                colony_is_cured = True\n","                                break\n","                                # end the loop, as we found a dot on the colony\n","\n","                            if this_comp == (num_cured_labels - 1):\n","                                # We looped through all the dots, but none\n","                                # of them were on the colony.  Don't analyze\n","                                # this colony.\n","                                colony_is_cured = False\n","\n","                quantifiable_cured.append(colony_is_cured)\n","\n","                #print('Colony', this_index, ': Cured:', colony_is_cured)\n","\n","                for (lower, upper) in stable_dot_boundaries:\n","                    # create NumPy arrays from the boundaries\n","                    lower = np.array(lower, dtype=\"uint8\")\n","                    upper = np.array(upper, dtype=\"uint8\")\n","                    # find the colors within the specified boundaries and apply\n","                    # the mask\n","                    #print(np.unique((colony_image*255).astype(np.uint8)))\n","                    dot_mask = cv2.inRange(\n","                        (state_image*255).astype(np.uint8), lower, upper)\n","                    #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n","                    # Get connected components of the detected pixels\n","                    #print(np.unique(dot_mask))\n","                    stable_labels = label(dot_mask)\n","                    num_stable_labels = len(np.unique(stable_labels))\n","                    if num_stable_labels <= 1:\n","                        # No dot was detected.  Thus the colony was considered\n","                        # non-quantifiable.\n","                        colony_is_stable = False\n","                    else:\n","                        # Loop through each component.  Find one component\n","                        # that is not too small and is directly on the colony\n","                        colony_center_y = (state_image.shape[0] - 1) / 2.0\n","                        colony_center_x = (state_image.shape[1] - 1) / 2.0\n","                        for this_comp in range(1, num_stable_labels):\n","                            this_dot_comp = stable_labels == this_comp\n","                            # Get centroid of component\n","                            (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(\n","                                this_dot_comp)\n","                            dot_dist = math.sqrt(\n","                                ((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n","                            if dot_dist < colony_locations[\"Radius\"][this_index]:\n","                                colony_is_stable = True\n","                                break\n","                                # end the loop, as we found a dot on the colony\n","\n","                            if this_comp == (num_stable_labels - 1):\n","                                # We looped through all the dots, but none of\n","                                # them were on the colony.  Don't analyze\n","                                # this colony.\n","                                colony_is_stable = False\n","\n","                quantifiable_stable.append(colony_is_stable)\n","\n","                #print('Colony', this_index, ': Stable:', colony_is_stable)\n","\n","                for (lower, upper) in sectored_dot_boundaries:\n","                    # create NumPy arrays from the boundaries\n","                    lower = np.array(lower, dtype=\"uint8\")\n","                    upper = np.array(upper, dtype=\"uint8\")\n","                    # find the colors within the specified boundaries and apply\n","                    # the mask\n","                    #print(np.unique((colony_image*255).astype(np.uint8)))\n","                    dot_mask = cv2.inRange(\n","                        (state_image*255).astype(np.uint8), lower, upper)\n","                    #dot_output = cv2.bitwise_and((count_image*255).astype(np.uint8), dot_mask)\n","                    # Get connected components of the detected pixels\n","                    #print(np.unique(dot_mask))\n","                    sectored_labels = label(dot_mask)\n","                    num_sectored_labels = len(np.unique(sectored_labels))\n","                    if num_sectored_labels <= 1:\n","                        # No dot was detected.  Thus the colony was considered\n","                        # non-quantifiable.\n","                        colony_is_sectored = False\n","                    else:\n","                        # Loop through each component.  Find one component\n","                        # that is not too small and is directly on the colony\n","                        colony_center_y = (state_image.shape[0] - 1) / 2.0\n","                        colony_center_x = (state_image.shape[1] - 1) / 2.0\n","                        for this_comp in range(1, num_sectored_labels):\n","                            this_dot_comp = sectored_labels == this_comp\n","                            # Get centroid of component\n","                            (comp_centroid_y, comp_centroid_x) = ndimage.center_of_mass(\n","                                this_dot_comp)\n","                            dot_dist = math.sqrt(\n","                                ((comp_centroid_y - colony_center_y) ** 2) + ((comp_centroid_x - colony_center_x) ** 2))\n","                            if dot_dist < colony_locations[\"Radius\"][this_index]:\n","                                colony_is_sectored = True\n","                                break\n","                                # end the loop, as we found a dot on the colony\n","\n","                            if this_comp == (num_sectored_labels - 1):\n","                                # We looped through all the dots, but\n","                                # none of them were on the colony.  Don't\n","                                # analyze this colony.\n","                                colony_is_sectored = False\n","\n","                quantifiable_sectored.append(colony_is_sectored)\n","\n","                #print('Colony', this_index, ': Sectored:', colony_is_sectored)\n","\n","                #----------------------------------\n","\n","            #-----------------------------------------------------\n","            # Get connectedness properties of the segmentation\n","            #-----------------------------------------------------\n","\n","            # Use this information to test whether the segmentation meets the conditions\n","\n","            # Condition 1 test: is the segmentation one connected component?\n","            condition_1_test_strong, condition_1_test_weak = check_components_of_colony(\n","                colony_mask)\n","            colony_is_connected.append(condition_1_test_strong)\n","            colony_is_approx_connected.append(condition_1_test_weak)\n","\n","            # Condition 2 test: Is the boundary one connected component?\n","            condition_2_test = check_components_of_boundary(edge_mask_unpadded)\n","            boundary_is_connected.append(condition_2_test)\n","\n","            # Condition 3 test: Are there holes in the segmentation?\n","            condition_3_test = check_for_holes(colony_mask, edge_mask_unpadded)\n","            colony_is_whole.append(condition_3_test)\n","\n","            # Condition 4 test: Is the boundary a Hamiltonian cycle?\n","            # (not ready yet)\n","            #condition_4_test = get_hamilton_cycle(colony_mask, edge_mask_unpadded)\n","\n","\n","            # Condition 5: Check circularity and convexity\n","            condition_5_convex, condition_5_circular = compare_convex_hull(\n","                colony_mask, edge_mask_unpadded)\n","            colony_is_approx_convex.append(condition_5_convex)\n","            colony_is_approx_circular.append(condition_5_circular)\n","\n","            # Condition 6: Check hausdorff distance\n","            hausdorff_chull, hausdorff_circle = get_hausdorff_distance(\n","                colony_mask, edge_mask_unpadded)\n","            hausdorff_dist_convex.append(hausdorff_chull)\n","            hausdorff_dist_circle.append(hausdorff_circle)\n","\n","\n","            #----------------------------------------\n","            # Partition the boundaries into red and white components\n","\n","            # Get 'ideal' boundary of the colony\n","            ideal_circle = create_circle_boundary(\n","                edge_mask_unpadded, colony_locations[\"Radius\"][this_index])\n","\n","            # Find connected components of the red and white pixels found on the boundary\n","            red_boundary_skeleton, white_boundary_skeleton, boundary_mask_h, boundary_mask_w = get_boundary_partitions(\n","                red_colony_mask, white_colony_mask, edge_mask_unpadded)\n","\n","            #plt.imshow(red_boundary_skeleton)\n","            #plt.title('Red Boundary Skeleton')\n","\n","            # Save the three images using this data\n","            #   - Oringinal image padded\n","            #   - CHT image padded\n","            #   - Segmentation padded\n","            # Force a circle like previously\n","            padded_x = 255 * x[max((top_left_y-1)-IMAGE_PADDING, 0):min((top_left_y + box_height - 1)+IMAGE_PADDING, HEIGHT-1), max(\n","                (top_left_x-1) - IMAGE_PADDING, 0):min((top_left_x + box_width - 1)+IMAGE_PADDING, WIDTH-1), :]\n","            padded_x_CHT = 255 * x_CHT[max((top_left_y-1)-IMAGE_PADDING, 0):min((top_left_y + box_height - 1)+IMAGE_PADDING, HEIGHT-1), max(\n","                (top_left_x-1) - IMAGE_PADDING, 0):min((top_left_x + box_width - 1)+IMAGE_PADDING, WIDTH-1), :]\n","            padded_mask = p[max((top_left_y-1)-IMAGE_PADDING, 0):min((top_left_y + box_height - 1)+IMAGE_PADDING, HEIGHT-1),\n","                            max((top_left_x-1) - IMAGE_PADDING, 0):min((top_left_x + box_width - 1)+IMAGE_PADDING, WIDTH-1)]\n","            ellipse_array_2 = create_filled_ellipse_in_array(\n","                padded_mask, padding=IMAGE_PADDING)\n","            padded_mask = np.multiply(padded_mask, ellipse_array_2)\n","\n","            # Save the colony images as previously\n","            if SAVE_ALL_ANNOTATIONS is True:\n","                if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/raw/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.jpg', padded_x):\n","                    raise IOError('Could not write image.')\n","                if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/circles/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.jpg', padded_x_CHT):\n","                    raise IOError('Could not write image.')\n","                if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/segs/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', padded_mask):\n","                    raise IOError('Could not write image.')\n","\n","            # Save the croppings for individual colonies which were annotated\n","                if USE_EXPERT_COUNTS is True:\n","                    padded_x_count = 255 * x_quant[max((top_left_y-1)-IMAGE_PADDING, 0):min((top_left_y + box_height - 1)+IMAGE_PADDING, HEIGHT-1), max(\n","                        (top_left_x-1) - IMAGE_PADDING, 0):min((top_left_x + box_width - 1)+IMAGE_PADDING, WIDTH-1), :]\n","                    if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/counted/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', padded_x_count):\n","                        raise IOError('Could not write image.')\n","            #-------------------------------------------------------------\n","\n","            # CLASSIFICATION STEP BEGINS\n","            # GET INITIAL REGIONAL BREAKDOWN AND RED REGION ANNOTATIONS OF THE COLONY\n","\n","            # Should store information about the following:\n","            #   - Idealized red and white regions\n","            #   - The boundaries of each red and white region\n","            #   - The sizes of each region\n","            #   - The purity scores of each region\n","            #   - the states of each colony (cured, stable)\n","\n","            # Images to save in this section\n","            # - Regional segmentation\n","            # - Boundary of the colony\n","            # - Red region boundary annotation\n","            # - Regions that fail consistency check\n","\n","            # Plot padded version of the initial segmentation.\n","            # Annotations will be saved onto the image.\n","            colony_image_padded = np.pad(colony_image, 5)\n","            fig1, ax1 = plt.subplots()\n","            ax1.imshow(colony_image_padded, cmap='gray', vmin=0, vmax=255)\n","\n","            # initialized to true so that we can look at how each step\n","            # of the pipeline is performing\n","            recheck_boundaries = True\n","\n","            # Using boundary information, find and extract potential\n","            # red and white regions of the colony\n","\n","            red_labels = label(red_boundary_skeleton)\n","            white_labels = label(white_boundary_skeleton)\n","\n","            # Initialize masks separating potential red and white regions\n","            initial_red_region_mask = np.zeros_like(red_boundary_skeleton)\n","            initial_white_region_mask = np.zeros_like(white_boundary_skeleton)\n","            initial_red_boundary_mask = np.zeros_like(red_boundary_skeleton)\n","            initial_white_boundary_mask = np.zeros_like(\n","                white_boundary_skeleton)\n","\n","            # keep track of regions which fail the consistency check\n","            initial_bad_red_score_mask = np.zeros_like(red_boundary_skeleton)\n","            initial_bad_white_score_mask = np.zeros_like(\n","                white_boundary_skeleton)\n","\n","            # Keep track of boundaries whihc fail the consistency check\n","            boundary_correction = np.zeros_like(red_boundary_skeleton)\n","\n","            # Initialize lists to store characteristics about each region\n","            # This includes endpoints on the sector, the purity of the\n","            # sector, and an indicator for the purity being above the\n","            # 50 percent threshold\n","            red_component_endpoints = []\n","            red_component_scores = []\n","            red_component_checks = []\n","            red_component_sizes = []\n","\n","            white_component_endpoints = []\n","            white_component_scores = []\n","            white_component_checks = []\n","            white_component_sizes = []\n","\n","            # How many boundaries of each color are there?\n","            # number of red boundaries present\n","            num_red_boundaries = len(np.unique(red_labels)[1:])\n","            # number of white boundaries present\n","            num_white_boundaries = len(np.unique(white_labels)[1:])\n","\n","            # Initial count of the number of sectors is the number of red boundaries\n","            initial_region_counts.append(num_red_boundaries)\n","\n","            # States can be initialy predicted using the number of red and white boundaries\n","            #if ((num_red_boundaries == 1) & (num_white_boundaries == 0)):\n","            if num_white_boundaries == 0:\n","                cured_colony_before.append(True)\n","            else:\n","                cured_colony_before.append(False)\n","\n","            #if ((num_red_boundaries == 0) & (num_white_boundaries == 1)):\n","            if num_red_boundaries == 0:\n","                stable_colony_before.append(True)\n","            else:\n","                stable_colony_before.append(False)\n","\n","            # Now, to analyze each of the regions to determine if they are sectored\n","\n","            # Analyze the initial red regions of the colony\n","            for this_label in np.unique(red_labels)[1:]:\n","                red_component = copy.deepcopy(red_labels)\n","                red_component = red_component == this_label\n","                red_component = red_component.astype(np.int32)\n","\n","                # Append the red boundary pixels on this component to the red boundary mask\n","                initial_red_boundary_mask = np.logical_or(\n","                    initial_red_boundary_mask, red_component > 0)\n","\n","                # Function to get endpoints of connected component\n","                full_endpoints_list = get_boundary_component_endpoints(\n","                    colony_image[:, :], red_component)\n","\n","                # If exactly two points are found, then everything's good.\n","\n","                # Get the angle of the endpoints relative to the colony center\n","                [endpoint_angles, endpoint_locations, endpoints_x, endpoints_y] = get_endpoint_locations(\n","                    full_endpoints_list, colony_mask, colony_locations[\"Radius\"][this_index])\n","\n","                # Function to get mask representing sector boundary\n","                sector_boundary, sector_interior, sector_filled = get_sector_masks(\n","                    red_component, full_endpoints_list)\n","\n","                # Append the predicted filled region to the red region mask\n","                initial_red_region_mask = np.logical_or(\n","                    initial_red_region_mask, sector_filled)\n","\n","                # Apply consistency check to score the region\n","                confirm_check, prop_interior = check_for_consistency_2(\n","                    sector_filled, red_colony_mask)\n","\n","                # Update score mask to denote where the consistency check failed\n","                if confirm_check is False:\n","                    recheck_boundaries = True\n","                    initial_bad_red_score_mask = np.logical_or(\n","                        initial_bad_red_score_mask, sector_filled)\n","\n","                # Append scores and info to lists\n","                # endpoints of the connected compponent on the boundary\n","                red_component_endpoints.append(full_endpoints_list)\n","                # purity score of the region\n","                red_component_scores.append(prop_interior)\n","                # whether the purity score was at least 0.5\n","                red_component_checks.append(confirm_check)\n","                # the number of pixels in the region\n","                red_component_sizes.append(np.sum(initial_red_region_mask))\n","\n","                # ---ANNOTATION PROCEDURE---\n","\n","                # Plot the lines of the sector (and the boundary line) onto the colony segmentation\n","                length_points = len(endpoints_x)\n","                #print(length_points)\n","                #print(endpoints_x)\n","                # only plots lines if there are divided regions\n","                if len(np.unique(red_labels)[1:]) > 0:\n","                    plot_bounds_x = []\n","                    plot_bounds_y = []\n","                    plot_bounds_x.append(endpoints_x[0] + IMAGE_PADDING)\n","                    plot_bounds_y.append(endpoints_y[0] + IMAGE_PADDING)\n","                    # Get list of center and endpoints on the boundary\n","                    for this_bound in range(0, length_points-1):\n","                        plot_bounds_x.append(\n","                            endpoints_x[this_bound+1] + IMAGE_PADDING)\n","                        plot_bounds_y.append(\n","                            endpoints_y[this_bound+1] + IMAGE_PADDING)\n","                        #plt.plot(plot_points_y, plot_points_x, color='blue')\n","                        #print(endpoints_x[0:2])\n","                        #print(endpoints_y[0:2])\n","                    plot_bounds_x = np.roll(np.array(plot_bounds_x), 1)\n","                    plot_bounds_y = np.roll(np.array(plot_bounds_y), 1)\n","                    #print(plot_bounds_x)\n","                    #print(plot_bounds_y)\n","                    line_style = ':' if (len(plot_bounds_x) == 2) else '-'\n","                    ax1.plot(plot_bounds_y, plot_bounds_x, linewidth=5,\n","                             linestyle=line_style, alpha=0.85)\n","                    if len(plot_bounds_x) == 1:\n","                        full_circle = Circle(\n","                            (plot_bounds_y, plot_bounds_x),\n","                            radius=colony_locations[\"Radius\"][this_index],\n","                            color='blue', fill=False, linewidth=5, alpha=0.85)\n","                        ax1.add_patch(full_circle)\n","\n","            # Do the same for the white regions\n","            for this_label in np.unique(white_labels)[1:]:\n","                white_component = copy.deepcopy(white_labels)\n","                white_component = white_component == this_label\n","                white_component = white_component.astype(np.int32)\n","\n","                initial_white_boundary_mask = np.logical_or(\n","                    initial_white_boundary_mask, white_component > 0)\n","\n","                # Function to get endpoints of connected component\n","                full_endpoints_list = get_boundary_component_endpoints(\n","                    colony_image[:, :], white_component)\n","\n","                # If exactly two points are found, then everything's good.\n","\n","                # Function to get mask representing sector boundary\n","                sector_boundary, sector_interior, sector_filled = get_sector_masks(\n","                    white_component, full_endpoints_list)\n","\n","                # Fill initial region mask with the filled sector\n","                initial_white_region_mask = np.logical_or(\n","                    initial_white_region_mask, sector_filled)\n","\n","                # Apply consistency check to score region\n","                confirm_check, prop_interior = check_for_consistency_2(\n","                    sector_filled, white_colony_mask)\n","\n","                # Update score mask to denote where the consistency check failed\n","                if confirm_check is False:\n","                    recheck_boundaries = True\n","                    initial_bad_white_score_mask = np.logical_or(\n","                        initial_bad_white_score_mask, sector_filled)\n","\n","                # Append scores and info to lists\n","                white_component_endpoints.append(full_endpoints_list)\n","                white_component_scores.append(prop_interior)\n","                white_component_checks.append(confirm_check)\n","                white_component_sizes.append(np.sum(initial_white_region_mask))\n","\n","            # At this point, you should have two masks, one for the red\n","            # and white regions respectivey.\n","            # You should also have the endponts of each component, stored\n","            # as a collection of lists, one list per component\n","            # Finally, you should have a score for those components\n","\n","            # -------------------------------------\n","            # Store the purity scores in a sublist, along with a second\n","            # sublist indicating the color of each region\n","            # -------------------------------------\n","\n","            all_component_scores = []\n","            all_region_colors = []\n","            all_region_sizes = []\n","\n","            if not red_component_scores:\n","                all_region_colors = all_region_colors + ['red']\n","                all_component_scores = all_component_scores + [np.nan]\n","                all_region_sizes = all_region_sizes + [np.nan]\n","            else:\n","                all_region_colors = all_region_colors + \\\n","                    (['red'] * len(red_component_scores))\n","                all_component_scores = all_component_scores + red_component_scores\n","                all_region_sizes = all_region_sizes + red_component_sizes\n","\n","            if not white_component_scores:\n","                all_region_colors = all_region_colors + ['white']\n","                all_component_scores = all_component_scores + [np.nan]\n","                all_region_sizes = all_region_sizes + [np.nan]\n","            else:\n","                all_region_colors = all_region_colors + \\\n","                    (['white'] * len(white_component_scores))\n","                all_component_scores = all_component_scores + white_component_scores\n","                all_region_sizes = all_region_sizes + white_component_sizes\n","\n","            region_purity_before.append(all_component_scores)\n","            region_color_before.append(all_region_colors)\n","            region_sizes_before.append(all_region_sizes)\n","\n","            # -------------------------------------\n","            # Do the same for the weighted purity scores across the entire colony\n","            # -------------------------------------\n","\n","            # Compute weighted purity scores over all regions, for white only, and for red only\n","\n","            total_red_sum = np.nansum(red_component_sizes)\n","            total_white_sum = np.nansum(white_component_sizes)\n","\n","            if not red_component_scores:\n","                red_region_weights = np.array([0])\n","                weighted_red_scores = np.array([0])\n","            else:\n","                # this vector should add to 1, as this is a normalization of the weights\n","                red_region_weights = np.divide(\n","                    np.array(red_component_sizes), total_red_sum)\n","                weighted_red_scores = np.multiply(\n","                    np.array(red_component_scores), red_region_weights)\n","\n","            if not white_component_scores:\n","                white_region_weights = np.array([0])\n","                weighted_white_scores = np.array([0])\n","            else:\n","                # this vector should add to 1, as this is a normalization of the weights\n","                white_region_weights = np.divide(\n","                    np.array(white_component_sizes), total_white_sum)\n","                weighted_white_scores = np.multiply(\n","                    np.array(white_component_scores), white_region_weights)\n","\n","            # Get weighted average over both regions together\n","            all_region_sum = np.nansum(all_region_sizes)\n","            all_region_weights = np.divide(\n","                np.array(red_component_sizes + white_component_sizes), all_region_sum)\n","            all_region_weighted_scores = np.multiply(\n","                np.array(red_component_scores + white_component_scores), all_region_weights)\n","\n","            weighted_purity_red_before.append(list(weighted_red_scores))\n","            weighted_purity_white_before.append(list(weighted_white_scores))\n","            weighted_purity_before.append(list(all_region_weighted_scores))\n","            weighted_red_sector_score_before.append(\n","                np.nansum(weighted_red_scores))\n","            weighted_white_sector_score_before.append(\n","                np.nansum(weighted_white_scores))\n","            weighted_sector_score_before.append(\n","                np.nansum(all_region_weighted_scores))\n","\n","            # Now, create the masks containing the initial_regions\n","            initial_region_mask = np.maximum(initial_red_region_mask.astype(\n","                np.uint8), 2*initial_white_region_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","            initial_boundary_mask = np.maximum(initial_red_boundary_mask.astype(\n","                np.uint8), 2*initial_white_boundary_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","            initial_score_mask = np.maximum(initial_bad_red_score_mask.astype(\n","                np.uint8), 2*initial_bad_white_score_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","\n","            # Make sure to pad them in the same way as the output segmentation\n","            initial_region_mask = np.pad(initial_region_mask, IMAGE_PADDING)\n","            initial_boundary_mask = np.pad(\n","                initial_boundary_mask, IMAGE_PADDING)\n","            initial_score_mask = np.pad(initial_score_mask, IMAGE_PADDING)\n","\n","            # Save the initial region and boundary mask.  Also save\n","            # image indicating regions which should be investigted further.\n","            if SAVE_ALL_ANNOTATIONS is True:\n","                if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/init_regions/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', initial_region_mask):\n","                    raise IOError('Could not write image.')\n","                if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/init_bounds/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', initial_boundary_mask):\n","                    raise IOError('Could not write image.')\n","                if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/init_bad/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', initial_score_mask):\n","                    raise IOError('Could not write image.')\n","            plt.axis('off')\n","            if SAVE_ALL_ANNOTATIONS is True:\n","                fig1.savefig(OUTPUT_CROPS_FOLDER + '/init_partitions/' + file_dict[plate_name] + '/' + pathlib.Path(\n","                    test_image).stem + '_c_' + str(this_index) + '.png', bbox_inches='tight', pad_inches=0)\n","            plt.close(fig1)\n","\n","            #------------------------------------------------------------------\n","\n","            # CLASS SWITCH/MERGING STEP\n","\n","            # This is only applied to regions where the consistency check fails.\n","            # i.e. less than 50% of pixels in the predicted region are of the same class\n","            # as the outer boundary pixels\n","\n","            # The process will repeat until all regions pass the consisency check\n","\n","            # NOTE: This section is only executed if one of either the red or\n","            # white regions estimated above, fails the constency check.\n","            # If all regions predicted are consistent in class, the below will\n","            # not execute, as it will do exactly the same stuff as just done above.\n","\n","            # Therefore, this section is purposely redundant and helps us keep\n","            # track of which regions are being updated.\n","\n","            repetition_counter = 0\n","            performing_correction = False  # initialize at the beginning\n","\n","            while recheck_boundaries is True:\n","\n","                recheck_boundaries = False  # reset.\n","                repetition_counter = repetition_counter + 1\n","\n","                # The above should be switched back to True if there is a\n","                # potentially misclassified boundary\n","\n","                # Find the connected components of the skeleton.\n","                # The number of red connected components gives the initial\n","                # number of sectors.\n","                # The number of white connected components are the regions\n","                # separating the red sectors.\n","                # A score for sectoriness will be applied to both sets of regions.\n","                red_labels = label(red_boundary_skeleton)\n","                white_labels = label(white_boundary_skeleton)\n","\n","                # Initialize masks separating potential red and white regions\n","                red_region_mask = np.zeros_like(red_boundary_skeleton)\n","                white_region_mask = np.zeros_like(white_boundary_skeleton)\n","                red_boundary_mask = np.zeros_like(red_boundary_skeleton)\n","                white_boundary_mask = np.zeros_like(white_boundary_skeleton)\n","                red_score_mask = np.zeros_like(red_boundary_skeleton)\n","                white_score_mask = np.zeros_like(white_boundary_skeleton)\n","\n","                # Intialize array to change boundary.\n","                # This is only updated when there is a potentially misclassified boundary.\n","                boundary_correction_red = np.zeros_like(red_boundary_skeleton)\n","                boundary_correction_white = np.zeros_like(\n","                    white_boundary_skeleton)\n","\n","                # Generate regions directly from segmentation\n","                # Iterate through each component and collect some information\n","                # Collect info about component endpoints and purity scores\n","                red_component_endpoints = []\n","                red_component_scores = []\n","                red_component_checks = []\n","\n","                white_component_endpoints = []\n","                white_component_scores = []\n","                white_component_checks = []\n","\n","               # print('Number of red components: ' + str(max(np.unique(red_labels)[1:])))\n","\n","                # Iterate through the red components\n","                for this_label in np.unique(red_labels)[1:]:\n","                    #print('Running the red check.')\n","                    red_component = copy.deepcopy(red_labels)\n","                    red_component = red_component == this_label\n","                    red_component = red_component.astype(np.int32)\n","\n","                    red_boundary_mask = np.logical_or(\n","                        red_boundary_mask, red_component > 0)\n","\n","                    # Function to get endpoints of connected component\n","                    full_endpoints_list = get_boundary_component_endpoints(\n","                        colony_image[:, :], red_component)\n","\n","                    # If exactly two points are found, then everything's good.\n","\n","                    # Function to get mask representing sector boundary\n","                    sector_boundary, sector_interior, sector_filled = get_sector_masks(\n","                        red_component, full_endpoints_list)\n","\n","                    # Fill initial region mask with the filled sector\n","                    red_region_mask = np.logical_or(\n","                        red_region_mask, sector_filled)\n","\n","                    # Apply consistency check to score region\n","                    confirm_check, prop_interior = check_for_consistency_2(\n","                        sector_filled, red_colony_mask)\n","\n","                    # Update score mask to denote where the consistency\n","                    # check failed\n","                    if confirm_check is False:\n","                        recheck_boundaries = True\n","                        boundary_correction_red = np.logical_or(\n","                            boundary_correction_red, red_component)\n","\n","                    # Append scores and info to lists\n","                    red_component_endpoints.append(full_endpoints_list)\n","                    red_component_scores.append(prop_interior)\n","                    red_component_checks.append(confirm_check)\n","\n","                # Do the same for the white components\n","                for this_label in np.unique(white_labels)[1:]:\n","\n","                    white_component = copy.deepcopy(white_labels)\n","                    white_component = white_component == this_label\n","                    white_component = white_component.astype(np.int32)\n","\n","                    white_boundary_mask = np.logical_or(\n","                        white_boundary_mask, white_component > 0)\n","\n","                    # Function to get endpoints of connected component\n","                    full_endpoints_list = get_boundary_component_endpoints(\n","                        colony_image[:, :], white_component)\n","\n","                    # If exactly two points are found, then everything's good.\n","\n","                    # Function to get mask representing sector boundary\n","                    sector_boundary, sector_interior, sector_filled = get_sector_masks(\n","                        white_component, full_endpoints_list)\n","\n","                    # Fill initial region mask with the filled sector\n","                    white_region_mask = np.logical_or(\n","                        white_region_mask, sector_filled)\n","\n","                    # Apply consistency check to score region\n","                    confirm_check, prop_interior = check_for_consistency_2(\n","                        sector_filled, white_colony_mask)\n","\n","                    # Update score mask to denote where the consistency\n","                    # check failed\n","                    if confirm_check is False:\n","                        recheck_boundaries = True\n","                        boundary_correction_white = np.logical_or(\n","                            boundary_correction_white, white_component)\n","\n","                    # Append scores and info to lists\n","                    white_component_endpoints.append(full_endpoints_list)\n","                    white_component_scores.append(prop_interior)\n","                    white_component_checks.append(confirm_check)\n","\n","                # If there were regions that failed the\n","                # consistency check, swap the classes on the boundary\n","                if recheck_boundaries is True:\n","\n","                    # This signifies that boundary information will\n","                    # be different from the initial breakdown\n","                    performing_correction = True\n","\n","                    # Run the swap functions\n","                    # takes the bad white boundaries and switches them to the red class\n","                    red_boundary_skeleton = grow_boundary(\n","                        red_boundary_skeleton, boundary_correction_white)\n","                    red_boundary_skeleton = shrink_boundary(\n","                        red_boundary_skeleton, boundary_correction_red)\n","                    # removes the bad red boundaries\n","\n","                    # takes the bad red boundaries and switches them\n","                    # to the white class\n","                    white_boundary_skeleton = grow_boundary(\n","                        white_boundary_skeleton, boundary_correction_red)\n","                    white_boundary_skeleton = shrink_boundary(\n","                        white_boundary_skeleton, boundary_correction_white)\n","                    # removes the bad white boundaries\n","\n","                # Only run the block below if this colony cannot be\n","                # analyzed appropriatly with this pipeline\n","                # (may be an awful segmentation)\n","                if repetition_counter > 20:\n","                    warnings.warn(\n","                        'Corrections have been applied too many times.  The colony segmentation used here is likely unsuitable for this pipeline.')\n","                    break\n","\n","                    # Once the swap is done, you will head back to the top\n","                    # of this while loop.\n","\n","            # At this point, you should have two masks, one for the red\n","            # and white regions respectivey.\n","            # You should also have the endponts of each components,\n","            # stored as a collection of lists, one list per component\n","            # Finally, you should have a score for those components\n","\n","            # Now, create the masks containing the regions that pass the consistency check\n","            corrected_region_mask = np.maximum(red_region_mask.astype(\n","                np.uint8), 2*white_region_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","            corrected_boundary_mask = np.maximum(red_boundary_mask.astype(\n","                np.uint8), 2*white_boundary_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","\n","            red_labels = label(red_boundary_skeleton)\n","            white_labels = label(white_boundary_skeleton)\n","\n","            # Use the corrected boundary_mask to piece together the corrected colony segmentation\n","            corrected_colony_image = np.add(\n","                interior_colony, corrected_boundary_mask).astype(np.uint8)\n","            corrected_colony_image_padded = np.pad(\n","                corrected_colony_image, IMAGE_PADDING)\n","\n","            # Re-partition the image following correction\n","            corrected_full = tf.identity(\n","                corrected_colony_image).numpy().astype(np.int32)\n","            corrected_white_colony_mask = tf.math.equal(tf.constant(\n","                corrected_full), tf.constant([255])).numpy().astype(np.uint8)\n","            corrected_red_colony_mask = tf.math.equal(tf.constant(\n","                corrected_full), tf.constant([127])).numpy().astype(np.uint8)\n","            # sanity check to see of this is the same as colony image\n","            corrected_colony_mask = np.logical_or(\n","                corrected_white_colony_mask, corrected_red_colony_mask)\n","\n","            #--------------------------------------------------\n","            # Get corrected segmentations and regions\n","\n","            # Get boundary information from the boundary corrected/merged\n","            # segmentation.\n","            corrected_red_boundary_skeleton, corrected_white_boundary_skeleton, corrected_boundary_mask_h, corrected_boundary_mask_w = get_boundary_partitions(\n","                corrected_red_colony_mask, corrected_white_colony_mask, edge_mask_unpadded)\n","\n","            red_labels = label(corrected_red_boundary_skeleton)\n","            white_labels = label(corrected_white_boundary_skeleton)\n","\n","            corrected_boundary_mask = np.maximum((red_labels > 0).astype(\n","                np.uint8), 2*((white_labels > 0).astype(np.uint8)))*(255/(NUM_CLASSES-1))\n","\n","            # Use the corrected boundary_mask to piece together the corrected colony segmentation\n","            corrected_colony_image = np.add(\n","                interior_colony, corrected_boundary_mask).astype(np.uint8)\n","            corrected_colony_image_padded = np.pad(\n","                corrected_colony_image, IMAGE_PADDING)\n","\n","            corrected_region_mask = np.maximum(red_region_mask.astype(\n","                np.uint8), 2*white_region_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","            corrected_boundary_mask = np.maximum(red_boundary_mask.astype(\n","                np.uint8), 2*white_boundary_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","\n","            # Re-partition the image following correction\n","            corrected_full = tf.identity(\n","                corrected_colony_image).numpy().astype(np.int32)\n","            corrected_white_colony_mask = tf.math.equal(tf.constant(\n","                corrected_full), tf.constant([255])).numpy().astype(np.uint8)\n","            corrected_red_colony_mask = tf.math.equal(tf.constant(\n","                corrected_full), tf.constant([127])).numpy().astype(np.uint8)\n","            # sanity check to see of this is the same as colony image\n","            corrected_colony_mask = np.logical_or(\n","                corrected_white_colony_mask, corrected_red_colony_mask)\n","\n","            #-------------------------------------------------------------------\n","\n","            # PROCESSING THE CORRECTED REGIONS\n","            # If you got to this point, then the boundaries should be\n","            # consistent with the interior of the colony.\n","\n","            # Images to save in this section\n","            # - Regional segmentation with the corrected boundary\n","            # - Red region boundary annotation with the corrected boundary\n","            # - Red regions remaining after correction applied\n","\n","            # initialize masks containing the sector locations\n","            all_sector_bounds = np.zeros_like(colony_mask).astype(np.int32)\n","            all_sector_filled = np.zeros_like(colony_mask).astype(np.int32)\n","            all_sector_filled_labels = np.zeros_like(\n","                colony_mask).astype(np.int32)\n","\n","            # Save the corrected segmentation\n","            if SAVE_ALL_ANNOTATIONS is True:\n","                if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/cor_segs/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', corrected_colony_image_padded):\n","                    raise IOError('Could not write image.')\n","\n","            # Initialize masks separating potential red and white regions\n","            post_red_region_mask = np.zeros_like(\n","                corrected_red_boundary_skeleton)\n","            post_white_region_mask = np.zeros_like(\n","                corrected_white_boundary_skeleton)\n","            post_red_boundary_mask = np.zeros_like(\n","                corrected_red_boundary_skeleton)\n","            post_white_boundary_mask = np.zeros_like(\n","                corrected_white_boundary_skeleton)\n","            post_red_score_mask = np.zeros_like(\n","                corrected_red_boundary_skeleton)\n","            post_white_score_mask = np.zeros_like(\n","                corrected_white_boundary_skeleton)\n","\n","            # red_labels = label(corrected_red_boundary_skeleton)\n","            # white_labels = label(corrected_white_boundary_skeleton)\n","\n","            # initialize counter for the number of sectors in this colony\n","            total_sectors = 0\n","\n","            # Make copy of colony mask and place sectors on top\n","            #colony_mask_faded = copy.deepcopy(colony_mask).astype(np.uint8)\n","            #colony_mask_faded[colony_mask_faded > 0] = 20\n","\n","            corrected_colony_mask_faded = copy.deepcopy(\n","                corrected_colony_mask).astype(np.uint8)\n","            corrected_colony_mask_faded[corrected_colony_mask_faded > 0] = 20\n","\n","            sector_scores = []\n","            sector_ious = []\n","\n","            # Create figure for annotating the corrected colony segmentations.\n","            # Annotations will be saved onto the image.\n","            fig2, ax2 = plt.subplots()\n","            ax2.imshow(corrected_colony_image_padded, cmap='gray', vmin=0, vmax=255)\n","\n","            # Compute the scores of the regions one more time.\n","            # All regions should pass the consistency check by this point.\n","            # If not, then something is wrong.\n","            red_component_endpoints = []\n","            red_component_scores = []\n","            red_component_checks = []\n","            red_component_sizes = []\n","\n","            white_component_endpoints = []\n","            white_component_scores = []\n","            white_component_checks = []\n","            white_component_sizes = []\n","\n","            # number of red boundaries present\n","            num_red_boundaries = len(np.unique(red_labels)[1:])\n","            # number of white boundaries present\n","            num_white_boundaries = len(np.unique(white_labels)[1:])\n","\n","            #if ((num_red_boundaries == 1) & (num_white_boundaries == 0)):\n","            if num_white_boundaries == 0:\n","                cured_colony_after.append(True)\n","            else:\n","                cured_colony_after.append(False)\n","\n","            #if ((num_red_boundaries == 0) & (num_white_boundaries == 1)):\n","            if num_red_boundaries == 0:\n","                stable_colony_after.append(True)\n","            else:\n","                stable_colony_after.append(False)\n","\n","            for this_label in np.unique(red_labels)[1:]:\n","                red_component = copy.deepcopy(red_labels)\n","                red_component = red_component == this_label\n","                red_component = red_component.astype(np.int32)\n","\n","                post_red_boundary_mask = np.logical_or(\n","                    post_red_boundary_mask, red_component > 0)\n","\n","                # Function to get endpoints of connected component\n","                full_endpoints_list = get_boundary_component_endpoints(\n","                    corrected_colony_image[:, :], red_component)\n","\n","                # If exactly two points are found, then everything's good.\n","\n","                # Function to get mask representing sector boundary\n","                sector_boundary, sector_interior, sector_filled = get_sector_masks(\n","                    red_component, full_endpoints_list)\n","\n","                # Fill initial region mask with the filled sector\n","                post_red_region_mask = np.logical_or(\n","                    post_red_region_mask, sector_filled)\n","\n","                # Apply consistency check to score region\n","                confirm_check, prop_interior = check_for_consistency_2(\n","                    sector_filled, corrected_red_colony_mask)\n","\n","                # Update score mask to denote where the consistency check failed\n","                if confirm_check is False:\n","                    print(\n","                        'Double check your code.  The red consistency check failed for this colony with score ' + str(prop_interior))\n","\n","                # Append scores and info to lists\n","                red_component_endpoints.append(full_endpoints_list)\n","                red_component_scores.append(prop_interior)\n","                red_component_checks.append(confirm_check)\n","                red_component_sizes.append(np.sum(post_red_region_mask))\n","\n","                # Code for plotting the annotations\n","\n","                # For the consistent sectors, get the angles of the endpoints\n","                # relative to the center.\n","                # colony mask, or any other array with the same size and shape,\n","                # will work as input as it's only needed for size info\n","                [endpoint_angles, endpoint_locations, endpoints_x, endpoints_y] = get_endpoint_locations(\n","                    full_endpoints_list, corrected_colony_mask, colony_locations[\"Radius\"][this_index])\n","                #print(endpoints_x)\n","\n","                # Add to mask containg sector locations\n","                #sector_filled = np.logical_or(sector_boundary, sector_interior)\n","                all_sector_bounds = np.logical_or(\n","                    all_sector_bounds, sector_boundary)\n","                all_sector_filled = np.logical_or(\n","                    all_sector_filled, sector_filled)\n","                all_sector_filled_labels[sector_filled.astype(\n","                    bool)] = this_label\n","                total_sectors = total_sectors + 1\n","                corrected_colony_mask_faded[sector_filled.astype(\n","                    bool)] = 255 / this_label\n","\n","                # Get a score for sectoriness.  We want to be sure we are\n","                # capturing the entire sector\n","                this_sector_mask = np.logical_and(\n","                    sector_filled, red_colony_mask)\n","                this_union_mask = np.logical_or(sector_filled, red_colony_mask)\n","                this_sector_score = np.sum(\n","                    this_sector_mask) / np.sum(sector_filled)\n","                this_sector_iou = np.sum(\n","                    this_sector_mask) / np.sum(this_union_mask)\n","                sector_scores.append(this_sector_score)\n","                sector_ious.append(this_sector_iou)\n","\n","                # Plot the lines of the sector (and the boundary line) onto the colony segmentation\n","                length_points = len(endpoints_x)\n","                #print(length_points)\n","                #print(endpoints_x)\n","                if len(np.unique(red_labels)[1:]) > 0:\n","                    plot_bounds_x = []\n","                    plot_bounds_y = []\n","                    plot_bounds_x.append(endpoints_x[0] + 5)\n","                    plot_bounds_y.append(endpoints_y[0] + 5)\n","                    # Get list of center and endpoints on the boundary\n","                    for this_bound in range(0, length_points-1):\n","                        plot_bounds_x.append(endpoints_x[this_bound+1] + 5)\n","                        plot_bounds_y.append(endpoints_y[this_bound+1] + 5)\n","                        #plt.plot(plot_points_y, plot_points_x, color='blue')\n","                        #print(endpoints_x[0:2])\n","                        #print(endpoints_y[0:2])\n","                    plot_bounds_x = np.roll(np.array(plot_bounds_x), 1)\n","                    plot_bounds_y = np.roll(np.array(plot_bounds_y), 1)\n","                    #print(plot_bounds_x)\n","                    #print(plot_bounds_y)\n","                    line_style = ':' if (len(plot_bounds_x) == 2) else '-'\n","                    ax2.plot(plot_bounds_y, plot_bounds_x, linewidth=5,\n","                             linestyle=line_style, alpha=0.85)\n","                    if len(plot_bounds_x) == 1:\n","                        full_circle = Circle(\n","                            (plot_bounds_y, plot_bounds_x),\n","                            radius=colony_locations[\"Radius\"][this_index],\n","                            color='blue', fill=False, linewidth=5, alpha=0.85)\n","                        ax2.add_patch(full_circle)\n","\n","            for this_label in np.unique(white_labels)[1:]:\n","                white_component = copy.deepcopy(white_labels)\n","                white_component = white_component == this_label\n","                white_component = white_component.astype(np.int32)\n","\n","                post_white_boundary_mask = np.logical_or(\n","                    post_white_boundary_mask, white_component > 0)\n","\n","                # Function to get endpoints of connected component\n","                full_endpoints_list = get_boundary_component_endpoints(\n","                    corrected_colony_image[:, :], white_component)\n","\n","                # If exactly two points are found, then everything's good.\n","\n","                # Function to get mask representing sector boundary\n","                sector_boundary, sector_interior, sector_filled = get_sector_masks(\n","                    white_component, full_endpoints_list)\n","\n","                # Fill initial region mask with the filled sector\n","                post_white_region_mask = np.logical_or(\n","                    post_white_region_mask, sector_filled)\n","\n","                # Apply consistency check to score region\n","                confirm_check, prop_interior = check_for_consistency_2(\n","                    sector_filled, corrected_white_colony_mask)\n","\n","                # Update score mask to denote where the consistency check failed\n","                if confirm_check is False:\n","                    print(\n","                        'Double check your code.  The white consistency check failed for this colony with score ' + str(prop_interior))\n","\n","                # Append scores and info to lists\n","                white_component_endpoints.append(full_endpoints_list)\n","                white_component_scores.append(prop_interior)\n","                white_component_checks.append(confirm_check)\n","                white_component_sizes.append(np.sum(post_white_region_mask))\n","\n","            print('Scores for red regions: ' + str(red_component_scores))\n","            print('Scores for white regions: ' + str(white_component_scores))\n","\n","            # Store the purity scores in a sublist, along with a second\n","            # sublist indicating the color of each region\n","\n","            all_component_scores = []\n","            all_region_colors = []\n","            all_region_sizes = []\n","\n","            if not red_component_scores:\n","                all_region_colors = all_region_colors + ['red']\n","                all_component_scores = all_component_scores + [np.nan]\n","                all_region_sizes = all_region_sizes + [np.nan]\n","            else:\n","                all_region_colors = all_region_colors + \\\n","                    (['red'] * len(red_component_scores))\n","                all_component_scores = all_component_scores + red_component_scores\n","                all_region_sizes = all_region_sizes + red_component_sizes\n","\n","            if not white_component_scores:\n","                all_region_colors = all_region_colors + ['white']\n","                all_component_scores = all_component_scores + [np.nan]\n","                all_region_sizes = all_region_sizes + [np.nan]\n","            else:\n","                all_region_colors = all_region_colors + \\\n","                    (['white'] * len(white_component_scores))\n","                all_component_scores = all_component_scores + white_component_scores\n","                all_region_sizes = all_region_sizes + white_component_sizes\n","\n","            region_purity_after.append(all_component_scores)\n","            region_color_after.append(all_region_colors)\n","            region_sizes_after.append(all_region_sizes)\n","\n","            # Compute weighted purity scores over all regions, for white only, and for red only\n","\n","            total_red_sum = np.nansum(red_component_sizes)\n","            total_white_sum = np.nansum(white_component_sizes)\n","\n","            if not red_component_scores:\n","                red_region_weights = np.array([0])\n","                weighted_red_scores = np.array([0])\n","            else:\n","                # this vector should add to 1, as this is a normalization of the weights\n","                red_region_weights = np.divide(\n","                    np.array(red_component_sizes), total_red_sum)\n","                weighted_red_scores = np.multiply(\n","                    np.array(red_component_scores), red_region_weights)\n","\n","            if not white_component_scores:\n","                white_region_weights = np.array([0])\n","                weighted_white_scores = np.array([0])\n","            else:\n","                # this vector should add to 1, as this is a normalization of the weights\n","                white_region_weights = np.divide(\n","                    np.array(white_component_sizes), total_white_sum)\n","                weighted_white_scores = np.multiply(\n","                    np.array(white_component_scores), white_region_weights)\n","\n","            # Get weighted average over both regions together\n","            all_region_sum = np.nansum(all_region_sizes)\n","            all_region_weights = np.divide(\n","                np.array(red_component_sizes + white_component_sizes), all_region_sum)\n","            all_region_weighted_scores = np.multiply(\n","                np.array(red_component_scores + white_component_scores), all_region_weights)\n","\n","            weighted_purity_red_after.append(list(weighted_red_scores))\n","            weighted_purity_white_after.append(list(weighted_white_scores))\n","            weighted_purity_after.append(list(all_region_weighted_scores))\n","            weighted_red_sector_score_after.append(\n","                np.nansum(weighted_red_scores))\n","            weighted_white_sector_score_after.append(\n","                np.nansum(weighted_white_scores))\n","            weighted_sector_score_after.append(\n","                np.nansum(all_region_weighted_scores))\n","\n","            # Now, create the masks containing the initial_regions\n","            post_region_mask = np.maximum(post_red_region_mask.astype(\n","                np.uint8), 2*post_white_region_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","            post_boundary_mask = np.maximum(post_red_boundary_mask.astype(\n","                np.uint8), 2*post_white_boundary_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","            post_score_mask = np.maximum(post_red_score_mask.astype(\n","                np.uint8), 2*post_white_score_mask.astype(np.uint8))*(255/(NUM_CLASSES-1))\n","\n","            post_region_mask = np.pad(post_region_mask, IMAGE_PADDING)\n","            post_boundary_mask = np.pad(post_boundary_mask, IMAGE_PADDING)\n","            post_score_mask = np.pad(post_score_mask, IMAGE_PADDING)\n","\n","            if SAVE_ALL_ANNOTATIONS is True:\n","                if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/cor_bounds/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', post_boundary_mask):\n","                    raise IOError('Could not write image.')\n","                if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/cor_regions/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', post_region_mask):\n","                    raise IOError('Could not write image.')\n","                if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/cor_bad/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', post_score_mask):\n","                    raise IOError('Could not write image.')\n","            plt.axis('off')\n","            if SAVE_ALL_ANNOTATIONS is True:\n","                fig2.savefig(OUTPUT_CROPS_FOLDER + '/cor_partitions/' + file_dict[plate_name] + '/' + pathlib.Path(\n","                    test_image).stem + '_c_' + str(this_index) + '.png', bbox_inches='tight', pad_inches=0)\n","            plt.close(fig2)\n","\n","            #------------------------------------------------------------------\n","\n","            # PRINTING RESULTS OF COLONY\n","\n","            if not sector_scores:\n","                sector_scores = 0\n","                sector_ious = 0\n","            average_sector_score.append(np.mean(sector_scores))\n","            average_sector_iou.append(np.mean(sector_ious))\n","            #print('Colony ' + str(this_index))\n","            print('Estimated number of sectors: ' + str(total_sectors))\n","            all_sector_counts.append(total_sectors)\n","            print('Average sector score: ' + str(average_sector_score[-1]))\n","            print('Average sector score (IoU): ' + str(average_sector_iou[-1]))\n","\n","            corrected_white_region_sum.append(\n","                np.sum(np.logical_xor(corrected_colony_mask, all_sector_filled)))\n","            corrected_red_region_sum.append(np.sum(all_sector_filled))\n","            corrected_sector_region_sum.append(\n","                np.sum(all_sector_filled) / np.sum(corrected_colony_mask))\n","\n","            true_sector_count = 0\n","            true_sector_counts.append(true_sector_count)\n","            true_sector_region_sum.append(0)\n","            corrected_colony_mask_faded[corrected_colony_mask == 0] = 0\n","\n","            corrected_colony_mask_faded = np.pad(\n","                corrected_colony_mask_faded, IMAGE_PADDING)\n","            corrected_red_colony_mask_padded = np.pad(\n","                corrected_red_colony_mask, IMAGE_PADDING)\n","            corrected_sector_comp_mask = np.multiply(\n","                corrected_red_colony_mask_padded, corrected_colony_mask_faded)\n","\n","            #colony_image_padded = np.pad(colony_image, IMAGE_PADDING)\n","            #cv2_imshow(colony_mask_faded)\n","            if SAVE_ALL_ANNOTATIONS is True:\n","                if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/sectors/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', corrected_colony_mask_faded):\n","                    raise IOError('Could not write image.')\n","                if not cv2.imwrite(OUTPUT_CROPS_FOLDER + '/sector_comps/' + file_dict[plate_name] + '/' + pathlib.Path(test_image).stem + '_c_' + str(this_index) + '.png', corrected_sector_comp_mask):\n","                    raise IOError('Could not write image.')\n","\n","        # This ends the loop on the isolated colonies\n","\n","        # Ensure that the number of sectors are integers\n","\n","        # Construct a dataframe with the nubmer of sectors and the proportion of red present\n","\n","        all_sector_counts_array = np.array(all_sector_counts).astype(int)\n","        true_sector_counts = np.array(true_sector_counts).astype(int)\n","        #true_sector_counts = np.repeat(1,len(indiv_good))\n","        correct_sector_count = np.abs(\n","            true_sector_counts - all_sector_counts_array) == 0\n","\n","        sides_vert_top_array = np.array(sides_vert_top)\n","        sides_vert_bottom_array = np.array(sides_vert_bottom)\n","        sides_horz_left_array = np.array(sides_horz_left)\n","        sides_horz_right_array = np.array(sides_horz_right)\n","\n","        # Gather all data that that can be created as a numpy array\n","        d = {'Plate Name': plate_names,\n","             'Colony Number': colony_numbers.astype(int),\n","             'True # Sectors': true_sector_counts,\n","             'Initial # Regions': np.array(initial_region_counts).astype(int),\n","             'Pred # Sectors': all_sector_counts_array,\n","             'Correct # Sectors?': correct_sector_count,\n","             'White Area (Seg)': white_region_sum,\n","             'Red Area (Seg)': red_region_sum,\n","             'Colony Area (Seg)': (np.array(white_region_sum) + np.array(red_region_sum)),\n","             'White Area (Corr)': corrected_white_region_sum,\n","             'Red Area (Corr)': corrected_red_region_sum,\n","             'Colony Area (Corr)': (np.array(corrected_white_region_sum) + np.array(corrected_red_region_sum)),\n","             'Avg Sector Score': average_sector_score,\n","             'Avg Sector Score (IoU)': average_sector_iou,\n","             'Side Top': sides_vert_top_array,\n","             'Side Bottom': sides_vert_bottom_array,\n","             'Side Left': sides_horz_left_array,\n","             'Side Right': sides_horz_right_array,\n","             '1 Comp': np.array(colony_is_connected),\n","             '1 Comp (Approx)': np.array(colony_is_approx_connected),\n","             'Bound Comp': np.array(boundary_is_connected),\n","             'No Holes': np.array(colony_is_whole),\n","             'Approx Convex': np.array(colony_is_approx_convex),\n","             'Approx Circle': np.array(colony_is_approx_circular),\n","             'Hausdorff Convex': np.array(hausdorff_dist_convex),\n","             'Hausdorff Circle': np.array(hausdorff_dist_circle)}\n","\n","        #Gather data based on what else we used as input\n","        if USE_EXPERT_COUNTS is True:\n","            d['Quantifiable'] = np.array(quantifiable_colony)\n","            d['Quantifiable Cured'] = np.array(quantifiable_cured)\n","            d['Quantifiable Stable'] = np.array(quantifiable_stable)\n","            d['Quantifiable Sectored'] = np.array(quantifiable_sectored)\n","\n","        df = pd.DataFrame(data=d)\n","\n","        # Gather data that could NOT be stored as a numpy array, such as nested lists\n","\n","        df['(BC) Regional Color Classes'] = list(region_color_before)\n","        df['(BC) Regional Sizes'] = list(region_sizes_before)\n","        df['(BC) Regional Purity Scores'] = list(region_purity_before)\n","        df['(BC) Red Purity Scores Weighted'] = list(\n","            weighted_purity_red_before)\n","        df['(BC) White Purity Scores Weighted'] = list(\n","            weighted_purity_white_before)\n","        df['(BC) Weighted Red Average Score'] = weighted_red_sector_score_before\n","        df['(BC) Weigted White Average Score'] = weighted_white_sector_score_before\n","        df['(BC) Weighted Full Average Score'] = weighted_sector_score_before\n","        df['(BC) Cured'] = cured_colony_before\n","        df['(BC) Stable'] = stable_colony_before\n","\n","        df['(AC) Regional Color Classes'] = list(region_color_after)\n","        df['(AC) Regional Sizes'] = list(region_sizes_after)\n","        df['(AC) Regional Purity Scores'] = list(region_purity_after)\n","        df['(AC) Red Purity Scores Weighted'] = list(\n","            weighted_purity_red_after)\n","        df['(AC) White Purity Scores Weighted'] = list(\n","            weighted_purity_white_after)\n","        df['(AC) Weighted Red Average Score'] = weighted_red_sector_score_after\n","        df['(AC) Weighted White Average Score'] = weighted_white_sector_score_after\n","        df['(AC) Weighted Full Average Score'] = weighted_sector_score_after\n","        df['(AC) Cured'] = cured_colony_after\n","        df['(AC) Stable'] = stable_colony_after\n","\n","        df.to_pickle(TEST_OUTPUT_TABLE_FOLDER + '/' + str(plate_stem) + '.pkl')\n"]},{"cell_type":"markdown","metadata":{"id":"ElZaHbZW18m2"},"source":["## Merge tables into one"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ftPWVHpDzu72"},"outputs":[],"source":["# Read in all the files of data\n","sorted_tables = sorted(glob.glob(TEST_OUTPUT_TABLE_FOLDER + '/' + '*'))\n","print(sorted_tables)\n","\n","first_table = True\n","\n","for this_table in sorted_tables:\n","    this_table_data = pd.read_pickle(this_table)\n","    if first_table is True:\n","        first_table = False\n","        all_table_data = copy.deepcopy(this_table_data)\n","    else:\n","        all_table_data = pd.concat([all_table_data, this_table_data], axis=0, ignore_index=True)\n","\n","all_table_data.to_pickle(TEST_OUTPUT_FOLDER + '/' + str(WEIGHTS_FILE) + '_colony_data.pkl')\n"]},{"cell_type":"markdown","metadata":{"id":"ZeIsygqA2CI0"},"source":["## Load data table and append the true data (if any) as additional columns"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WCdlyTrc2JW2"},"outputs":[],"source":["colony_data = pd.read_pickle(TEST_OUTPUT_FOLDER + '/' + str(WEIGHTS_FILE) + '_colony_data.pkl')\n","\n","#print(colony_data)\n","all_plate_names = colony_data['Plate Name'].unique()\n","all_sector_values = list(range(0, int(np.max(colony_data['Pred # Sectors']))+1))\n","\n","# Include true sector counts if available\n","if USE_TRUE_SECTOR_COUNTS is True:\n","\n","    # Read in table with true sector counts\n","    true_sector_counts = pd.read_csv(TEST_OUTPUT_FOLDER + '/true_colony_data.csv')\n","    # load file containing true sector counts\n","    colony_data['True # Sectors'] = true_sector_counts['True # Sectors']\n","    # insert the true sector counts in the data\n","    matching_sector_counts = colony_data['True # Sectors'] == colony_data['Pred # Sectors']\n","    # compare the true and predicted sector counts\n","    colony_data['Correct # Sectors?'] = matching_sector_counts\n","    # mark where the counts match and insert this into the data\n","\n","if USE_QUANTIFIABLE_COUNTS_FROM_TABLE is True:\n","    true_quant_colonies = pd.read_csv(TEST_OUTPUT_FOLDER + '/true_quantifiable_colonies.csv')\n","    # load file containing whether colony is cured\n","    colony_data['Quantifiable'] = true_quant_colonies['Quantifiable']\n","    # insert this data into the original table\n","\n","if USE_TRUE_CURED_COLONIES_FROM_TABLE is True:\n","    # Read in table with true cured colonies\n","    true_cured_colonies = pd.read_csv(TEST_OUTPUT_FOLDER + '/true_cured_colonies.csv')\n","    # load file containing whether colony is cured\n","    colony_data['Is Cured?'] = true_cured_colonies['Is Cured?']\n","    # insert this data into the original table\n","\n","if (USE_TRUE_SECTOR_COUNTS is True) & (USE_QUANTIFIABLE_COUNTS_FROM_TABLE is True) & (USE_TRUE_CURED_COLONIES_FROM_TABLE is True):\n","    colony_data['Quantifiable Cured'] = (colony_data['Quantifiable']) & (colony_data['Is Cured?'])\n","    colony_data['Quantifiable Stable'] = (colony_data['Quantifiable']) & (colony_data['True # Sectors'] == 0)\n","    colony_data['Quantifiable Sectored'] = (colony_data['Quantifiable']) & (colony_data['True # Sectors'] > 0) & (~colony_data['Is Cured?'])\n","\n","colony_data.to_pickle(TEST_OUTPUT_FOLDER + '/' + str(WEIGHTS_FILE) + '_colony_data.pkl')\n","\n","colony_data.to_csv(TEST_OUTPUT_FOLDER + '/' + str(WEIGHTS_FILE) + '_colony_data.csv')\n","colony_data\n"]},{"cell_type":"markdown","metadata":{"id":"10aO-mKQ2dMX"},"source":["## Add [PSI] labels to classified colonies using data obtained from the classification step"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c1l2QZSN2k4J"},"outputs":[],"source":["colony_states_before = np.array(\n","    ['UNFILLED' for i in range(0, len(colony_data))])\n","colony_states_after = np.array(\n","    ['UNFILLED' for i in range(0, len(colony_data))])\n","colony_states_true = np.array(['UNFILLED' for i in range(0, len(colony_data))])\n","#colony_states_set = set(colony_states)\n","#print(colony_states_set)\n","\n","max_sector_count_before = max(colony_data['Initial # Regions'])\n","max_sector_count_after = max(colony_data['Pred # Sectors'])\n","max_sector_count_true = max(colony_data['True # Sectors'])\n","\n","max_sector_count_all = max(\n","    [max_sector_count_before, max_sector_count_after, max_sector_count_true])\n","\n","# [PSI+]: Get all colonies with no red regions\n","\n","colony_states_before[colony_data['(BC) Stable']] = '[PSI+]'\n","colony_states_after[colony_data['(AC) Stable']] = '[PSI+]'\n","#colony_states_true[colony_data['Is Stable?']] = '[PSI+]'\n","\n","# [psi-]: Get all quantifiable colonies with no white regions\n","\n","colony_states_before[colony_data['(BC) Cured']] = '[psi-]'\n","colony_states_after[colony_data['(AC) Cured']] = '[psi-]'\n","#colony_states_true[colony_data['Is Cured?']] = '[psi-]'\n","\n","# Sx: Get all quantifiable colonies with at least 1 white region and exactly x red regions\n","\n","for num_regions in range(1, max_sector_count_all+1):\n","    colony_states_before[(~colony_data['(BC) Cured']) & (~colony_data['(BC) Stable']) & (\n","        colony_data['Initial # Regions'] == num_regions)] = str('S' + str(num_regions))\n","    colony_states_after[(~colony_data['(AC) Cured']) & (~colony_data['(AC) Stable']) & (\n","        colony_data['Pred # Sectors'] == num_regions)] = str('S' + str(num_regions))\n","    #colony_states_true[(~colony_data['Is Cured?']) & (~colony_data['Is Stable?']) & (\n","    #    colony_data['True # Sectors'] == num_regions).astype(bool)] = str('S' + str(num_regions))\n","\n","#print(np.unique(colony_states_before))\n","#print(np.unique(colony_states_after))\n","#print(np.unique(colony_states_true))\n","\n","unmarked_locations = np.where(colony_states_true == 'UNFILLED')\n","\n","# Make corrections to the table for unfilled locations\n","\n","\n","# Display any colony locations what are marked as UNFILLED\n","\n","colony_row = colony_data.iloc[unmarked_locations]\n","#print(colony_row)\n","#print(colony_row.index)\n","\n","#print(colony_states_before)\n","\n","# If every location has been filled, then add these to the merged table\n","colony_data['Label Before'] = colony_states_before\n","colony_data['Label After'] = colony_states_after\n","#colony_data['Label True'] = colony_states_true\n"]},{"cell_type":"markdown","metadata":{"id":"LtQKfuBy4SID"},"source":["## Show locations of extracted colonies and save these as separate images"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qH-UrS035-qN"},"outputs":[],"source":["all_plate_names = colony_data['Plate Name'].unique()\n","all_sector_values = list(range(0, np.max(colony_data['Pred # Sectors'])+1))\n","\n","# iterate through each plate\n","for this_plate_name in all_plate_names:\n","\n","    this_plate_stem = os.path.splitext(this_plate_name)[0]\n","    print('Looking at ' + str(this_plate_name) + ':')\n","    this_plate_data = colony_data[colony_data['Plate Name'] == this_plate_name]\n","    number_colonies = len(this_plate_data)  # number of colonies found\n","    print(number_colonies)\n","    indicator_array = []  # initialize\n","\n","    for this_colony in range(0, number_colonies):\n","        # Check if the colony was predicted to be red (cured)\n","        if (this_plate_data['(AC) Cured'].iloc[this_colony]) & (this_plate_data['Pred # Sectors'].iloc[this_colony] == 1):\n","            indicator_array.append(2)\n","        # Check if the colony was predicted to be white (stable)\n","        elif (this_plate_data['(AC) Stable'].iloc[this_colony]) & (this_plate_data['Pred # Sectors'].iloc[this_colony] == 0):\n","            indicator_array.append(4)\n","        # Check if the colony was predicted to be variegating (sectored, neither cured nor stable)\n","        elif ~this_plate_data['(AC) Stable'].iloc[this_colony] & ~this_plate_data['(AC) Cured'].iloc[this_colony] & (this_plate_data['Pred # Sectors'].iloc[this_colony] > 0):\n","            indicator_array.append(3)\n","        # Anything else is a bad segmentation.\n","        # Pink colonies are not considered, so 1 is not assigned\n","        else:\n","            indicator_array.append(0)\n","\n","    indicator_array = np.array(indicator_array)\n","    # Display total number of colonies for each label\n","    print('Bad segementations: ' + str(np.sum(indicator_array == 0)))\n","    print('Fully red colonies: ' + str(np.sum(indicator_array == 2)))\n","    print('Fully white colonies: ' + str(np.sum(indicator_array == 4)))\n","    print('Sectored colonies: ' + str(np.sum(indicator_array == 3)))\n","\n","    # Plot the boxes onto the image\n","    this_image = read_image(REAL_IMAGE_FOLDER + '/' + this_plate_name)\n","    this_img_copy = copy.deepcopy(this_image)*255\n","    print(len(indicator_array))\n","    for this_row in range(0, number_colonies):\n","        this_pred = indicator_array[this_row]\n","        cv2.rectangle(this_img_copy, (this_plate_data['Side Left'].iloc[this_row], this_plate_data['Side Top'].iloc[this_row]), (\n","            this_plate_data['Side Right'].iloc[this_row], this_plate_data['Side Bottom'].iloc[this_row]), get_color_codes(this_pred), 2)\n","        #cv2.rectangle(this_img_copy, (this_plate_data['Side Top'].iloc[this_row], this_plate_data['Side Left'].iloc[this_row]), (this_plate_data['Side Bottom'].iloc[this_row], this_plate_data['Side Right'].iloc[this_row]), get_color_codes(this_pred), 2)\n","    cv2_imshow(this_img_copy)\n","\n","    cv2.imwrite(TEST_BOXES_FOLDER + '/' +\n","                this_plate_stem + '.jpg', this_img_copy)\n"]},{"cell_type":"markdown","metadata":{"id":"2R_Gc0jwCYTA"},"source":["## Plots"]},{"cell_type":"markdown","metadata":{"id":"r0iapfGJDBKs"},"source":["### Predictions Only"]},{"cell_type":"markdown","metadata":{"id":"aE4_HedXDFi4"},"source":["#### Colony States (no sector counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rHbK4prYDDqj"},"outputs":[],"source":["max_initial = np.max(colony_data['Initial # Regions'])\n","max_pred = np.max(colony_data['Pred # Sectors'])\n","# max_true = np.max(colony_data['True # Sectors'])\n","max_all = np.max([max_initial, max_pred])\n","# diff_count_before = np.abs(colony_data['Initial # Regions'] - colony_data['True # Sectors'])\n","# diff_count_after = np.abs(colony_data['Pred # Sectors'] - colony_data['True # Sectors'])\n","\n","label_names = ['[PSI+]', '[psi-]', 'Sectored']\n","\n","initial_correct_counts = []\n","post_correct_counts = []\n","#true_correct_counts = []\n","all_counts = []\n","\n","\n","# print(np.unique(colony_data['Label True']))\n","\n","# Gather [PSI+] counts\n","#true_white_labels = colony_data[(colony_data['Label True'] == '[PSI+]')]\n","correct_white_labels_before = colony_data[(\n","    colony_data['Label Before'] == '[PSI+]')]\n","correct_white_labels_after = colony_data[(\n","    colony_data['Label After'] == '[PSI+]')]\n","\n","initial_correct_counts.append(len(correct_white_labels_before))\n","post_correct_counts.append(len(correct_white_labels_after))\n","# true_correct_counts.append(len(true_white_labels))\n","\n","# Gather [psi-] counts\n","#true_red_labels = colony_data[(colony_data['Label True'] == '[psi-]')]\n","correct_red_labels_before = colony_data[(\n","    colony_data['Label Before'] == '[psi-]')]\n","correct_red_labels_after = colony_data[(\n","    colony_data['Label After'] == '[psi-]')]\n","\n","initial_correct_counts.append(len(correct_red_labels_before))\n","post_correct_counts.append(len(correct_red_labels_after))\n","# true_correct_counts.append(len(true_red_labels))\n","\n","\n","# Gather sectored counts\n","correct_sector_labels_before = colony_data[(\n","    colony_data['Label Before'].str.startswith('S'))]\n","correct_sector_labels_after = colony_data[(\n","    colony_data['Label After'].str.startswith('S'))]\n","\n","initial_correct_counts.append(len(correct_sector_labels_before))\n","post_correct_counts.append(len(correct_sector_labels_after))\n","# max_sector_counts = max([np.nanmax(colony_data['Initial # Regions'].astype(int)), np.nanmax(colony_data['Pred # Sectors'].astype(int)), np.nanmax(colony_data['True # Sectors'].astype(int))])\n","# print(max_sector_counts)\n","\n","# for this_num_sectors in range(1, max_sector_counts+1):\n","#     #true_sector_labels = colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors))]\n","#     correct_sector_labels_before = colony_data[(colony_data['Label Before'] == 'S'+str(this_num_sectors))]\n","#     correct_sector_labels_after = colony_data[(colony_data['Label After'] == 'S'+str(this_num_sectors))]\n","\n","#     initial_correct_counts.append(len(correct_sector_labels_before))\n","#     post_correct_counts.append(len(correct_sector_labels_after))\n","#     #true_correct_counts.append(len(true_sector_labels))\n","\n","# print(colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors)) & (colony_data['Label After'] == 'S'+str(this_num_sectors))])\n","#sector_labels = ['S'+str(i) for i in (range(1, max_sector_counts+1))]\n","# print(sector_labels)\n","#label_names = label_names + sector_labels\n","# print(label_names)\n","x = np.arange(len(label_names))\n","# print(len(x))\n","# print(len(initial_correct_counts))\n","\n","\n","width = 0.25  # the width of the bars\n","\n","fig, ax = plt.subplots(figsize=(12, 5), sharey=True)\n","#x - width/2\n","ax.set_ylim(bottom=0, top=max(initial_correct_counts + post_correct_counts)+50)\n","rects1 = ax.bar(x - width/2, initial_correct_counts, width,\n","                label='Original Predictions', color='blue')\n","rects2 = ax.bar(x+width/2, post_correct_counts, width,\n","                label='With Purity Correction', color='red')\n","#rects2 = ax.bar(x + width/2, all_counts, width, label='All Colonies', color='red')\n","#rects3 = ax.bar(x + width, true_correct_counts, width, label='Manual Counts', color='green')\n","\n","# print(true_single_frequency)\n","# print(pred_single_frequency)\n","\n","ax.set_xlabel('Colony States')\n","ax.set_ylabel('Frequency')\n","ax.set_title('Classified Colonies', fontsize=16)\n","ax.xaxis.label.set_fontsize(14)\n","ax.yaxis.label.set_fontsize(14)\n","ax.set_xticks(np.arange(0, 3, step=1))\n","ax.set_xticklabels(label_names)\n","ax.tick_params(axis='both', labelsize=12)\n","ax.legend(loc='best')\n","\n","xtickslocs = ax.get_xticks()\n","print(xtickslocs)\n","\n","addlabels_centered(xtickslocs-width/2, initial_correct_counts, 9)\n","addlabels_centered(xtickslocs+width/2, post_correct_counts, 9)\n","#addlabels_pred(x, all_counts, 10)\n","#addlabels_truemarks(x, true_correct_counts, 9)\n","\n","ax.axvline(x=0.5, color='k', linestyle='--')\n","ax.axvline(x=1.5, color='k', linestyle='--')\n","\n","fig.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"Xn-89EPYDHuF"},"source":["#### Colony States (with sector counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"W6EbJA8DDKQP"},"outputs":[],"source":["max_initial = np.max(colony_data['Initial # Regions'])\n","max_pred = np.max(colony_data['Pred # Sectors'])\n","# max_true = np.max(colony_data['True # Sectors'])\n","max_all = np.max([max_initial, max_pred])\n","# diff_count_before = np.abs(colony_data['Initial # Regions'] - colony_data['True # Sectors'])\n","# diff_count_after = np.abs(colony_data['Pred # Sectors'] - colony_data['True # Sectors'])\n","\n","initial_correct_counts = []\n","post_correct_counts = []\n","#true_correct_counts = []\n","all_counts = []\n","\n","label_names = ['[PSI+]', '[psi-]']\n","\n","# print(np.unique(colony_data['Label True']))\n","\n","# Gather [PSI+] counts\n","#true_white_labels = colony_data[(colony_data['Label True'] == '[PSI+]')]\n","correct_white_labels_before = colony_data[(\n","    colony_data['Label Before'] == '[PSI+]')]\n","correct_white_labels_after = colony_data[(\n","    colony_data['Label After'] == '[PSI+]')]\n","\n","initial_correct_counts.append(len(correct_white_labels_before))\n","post_correct_counts.append(len(correct_white_labels_after))\n","# true_correct_counts.append(len(true_white_labels))\n","\n","# Gather [psi-] counts\n","#true_red_labels = colony_data[(colony_data['Label True'] == '[psi-]')]\n","correct_red_labels_before = colony_data[(\n","    colony_data['Label Before'] == '[psi-]')]\n","correct_red_labels_after = colony_data[(\n","    colony_data['Label After'] == '[psi-]')]\n","\n","initial_correct_counts.append(len(correct_red_labels_before))\n","post_correct_counts.append(len(correct_red_labels_after))\n","# true_correct_counts.append(len(true_red_labels))\n","\n","\n","# Gather sectored counts\n","max_sector_counts = max([np.nanmax(colony_data['Initial # Regions'].astype(int)), np.nanmax(\n","    colony_data['Pred # Sectors'].astype(int)), np.nanmax(colony_data['True # Sectors'].astype(int))])\n","# print(max_sector_counts)\n","\n","for this_num_sectors in range(1, max_sector_counts+1):\n","    #true_sector_labels = colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors))]\n","    correct_sector_labels_before = colony_data[(\n","        colony_data['Label Before'] == 'S'+str(this_num_sectors))]\n","    correct_sector_labels_after = colony_data[(\n","        colony_data['Label After'] == 'S'+str(this_num_sectors))]\n","\n","    initial_correct_counts.append(len(correct_sector_labels_before))\n","    post_correct_counts.append(len(correct_sector_labels_after))\n","    # true_correct_counts.append(len(true_sector_labels))\n","\n","# print(colony_data[(colony_data['Label True'] == 'S'+str(this_num_sectors)) & (colony_data['Label After'] == 'S'+str(this_num_sectors))])\n","sector_labels = ['S'+str(i) for i in (range(1, max_sector_counts+1))]\n","# print(sector_labels)\n","label_names = label_names + sector_labels\n","# print(label_names)\n","x = np.arange(len(label_names))\n","# print(len(x))\n","# print(len(initial_correct_counts))\n","\n","\n","width = 0.25  # the width of the bars\n","\n","fig, ax = plt.subplots(figsize=(12, 5), sharey=True)\n","#x - width/2\n","ax.set_ylim(bottom=0, top=max(initial_correct_counts + post_correct_counts)+50)\n","rects1 = ax.bar(x - width/2, initial_correct_counts, width,\n","                label='Original Predictions', color='blue')\n","rects2 = ax.bar(x+width/2, post_correct_counts, width,\n","                label='With Purity Correction', color='red')\n","#rects2 = ax.bar(x + width/2, all_counts, width, label='All Colonies', color='red')\n","#rects3 = ax.bar(x + width, true_correct_counts, width, label='Manual Counts', color='green')\n","\n","# print(true_single_frequency)\n","# print(pred_single_frequency)\n","\n","ax.set_xlabel('Colony States')\n","ax.set_ylabel('Frequency')\n","ax.set_title('Classified Colonies', fontsize=16)\n","ax.xaxis.label.set_fontsize(14)\n","ax.yaxis.label.set_fontsize(14)\n","ax.set_xticks(np.arange(0, max_sector_counts+2, step=1))\n","ax.set_xticklabels(label_names)\n","ax.tick_params(axis='both', labelsize=12)\n","ax.legend(loc='best')\n","\n","xtickslocs = ax.get_xticks()\n","print(xtickslocs)\n","\n","addlabels_centered(xtickslocs-width/2, initial_correct_counts, 9)\n","addlabels_centered(xtickslocs+width/2, post_correct_counts, 9)\n","#addlabels_pred(x, all_counts, 10)\n","#addlabels_truemarks(x, true_correct_counts, 9)\n","\n","ax.axvline(x=0.5, color='k', linestyle='--')\n","ax.axvline(x=1.5, color='k', linestyle='--')\n","\n","fig.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"_So01zqfLNZ1"},"source":["# Write colony crops to PDF files"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OuHTN53RLQSL"},"outputs":[],"source":["# Code to print a pdf of the croppings\n","# 1. Sort data in table based on plate name, colony number and other elements.\n","# 2. Iterate through each row of the sorted table to get colony imformation\n","# 3. Add information to pdf document.\n","# 4. Repear for each colony and plate.\n","# 5. Output pdf.\n","\n","for this_plate in all_plate_names:\n","\n","    # this_plate is the key to the correspnding subfolder in each annotation class\n","    # Initialize PDF writer\n","    pdf = FPDF()\n","    pdf = FPDF(unit=\"pt\", format=[850, 1100])\n","    pdf.set_font('Arial', 'B', 16)\n","    target_height = float(40)\n","    left_margin = 10\n","    right_margin = 840\n","    bottom_margin = 1050\n","    number_spacing = 7\n","    uniform_spacing = 640\n","\n","    row_number = 1  # initial row index\n","    col_position = 10  # initial column position\n","    col_margin = 40\n","    this_plate_stem = os.path.splitext(this_plate)[0]\n","\n","    this_plate_data = colony_data[colony_data['Plate Name'] == this_plate]\n","    #this_plate_data.set_index('Colony Number', inplace=True)\n","    max_num_sectors_in_plate = int(max(this_plate_data['Pred # Sectors']))\n","    pdf.add_page()\n","\n","    pdf.text(col_position, target_height*row_number, 'Colonies detected in Plate ' +\n","             str(this_plate) + '.  ' + str(len(this_plate_data)) + ' colonies were detected.')\n","    pdf.text(col_position, target_height*row_number +\n","             20, 'Group 1: Raw image data')\n","    pdf.text(col_position, target_height*row_number + 40,\n","             'Group 2: Raw segmentation of whole colony and boundary')\n","    pdf.text(col_position, target_height*row_number + 60,\n","             'Group 3: Regional breakdown and analysis before boundary corrections were made')\n","    pdf.text(col_position, target_height*row_number + 80,\n","             'Group 4: Segmentation with corrected boundary')\n","    pdf.text(col_position, target_height*row_number + 100,\n","             'Group 5: Regional breakdown and analysis after boundary corrections were made')\n","    pdf.text(col_position, target_height*row_number + 120,\n","             'Group 6: Breakdown of red sectored regions and pixels after correction')\n","\n","    row_number = row_number + 2\n","\n","    # Start by collecting all of the [PSI+] predictions\n","    for this_num_sectors in range(0, 1):\n","        row_number = row_number + 1\n","        col_position = 10\n","        # If there is not enough room for rows, move the remaining images to a new page.\n","        if (target_height*(row_number+1)) > bottom_margin:\n","            pdf.add_page()\n","            row_number = 1  # initial row index\n","        #print(this_plate_data)\n","        this_plate_sector_data = this_plate_data[this_plate_data['Label After'] == '[PSI+]']\n","        #print(this_plate_sector_data)\n","        this_plate_sector_data.reset_index()\n","        #print(this_plate_sector_data)\n","        pdf.text(col_position, target_height*row_number + (target_height/2),\n","                 'Colonies labeled [PSI+]: ' + str(len(this_plate_sector_data)))\n","        row_number = row_number + 1\n","\n","        # Sort this subtable by sector scores in descending order\n","        sorted_plate_sector_data = this_plate_sector_data.sort_values(\n","            by=['(AC) Weighted Full Average Score', 'Colony Number'], ascending=[False, True])\n","        sorted_plate_sector_data.reset_index()\n","\n","        for index, row in sorted_plate_sector_data.iterrows():\n","\n","            #print('Colony ' + str(int(row['Colony Number'])))\n","\n","            cured_status = 'Cured' if (\n","                (row['Red Area (Seg)'] / row['Colony Area (Seg)']) >= 0.95) else ''\n","\n","            cover_image_name = OUTPUT_CROPS_FOLDER + '/raw/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.jpg'\n","            cover_circle_name = OUTPUT_CROPS_FOLDER + '/circles/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.jpg'\n","            cover_mask_name = OUTPUT_CROPS_FOLDER + '/segs/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            cover_initial_region_name = OUTPUT_CROPS_FOLDER + '/init_regions/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_initial_boundary_name = OUTPUT_CROPS_FOLDER + '/init_bounds/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_initial_bad_region_name = OUTPUT_CROPS_FOLDER + '/init_bad/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_initial_sector_bounds_name = OUTPUT_CROPS_FOLDER + '/init_partitions/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            cover_corrected_mask_name = OUTPUT_CROPS_FOLDER + '/cor_segs/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_corrected_region_name = OUTPUT_CROPS_FOLDER + '/cor_regions/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_corrected_boundary_name = OUTPUT_CROPS_FOLDER + '/cor_bounds/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_corrected_bad_region_name = OUTPUT_CROPS_FOLDER + '/cor_bad/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_corrected_sector_bounds_name = OUTPUT_CROPS_FOLDER + '/cor_partitions/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            cover_sector_name = OUTPUT_CROPS_FOLDER + '/sectors/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_sector_comp_name = OUTPUT_CROPS_FOLDER + '/sector_comps/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            if USE_EXPERT_COUNTS is True:\n","                cover_counts_name = OUTPUT_CROPS_FOLDER + '/counted/' + \\\n","                    file_dict[this_plate] + '/' + this_plate_stem + \\\n","                    '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            cover_image = PIL.Image.open(cover_image_name, mode='r')\n","            cover_circle = PIL.Image.open(cover_circle_name, mode='r')\n","            cover_mask = PIL.Image.open(cover_mask_name, mode='r')\n","\n","            cover_initial_region = PIL.Image.open(\n","                cover_initial_region_name, mode='r')\n","            cover_initial_boundary = PIL.Image.open(\n","                cover_initial_boundary_name, mode='r')\n","            cover_initial_bad_region = PIL.Image.open(\n","                cover_initial_bad_region_name, mode='r')\n","            cover_initial_sector_bounds = PIL.Image.open(\n","                cover_initial_sector_bounds_name, mode='r')\n","\n","            cover_corrected_region = PIL.Image.open(\n","                cover_corrected_region_name, mode='r')\n","            cover_corrected_boundary = PIL.Image.open(\n","                cover_corrected_boundary_name, mode='r')\n","            cover_corrected_bad_region = PIL.Image.open(\n","                cover_corrected_bad_region_name, mode='r')\n","            cover_corrected_sector_bounds = PIL.Image.open(\n","                cover_corrected_sector_bounds_name, mode='r')\n","\n","            cover_sector = PIL.Image.open(cover_sector_name, mode='r')\n","            cover_sector_comp = PIL.Image.open(\n","                cover_sector_comp_name, mode='r')\n","\n","            if USE_EXPERT_COUNTS is True:\n","                cover_counts = PIL.Image.open(cover_counts_name, mode='r')\n","\n","            w_im, h_im = cover_image.size\n","            w_ma, h_ma = cover_mask.size\n","            w_annot, h_annot = cover_initial_sector_bounds.size\n","            scaling_factor_im = target_height / float(h_im)\n","            scaling_factor_ma = target_height / float(h_ma)\n","            scaling_factor_annot = target_height / float(h_annot)\n","            scaled_width_im = scaling_factor_im*w_im\n","            scaled_width_ma = scaling_factor_ma*w_ma\n","            scaled_width_annot = scaling_factor_annot*w_annot\n","            scaled_height_im = scaling_factor_im*h_im\n","            scaled_height_ma = scaling_factor_ma*h_ma\n","            scaled_height_annot = scaling_factor_annot*h_annot\n","\n","            # Check that the image, mask, and number will fit inside the\n","            # margins on the give row, and if not, move them to the next row\n","            if col_position + (3*scaled_width_im) + (10*scaled_width_ma) + (2*scaled_width_annot) + number_spacing > right_margin:\n","                row_number = row_number + 1\n","                col_position = 10\n","                current_col_position = copy.deepcopy(col_position)\n","                # If there is not enough room for rows, move the remaining\n","                # images to a new page.\n","                if (target_height*(row_number+1)) > bottom_margin:\n","                    pdf.add_page()\n","                    row_number = 1  # initial row index\n","            else:\n","                current_col_position = copy.deepcopy(col_position)\n","            #print(all_cropped_images[index])\n","            # Add images and masks to the defined position\n","\n","            # Cropping of colony\n","            pdf.image(cover_image_name, current_col_position, target_height*row_number,\n","                      scaled_width_im, scaled_height_im)  # Insert cropping of colony\n","            current_col_position = current_col_position + scaled_width_im\n","\n","            # Cropping of colony from Wes's annotations\n","            if USE_EXPERT_COUNTS is True:\n","                pdf.image(cover_counts_name, current_col_position, target_height*row_number,\n","                          scaled_width_im, scaled_height_im)  # Insert cropping of colony\n","                current_col_position = current_col_position + scaled_width_im\n","\n","            # Cropping of colony with circle\n","            pdf.image(cover_circle_name, current_col_position, target_height*row_number,\n","                      scaled_width_im, scaled_height_im)  # Insert cropping of\n","            # colony with overlayed circle\n","            current_col_position = current_col_position + scaled_width_im\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # Raw semgentation\n","            pdf.image(cover_mask_name, current_col_position, target_height*row_number,\n","                      scaled_width_ma, scaled_height_ma)  # Insert colony\n","            # segmentation within the circle\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # The boundary of the raw segmentation\n","            pdf.image(cover_initial_boundary_name, current_col_position, target_height*row_number,\n","                      scaled_width_ma, scaled_height_ma)  # Insert colony\n","            # segmentation within the circle\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # The regional breakdown of the raw segmentation\n","            pdf.image(cover_initial_region_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation showing\n","            # the different regions of the colony\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # Annotations of where the red regions are found in the regional breakdown\n","            pdf.image(cover_initial_sector_bounds_name, current_col_position,\n","                      target_height*row_number,\n","                      scaled_width_annot, scaled_height_annot)  # Insert\n","            # segmentaiton with boundaries of sectors annotated\n","            current_col_position = current_col_position + scaled_width_annot\n","\n","            # The inconsistent regions located\n","            pdf.image(cover_initial_bad_region_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation that shows\n","            # the regions that failed the consistency check\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # The segmentation such that boundary pixels inconsistent with\n","            # their assigned region were changed\n","            pdf.image(cover_corrected_mask_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation showing\n","            # the different regions of the colony\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # The boundary of the corrected segmentation\n","            pdf.image(cover_corrected_boundary_name, current_col_position, target_height*row_number,\n","                      scaled_width_ma, scaled_height_ma)  # Insert boundary\n","            # segmentation showing the different regions of the colony\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # The regional breakdown of the corrected segmentation\n","            pdf.image(cover_corrected_region_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation showing\n","            # the different regions of the colony\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # Annotations on the corrected segmentations indicating where the\n","            # red regions are (these should be the sectors)\n","            pdf.image(cover_corrected_sector_bounds_name, current_col_position,\n","                      target_height*row_number,\n","                      scaled_width_annot, scaled_height_annot)  # Insert\n","            # segmentation with boundaries of sectors annotated\n","            current_col_position = current_col_position + scaled_width_annot\n","\n","            # Any inconsistent regions detected in the corrected segmentation\n","            # (in theory, these should always be completely black)\n","            pdf.image(cover_corrected_bad_region_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation that shows\n","            # the regions that failed the consistency check\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # Partitioning of the red regions found in the corrected\n","            # segmentation (each shaed of gray is a different sector)\n","            pdf.image(cover_sector_name, current_col_position,\n","                      target_height*row_number,\n","                      scaled_width_ma, scaled_height_ma)  # Insert predicted sector regions\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A subset of the previous image with only the red pixels preserved.\n","            # Insert red pixel segmentations within the predicted secto regions.\n","            pdf.image(cover_sector_comp_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma, scaled_height_ma)\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            pdf.text(current_col_position + number_spacing, target_height *\n","                     row_number + 16, str('Col #: ' + str(row['Colony Number'])))\n","            pdf.text(current_col_position + number_spacing, target_height*row_number + 36,\n","                     str('Avg Sc: ' + str(round(row['(AC) Weighted Full Average Score'], 2))))\n","\n","            # make space for the next set of images\n","\n","            col_position = current_col_position + number_spacing + col_margin\n","\n","    # Next, do the same thing for [psi-] predictions\n","    for this_num_sectors in range(0, 1):\n","        row_number = row_number + 1\n","        col_position = 10\n","        # If there is not enough room for rows, move the remaining images to a new page.\n","        if (target_height*(row_number+1)) > bottom_margin:\n","            pdf.add_page()\n","            row_number = 1  # initial row index\n","        #print(this_plate_data)\n","        this_plate_sector_data = this_plate_data[this_plate_data['Label After'] == '[psi-]']\n","        #print(this_plate_sector_data)\n","        this_plate_sector_data.reset_index()\n","        #print(this_plate_sector_data)\n","        pdf.text(col_position, target_height*row_number + (target_height/2),\n","                 'Colonies labeled [psi-]: ' + str(len(this_plate_sector_data)))\n","        row_number = row_number + 1\n","\n","        # Sort this subtable by sector scores in descending order\n","        sorted_plate_sector_data = this_plate_sector_data.sort_values(\n","            by=['(AC) Weighted Full Average Score', 'Colony Number'], ascending=[False, True])\n","        sorted_plate_sector_data.reset_index()\n","\n","        for index, row in sorted_plate_sector_data.iterrows():\n","\n","            #print('Colony ' + str(int(row['Colony Number'])))\n","\n","            cured_status = 'Cured' if (\n","                (row['Red Area (Seg)'] / row['Colony Area (Seg)']) >= 0.95) else ''\n","\n","            cover_image_name = OUTPUT_CROPS_FOLDER + '/raw/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.jpg'\n","            cover_circle_name = OUTPUT_CROPS_FOLDER + '/circles/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.jpg'\n","            cover_mask_name = OUTPUT_CROPS_FOLDER + '/segs/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            cover_initial_region_name = OUTPUT_CROPS_FOLDER + '/init_regions/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_initial_boundary_name = OUTPUT_CROPS_FOLDER + '/init_bounds/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_initial_bad_region_name = OUTPUT_CROPS_FOLDER + '/init_bad/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_initial_sector_bounds_name = OUTPUT_CROPS_FOLDER + '/init_partitions/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            cover_corrected_mask_name = OUTPUT_CROPS_FOLDER + '/cor_segs/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_corrected_region_name = OUTPUT_CROPS_FOLDER + '/cor_regions/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_corrected_boundary_name = OUTPUT_CROPS_FOLDER + '/cor_bounds/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_corrected_bad_region_name = OUTPUT_CROPS_FOLDER + '/cor_bad/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_corrected_sector_bounds_name = OUTPUT_CROPS_FOLDER + '/cor_partitions/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            cover_sector_name = OUTPUT_CROPS_FOLDER + '/sectors/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_sector_comp_name = OUTPUT_CROPS_FOLDER + '/sector_comps/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            if USE_EXPERT_COUNTS is True:\n","                cover_counts_name = OUTPUT_CROPS_FOLDER + '/counted/' + \\\n","                    file_dict[this_plate] + '/' + this_plate_stem + \\\n","                    '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            cover_image = PIL.Image.open(cover_image_name, mode='r')\n","            cover_circle = PIL.Image.open(cover_circle_name, mode='r')\n","            cover_mask = PIL.Image.open(cover_mask_name, mode='r')\n","\n","            cover_initial_region = PIL.Image.open(\n","                cover_initial_region_name, mode='r')\n","            cover_initial_boundary = PIL.Image.open(\n","                cover_initial_boundary_name, mode='r')\n","            cover_initial_bad_region = PIL.Image.open(\n","                cover_initial_bad_region_name, mode='r')\n","            cover_initial_sector_bounds = PIL.Image.open(\n","                cover_initial_sector_bounds_name, mode='r')\n","\n","            cover_corrected_region = PIL.Image.open(\n","                cover_corrected_region_name, mode='r')\n","            cover_corrected_boundary = PIL.Image.open(\n","                cover_corrected_boundary_name, mode='r')\n","            cover_corrected_bad_region = PIL.Image.open(\n","                cover_corrected_bad_region_name, mode='r')\n","            cover_corrected_sector_bounds = PIL.Image.open(\n","                cover_corrected_sector_bounds_name, mode='r')\n","\n","            cover_sector = PIL.Image.open(cover_sector_name, mode='r')\n","            cover_sector_comp = PIL.Image.open(\n","                cover_sector_comp_name, mode='r')\n","\n","            if USE_EXPERT_COUNTS is True:\n","                cover_counts = PIL.Image.open(cover_counts_name, mode='r')\n","\n","            w_im, h_im = cover_image.size\n","            w_ma, h_ma = cover_mask.size\n","            w_annot, h_annot = cover_initial_sector_bounds.size\n","            scaling_factor_im = target_height / float(h_im)\n","            scaling_factor_ma = target_height / float(h_ma)\n","            scaling_factor_annot = target_height / float(h_annot)\n","            scaled_width_im = scaling_factor_im*w_im\n","            scaled_width_ma = scaling_factor_ma*w_ma\n","            scaled_width_annot = scaling_factor_annot*w_annot\n","            scaled_height_im = scaling_factor_im*h_im\n","            scaled_height_ma = scaling_factor_ma*h_ma\n","            scaled_height_annot = scaling_factor_annot*h_annot\n","\n","            # Check that the image, mask, and number will fit inside the\n","            # margins on the give row, and if not, move them to the next row\n","            if col_position + (3*scaled_width_im) + (10*scaled_width_ma) + (2*scaled_width_annot) + number_spacing > right_margin:\n","                row_number = row_number + 1\n","                col_position = 10\n","                current_col_position = copy.deepcopy(col_position)\n","                # If there is not enough room for rows, move the remaining\n","                # images to a new page.\n","                if (target_height*(row_number+1)) > bottom_margin:\n","                    pdf.add_page()\n","                    row_number = 1  # initial row index\n","            else:\n","                current_col_position = copy.deepcopy(col_position)\n","            #print(all_cropped_images[index])\n","            # Add images and masks to the defined position\n","\n","            # Cropping of colony\n","            pdf.image(cover_image_name, current_col_position, target_height*row_number,\n","                      scaled_width_im, scaled_height_im)  # Insert cropping of colony\n","            current_col_position = current_col_position + scaled_width_im\n","\n","            # Cropping of colony from Wes's annotations\n","            if USE_EXPERT_COUNTS is True:\n","                pdf.image(cover_counts_name, current_col_position, target_height*row_number,\n","                          scaled_width_im, scaled_height_im)  # Insert cropping of colony\n","                current_col_position = current_col_position + scaled_width_im\n","\n","            # Cropping of colony with circle\n","            pdf.image(cover_circle_name, current_col_position, target_height*row_number,\n","                      scaled_width_im, scaled_height_im)  # Insert cropping of\n","            # colony with overlayed circle\n","            current_col_position = current_col_position + scaled_width_im\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # Raw semgentation\n","            pdf.image(cover_mask_name, current_col_position, target_height*row_number,\n","                      scaled_width_ma, scaled_height_ma)  # Insert colony\n","            # segmentation within the circle\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # The boundary of the raw segmentation\n","            pdf.image(cover_initial_boundary_name, current_col_position, target_height*row_number,\n","                      scaled_width_ma, scaled_height_ma)  # Insert colony\n","            # segmentation within the circle\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # The regional breakdown of the raw segmentation\n","            pdf.image(cover_initial_region_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation showing the\n","            # different regions of the colony\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # Annotations of where the red regions are found in the regional breakdown\n","            pdf.image(cover_initial_sector_bounds_name, current_col_position,\n","                      target_height*row_number,\n","                      scaled_width_annot, scaled_height_annot)  # Insert\n","            # segmentaiton with boundaries of sectors annotated\n","            current_col_position = current_col_position + scaled_width_annot\n","\n","            # The inconsistent regions located\n","            pdf.image(cover_initial_bad_region_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation that shows\n","            # the regions that failed the consistency check\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # The segmentation such that boundary pixels inconsistent with\n","            # their assigned region were changed\n","            pdf.image(cover_corrected_mask_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation showing the\n","            # different regions of the colony\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # The boundary of the corrected segmentation\n","            pdf.image(cover_corrected_boundary_name, current_col_position, target_height*row_number,\n","                      scaled_width_ma, scaled_height_ma)  # Insert\n","            # segmentation showing the different regions of the colony\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # The regional breakdown of the corrected segmentation\n","            pdf.image(cover_corrected_region_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation showing\n","            # the different regions of the colony\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # Annotations on the corrected segmentations indicating where\n","            # the red regions are (these should be the sectors)\n","            pdf.image(cover_corrected_sector_bounds_name, current_col_position,\n","                      target_height*row_number,\n","                      scaled_width_annot, scaled_height_annot)  # Insert\n","            # segmentation with boundaries of sectors annotated\n","            current_col_position = current_col_position + scaled_width_annot\n","\n","            # Any inconsistent regions detected in the corrected segmentation\n","            # (in theory, these should always be completely black)\n","            pdf.image(cover_corrected_bad_region_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation that shows\n","            # the regions that failed the consistency check\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # Partitioning of the red regions found in the corrected\n","            # segmentation (each shaed of gray is a different sector)\n","            pdf.image(cover_sector_name, current_col_position, target_height*row_number,\n","                      scaled_width_ma, scaled_height_ma)  # Insert predicted\n","            # sector regions\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A subset of the previous image with only the red pixels preserved.\n","            # Insert red pixel segmentations within the predicted sector regions.\n","            pdf.image(cover_sector_comp_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma, scaled_height_ma)\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            pdf.text(current_col_position + number_spacing, target_height *\n","                     row_number + 16, str('Col #: ' + str(row['Colony Number'])))\n","            pdf.text(current_col_position + number_spacing, target_height*row_number + 36,\n","                     str('Avg Sc: ' + str(round(row['(AC) Weighted Full Average Score'], 2))))\n","\n","            # make space for the next set of images\n","\n","            col_position = current_col_position + number_spacing + col_margin\n","\n","    # Now, do this for sectored colonies with any number of sectors\n","    for this_num_sectors in range(1, max_num_sectors_in_plate + 1):\n","        row_number = row_number + 1\n","        col_position = 10\n","        # If there is not enough room for rows, move the remaining images to a new page.\n","        if (target_height*(row_number+1)) > bottom_margin:\n","            pdf.add_page()\n","            row_number = 1  # initial row index\n","        #print(this_plate_data)\n","        this_plate_sector_data = this_plate_data[this_plate_data['Label After'] == 'S'+str(\n","            this_num_sectors)]\n","        #print(this_plate_sector_data)\n","        this_plate_sector_data.reset_index()\n","        #print(this_plate_sector_data)\n","        if this_num_sectors == 1:\n","            pdf.text(col_position, target_height*row_number + (target_height/2), 'Colonies with ' +\n","                     str(num2words(this_num_sectors)) + ' sector: ' + str(len(this_plate_sector_data)))\n","        else:\n","            pdf.text(col_position, target_height*row_number + (target_height/2), 'Colonies with ' +\n","                     str(num2words(this_num_sectors)) + ' sectors: ' + str(len(this_plate_sector_data)))\n","        row_number = row_number + 1\n","\n","        # Sort this subtable by sector scores in descending order\n","        sorted_plate_sector_data = this_plate_sector_data.sort_values(\n","            by=['(AC) Weighted Full Average Score', 'Colony Number'], ascending=[False, True])\n","        sorted_plate_sector_data.reset_index()\n","\n","        for index, row in sorted_plate_sector_data.iterrows():\n","\n","            cured_status = 'Cured' if (\n","                (row['Red Area (Seg)'] / row['Colony Area (Seg)']) >= 0.95) else ''\n","\n","            cover_image_name = OUTPUT_CROPS_FOLDER + '/raw/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.jpg'\n","            cover_circle_name = OUTPUT_CROPS_FOLDER + '/circles/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.jpg'\n","            cover_mask_name = OUTPUT_CROPS_FOLDER + '/segs/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            cover_initial_region_name = OUTPUT_CROPS_FOLDER + '/init_regions/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_initial_boundary_name = OUTPUT_CROPS_FOLDER + '/init_bounds/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_initial_bad_region_name = OUTPUT_CROPS_FOLDER + '/init_bad/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_initial_sector_bounds_name = OUTPUT_CROPS_FOLDER + '/init_partitions/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            cover_corrected_mask_name = OUTPUT_CROPS_FOLDER + '/cor_segs/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_corrected_region_name = OUTPUT_CROPS_FOLDER + '/cor_regions/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_corrected_boundary_name = OUTPUT_CROPS_FOLDER + '/cor_bounds/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_corrected_bad_region_name = OUTPUT_CROPS_FOLDER + '/cor_bad/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_corrected_sector_bounds_name = OUTPUT_CROPS_FOLDER + '/cor_partitions/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            cover_sector_name = OUTPUT_CROPS_FOLDER + '/sectors/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","            cover_sector_comp_name = OUTPUT_CROPS_FOLDER + '/sector_comps/' + \\\n","                file_dict[this_plate] + '/' + this_plate_stem + \\\n","                '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            if USE_EXPERT_COUNTS is True:\n","                cover_counts_name = OUTPUT_CROPS_FOLDER + '/counted/' + \\\n","                    file_dict[this_plate] + '/' + this_plate_stem + \\\n","                    '_c_' + str(int(row['Colony Number'])) + '.png'\n","\n","            cover_image = PIL.Image.open(cover_image_name, mode='r')\n","            cover_circle = PIL.Image.open(cover_circle_name, mode='r')\n","            cover_mask = PIL.Image.open(cover_mask_name, mode='r')\n","\n","            cover_initial_region = PIL.Image.open(\n","                cover_initial_region_name, mode='r')\n","            cover_initial_boundary = PIL.Image.open(\n","                cover_initial_boundary_name, mode='r')\n","            cover_initial_bad_region = PIL.Image.open(\n","                cover_initial_bad_region_name, mode='r')\n","            cover_initial_sector_bounds = PIL.Image.open(\n","                cover_initial_sector_bounds_name, mode='r')\n","\n","            cover_corrected_region = PIL.Image.open(\n","                cover_corrected_region_name, mode='r')\n","            cover_corrected_boundary = PIL.Image.open(\n","                cover_corrected_boundary_name, mode='r')\n","            cover_corrected_bad_region = PIL.Image.open(\n","                cover_corrected_bad_region_name, mode='r')\n","            cover_corrected_sector_bounds = PIL.Image.open(\n","                cover_corrected_sector_bounds_name, mode='r')\n","\n","            cover_sector = PIL.Image.open(cover_sector_name, mode='r')\n","            cover_sector_comp = PIL.Image.open(\n","                cover_sector_comp_name, mode='r')\n","\n","            if USE_EXPERT_COUNTS is True:\n","                cover_counts = PIL.Image.open(cover_counts_name, mode='r')\n","\n","            w_im, h_im = cover_image.size\n","            w_ma, h_ma = cover_mask.size\n","            w_annot, h_annot = cover_initial_sector_bounds.size\n","            scaling_factor_im = target_height / float(h_im)\n","            scaling_factor_ma = target_height / float(h_ma)\n","            scaling_factor_annot = target_height / float(h_annot)\n","            scaled_width_im = scaling_factor_im*w_im\n","            scaled_width_ma = scaling_factor_ma*w_ma\n","            scaled_width_annot = scaling_factor_annot*w_annot\n","            scaled_height_im = scaling_factor_im*h_im\n","            scaled_height_ma = scaling_factor_ma*h_ma\n","            scaled_height_annot = scaling_factor_annot*h_annot\n","\n","            # Check that the image, mask, and number will fit inside the\n","            # margins on the give row, and if not, move them to the next row\n","            if col_position + (3*scaled_width_im) + (10*scaled_width_ma) + (2*scaled_width_annot) + number_spacing > right_margin:\n","                row_number = row_number + 1\n","                col_position = 10\n","                current_col_position = copy.deepcopy(col_position)\n","                # If there is not enough room for rows, move the remaining\n","                # images to a new page.\n","                if (target_height*(row_number+1)) > bottom_margin:\n","                    pdf.add_page()\n","                    row_number = 1  # initial row index\n","            else:\n","                current_col_position = copy.deepcopy(col_position)\n","            #print(all_cropped_images[index])\n","            # Add images and masks to the defined position\n","\n","            # Cropping of colony\n","            pdf.image(cover_image_name, current_col_position, target_height*row_number,\n","                      scaled_width_im, scaled_height_im)  # Insert cropping of colony\n","            current_col_position = current_col_position + scaled_width_im\n","\n","            # Cropping of colony from Wes's annotations\n","            if USE_EXPERT_COUNTS is True:\n","                pdf.image(cover_counts_name, current_col_position, target_height*row_number,\n","                          scaled_width_im, scaled_height_im)  # Insert cropping of colony\n","                current_col_position = current_col_position + scaled_width_im\n","\n","            # Cropping of colony with circle\n","            pdf.image(cover_circle_name, current_col_position, target_height*row_number,\n","                      scaled_width_im, scaled_height_im)  # Insert cropping of\n","            # colony with overlayed circle\n","            current_col_position = current_col_position + scaled_width_im\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # Raw semgentation\n","            pdf.image(cover_mask_name, current_col_position, target_height*row_number,\n","                      scaled_width_ma, scaled_height_ma)  # Insert colony\n","            # segmentation within the circle\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # The boundary of the raw segmentation\n","            pdf.image(cover_initial_boundary_name, current_col_position,\n","                      target_height*row_number,\n","                      scaled_width_ma, scaled_height_ma)  # Insert colony\n","            # segmentation within the circle\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # The regional breakdown of the raw segmentation\n","            pdf.image(cover_initial_region_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation showing\n","            # the different regions of the colony\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # Annotations of where the red regions are found in the\n","            # regional breakdown\n","            pdf.image(cover_initial_sector_bounds_name, current_col_position,\n","                      target_height*row_number,\n","                      scaled_width_annot, scaled_height_annot)  # Insert\n","            # segmentaiton with boundaries of sectors annotated\n","            current_col_position = current_col_position + scaled_width_annot\n","\n","            # The inconsistent regions located\n","            pdf.image(cover_initial_bad_region_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation that shows\n","            # the regions that failed the consistency check\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # The segmentation such that boundary pixels inconsistent\n","            # with their assigned region were changed\n","            pdf.image(cover_corrected_mask_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation showing\n","            # the different regions of the colony\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # The boundary of the corrected segmentation\n","            pdf.image(cover_corrected_boundary_name, current_col_position, target_height*row_number,\n","                      scaled_width_ma, scaled_height_ma)  # Insert\n","            # segmentation showing the different regions of the colony\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # The regional breakdown of the corrected segmentation\n","            pdf.image(cover_corrected_region_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation showing\n","            # the different regions of the colony\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # Annotations on the corrected segmentations indicating where\n","            # the red regions are (these should be the sectors)\n","            pdf.image(cover_corrected_sector_bounds_name, current_col_position,\n","                      target_height*row_number,\n","                      scaled_width_annot, scaled_height_annot)  # Insert\n","            # segmentation with boundaries of sectors annotated\n","            current_col_position = current_col_position + scaled_width_annot\n","\n","            # Any inconsistent regions detected in the corrected segmentation\n","            # ( in theory, these should always be completely black)\n","            pdf.image(cover_corrected_bad_region_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma,\n","                      scaled_height_ma)  # Insert segmentation that shows\n","            # the regions that failed the consistency check\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A margin to separate subsets of visualizations\n","            current_col_position = current_col_position + 5\n","\n","            # Partitioning of the red regions found in the corrected\n","            # segmentation (each shaed of gray is a different sector)\n","            pdf.image(cover_sector_name, current_col_position, target_height*row_number,\n","                      scaled_width_ma, scaled_height_ma)  # Insert predicted\n","            # sector regions\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            # A subset of the previous image with only the red pixels preserved.\n","            # Insert red pixel segmentations within the predicted sector regions.\n","            pdf.image(cover_sector_comp_name, current_col_position,\n","                      target_height*row_number, scaled_width_ma, scaled_height_ma)\n","            current_col_position = current_col_position + scaled_width_ma\n","\n","            pdf.text(current_col_position + number_spacing, target_height *\n","                     row_number + 16, str('Col #: ' + str(row['Colony Number'])))\n","            pdf.text(current_col_position + number_spacing, target_height*row_number + 36,\n","                     str('Avg Sc: ' + str(round(row['(AC) Weighted Full Average Score'], 2))))\n","\n","            # make space for the next set of images\n","\n","            col_position = current_col_position + number_spacing + col_margin\n","\n","    # Write pdf file with output of colony data generated for this plate.\n","    pdf.output(OUTPUT_DETAILS_FOLDER + '/' + this_plate_stem + '.pdf', \"F\")\n","    print('Colonies from ' + this_plate_stem + ' printed.')\n","\n","# Merge all pdf files printed.  This will concatenate data from all plates.\n","all_files = sorted(glob.glob(OUTPUT_DETAILS_FOLDER + '/' + '*.pdf'))\n","merger = PdfMerger()\n","for this_file in all_files:\n","    merger.append(PdfReader(open(this_file, 'rb')))\n","\n","merger.write(MAIN_FOLDER + '/' + COLONY_CHART_DOC + '.pdf')\n"]},{"cell_type":"markdown","metadata":{"id":"hC2DWSL_Ni9p"},"source":["# Other Stuff I'm testing"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"h9keauu13G5e"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","my_bool_list = [True, True, False, False, True]\n","my_bool_df = pd.DataFrame()\n","\n","my_bool_df['Bools'] = my_bool_list\n","\n","print(not (True | True) & True)\n","print(not True | True & True)\n","\n","\n","~my_bool_df['Bools'].iloc[2]\n","\n","#(~stable & ~cured)\n","#~(stable | cured)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uVxbS-3vNlvE"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","\n","#my_array = np.zeros((3,3))\n","# 127 is white\n","# 255 is red\n","my_array = np.array([[0, 127, 255], [127, 127, 127], [0,127,255]], dtype=np.uint8)\n","red_array = np.where(my_array == 255, 127, 0)\n","white_array = np.where(my_array == 127, 255, 0)\n","swapped_array = red_array + white_array\n","print(my_array)\n","print(swapped_array)\n","\n","swapped_array_2 = swap_class_labels(my_array, 127, 255)\n","print(swapped_array_2)\n","\n","print(swapped_array - swapped_array_2)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r6h87zIzI7Uw"},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyN7iOCqqipRlXQYBDaYLRP3","collapsed_sections":["WdcJkrwWTDWw","rVjosxWzSovb","VnzEx3uuTgyc","-Aj5pFCzT23C","lS_pVjz3VmY8","6eoDt6C4xW53","UES7HxsLPqQU","HRJJC1OyPsjk","MwYNwSpL3vr3","G-KHZeOY39Tb","7Gs78Ruu45z0","54HKkXOM48wY","OUFRCxo55AVI","C6Eh7KVrEENl","_8FYFdm_FsCt","xwiHKpE6K558","9ECOZTFqK9BP","okqItdw8RzPs","NYiHKhfbR05-","yVbA7O4nR3aJ","ppa0h-P2gygj","JKSusIvghEHj","iSVlxwKRjRty","IpFYnY54NPbJ","CbQdR6A_NPbJ","fM4j1efJNPbK","EvBEYSlFNPbP","1k6WXhuUNPbP","hM7HRJVNNPbP","ElZaHbZW18m2","ZeIsygqA2CI0","LtQKfuBy4SID","aE4_HedXDFi4","Xn-89EPYDHuF"],"gpuType":"V100","provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
